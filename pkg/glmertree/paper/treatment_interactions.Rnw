\documentclass[nobf,doc]{apa}
\usepackage{amssymb}
\usepackage{amsmath,amsthm,tabularx,curves,texdraw,psfrag}
\usepackage{apacite}
\usepackage[english]{babel}
\usepackage{lscape,dcolumn,hhline}
\usepackage{graphicx,epic,eepic,rotating}
\usepackage[normalem]{ulem}
\usepackage{fancyhdr}
\usepackage{eurosym,bbding}
\usepackage{verbatim}
\usepackage{bigfoot}
\usepackage{ctable}
\usepackage{rotating}
\usepackage{lineno}
\usepackage{placeins}
\linespread{1.2}
\usepackage{tabto}

%% for \usepackage{Sweave}
\SweaveOpts{echo=FALSE, results=hide}
\setkeys{Gin}{width=0.8\textwidth}

<<preliminaries>>=
library("foreign")
library("glmertree")
library("lattice")
@

\title{Detecting Treatment-Subgroup Interactions in Clustered Data with Generalized Linear Mixed-Effects Model Trees}
\shorttitle{Detecting Treatment-Subgroup Interactions in Clustered Data with GLMM Trees}
\leftheader{Treatment-Subgroup Interactions with GLMM Trees}
\rightheader{Treatment-Subgroup Interactions with GLMM Trees}
\author{M. Fokkema$^1$, N. Smits$^2$, A. Zeileis$^3$, T. Hothorn$^4$, H. Kelderman$^5$}
\affiliation{$^1$Universiteit Leiden, $^2$Universiteit van Amsterdam, $^3$Universit\"{a}t Innsbruck, $^4$Universit\"{a}t Z\"{u}rich, $^5$Universiteit Leiden and Vrije Universiteit, Amsterdam}

\acknowledgements{The authors would like to thank Prof.~Pim Cuijpers, Prof.~Jeanne Miranda, Dr.~Boadie Dunlop, Prof.~Rob DeRubeis, Prof.~Zindel Segal, Dr.~Sona Dimidjian, Prof.~Steve Hollon and Erica Weitz for granting access to the dataset for the application. The work for this paper was partially done while MF, AZ and TH were visiting the Institute for Mathematical Sciences, National University of Singapore in 2014. The visit was supported by the Institute.}

\begin{document}

\maketitle
\pagewiselinenumbers

\section{Abstract}
Identification of subgroups of patients for which treatment A is more effective than treatment B, and vice versa, is of key importance to the development of personalized medicine. Tree-based algorithms are helpful tools for the  detection of such interactions, but none of the available tree-based algorithms allow for taking into account a clustered or nested structure. Therefore, we propose the generalized linear mixed-effects model trees (GLMM tree) algorithm, which allows for the detection of treatment-subgroup interactions, while accounting for the clustered structure of a dataset. The algorithm uses model-based recursive partitioning (MOB) to detect treatment-subgroup interactions, and a GLMM for the estimation of random-effects parameters. In a simulation study, we evaluate the performance of GLMM trees and compare it with that of trees without random effects, and GLMMs with pre-specified interactions. GLMM tree was found to accurately recover treatment-subgroup interactions in 90\% of the simulated datasets, whereas trees without random effects only did so in 61\% of datasets. GLMM tree also outperformed trees without random effects in terms of predictive accuracy (.94 and .88 on average, respectively) and Type-I error rates (4\% and 33\%, respectively). Furthermore, compared to GLMMs with pre-specified interaction effects, GLMM tree showed equal predictive accuracy (.60 on average), but better accuracy in detecting interactions. We illustrate the application of GLMM trees on an individual patient-level data meta-analysis on treatments for depression. We conclude that GLMM tree is a promising algorithm for the detection of treatment-subgroup interactions in clustered datasets.\\
\\
\textit{Keywords}: model-based recursive partitioning, treatment-subgroup interactions, random effects, generalized linear mixed-effects model, classification and regression trees


\section{Introduction}

In research on the efficacy of treatments for somatic and psychological disorders, the one-size-fits-all paradigm is slowly losing ground, and stratified (or personalized) medicine is becoming increasingly important. Stratified medicine presents the challenge of finding which patients respond best to which treatments. This can be referred to as the detection of treatment-subgroup interactions \cite<e.g., >{DoovyDuss14}. Often, treatment-subgroup interactions are studied using linear models, such as factorial analysis of variance techniques, in which potential moderators have to be specified a-priori, have to be checked one at a time, and continuous moderator variables have to be discretized. This may hamper identification of which treatment works best for whom, especially when there are no a-priori hypotheses about treatment-subgroup interactions. As noted by \citeA{KreayFran06}, there is a need for methods that generate instead of test such hypotheses.

Tree-based methods are such hypothesis-generating methods, as they can automatically detect subgroups which differ in the expected outcomes for one or more treatments. Due to their flexibility, tree-based methods are particularly useful for exploratory purposes, as they can handle many potential predictor variables at once and can automatically detect (higher order) interactions between predictor variables \cite{StroyMall09}. As such, tree-based methods are preeminently suited to the detection of treatment-subgroup interactions. Several tree-based algorithms for the detection of treatment-subgroup interactions have already been developed (\citeNP{DussyDoov15, DussyMeul04, SuyTsai09, FostyTayl11, LipkyDmit11, ZeilyHoth08, SeibyZeil15}; see \citeNP{DoovyDuss14} for an overview). Also, \citeA{ZhanyTsia12Bio,ZhanyTsia12Stat} have developed a flexible classification-based approach, allowing users to select from a range of statistical methods, including trees.

In many instances, researchers may want to detect treatment-subgroup interactions in a generalized linear mixed-effects (GLMM) type model. For example, in individual-level patient data meta-analysis, where datasets of multiple clinical trials on the same treatments are pooled \cite<e.g., >{KoopyHeij07}. In such analyses, the nested or clustered structure of the dataset should be taken into account by including study-specific random effects in the model, prompting the need for a mixed-effects model \cite<e.g., >{CoopyPatt09,HiggyWhit01}. In linear models, ignoring the clustered structure may lead, for example, to biased inference due to underestimated standard errors in linear models \cite<e.g., >{BrykyRaud92,NooryOpde05}. For tree-based methods, ignoring the clustered structure has been found to result in the detection of spurious subgroups and inaccurate predictor variable selection \cite<e.g., >{SelaySimo12, Mart15}. However, none of the purely tree-based methods for treatment-subgroup interaction detection allow for taking into account the clustered structure of a dataset. Therefore, in the current paper, we present a tree-based algorithm which can be used for the detection of (treatment-subgroup) interactions and non-linearities in GLMM type models: generalized linear mixed-effects model trees, or GLMM trees.

The GLMM tree algorithm builds on model-based recursive partitioning (MOB, \citeNP{ZeilyHoth08}), which offers a flexible framework for subgroup detection. For example, GLM-based MOB has been applied to detect treatment-subgroup interactions for the treatment of depression \cite{DrieySmit16} and amyotrophic lateral sclerosis \cite{SeibyZeil15}. In contrast to other purely tree-based methods \cite<e.g., >{ZeilyHoth08, SuyTsai09, DussyMech14}), GLMM tree allows for taking into account the clustered structure of datasets. In contrast to previously suggested regression trees with random effects, GLMM tree allows for treatment effect estimation, with continuous as well as non-continuous response variables \cite<e.g., >{HajjyBell11,SelaySimo12}.

In what follows, we first introduce an artificial motivating dataset, which will be used to illustrate and explain treatment-subgroup interaction detection with GLM-based MOB and GLMM tree. In the Simulation-based Evaluation, we evaluate the performance of GLMM tree in simulated datasets, and compare it with that of GLM-based MOB and GLMMs with pre-specified interaction effects. The comparison with GLM-based MOB allows for assessing the extent to which including random-effects estimation improves the performance of MOB trees. The comparison with GLMMs with pre-specified interactions will allow for assessing the extent to which using a tree-based method will improve detection of treatment-subgroup interactions. In the Application, we apply the algorithm to an existing dataset of a patient-level meta-analysis on the effects of psycho- and pharmacotherapy for depression. Finally, in the Discussion we summarize the results and point out some directions for future research. 


\subsection{Artificial motivating dataset} 

<<artificial-data>>=
set.seed(123)
treatment <- rbinom(n=150,size=1,prob=1/2)
duration <- round(matrix(rnorm(150,mean=5,sd=3),ncol=1))
duration[duration<0] <- 1
anxiety <- round(rnorm(150,mean=10,sd=3))
age <- round(rnorm(150,mean=30,sd=10))
age[age<18] <- 18
age[age>75] <- 75
cutscore1 <- 5+.44*3
cutscore2 <- 10
node1t1 <- ifelse(duration<=cutscore1 & anxiety<=cutscore2 & treatment==0, 1, 0)
node1t2 <- ifelse(duration<=cutscore1 & anxiety<=cutscore2 & treatment==1, 1, 0)
node2t1 <- ifelse(duration<=cutscore1 & anxiety>cutscore2 & treatment==0, 1, 0)
node2t2 <- ifelse(duration<=cutscore1 & anxiety>cutscore2 & treatment==1, 1, 0)
node3t1 <- ifelse(duration>cutscore1 & treatment==0, 1, 0)
node3t2 <- ifelse(duration>cutscore1 & treatment==1, 1, 0)
beta1 <- -2
beta2 <- 0
beta3 <- 2.5
error <- rnorm(150,0,2)
cluster <- error+rnorm(150, 0, 6)
int_values <- rnorm(10, 0, 1)
tmp <- rep(int_values,each=15)
tmp <- tmp[order(tmp)]
rand_int <- rep(NA, times=150)
rand_int[order(cluster)] <- tmp
cluster[order(cluster)] <- rep(1:10, each=15)
cor(error,rand_int)
true_error <- error - rand_int
true_eff <- round(9 + beta1*node1t1 - beta1*node1t2 + beta2*node2t1 - beta2*node2t2 + beta3*node3t1 - beta3*node3t2 + 
     + .4*treatment)
outcome <- round(9 + beta1*node1t1 - beta1*node1t2 + beta2*node2t1 - beta2*node2t2 + beta3*node3t1 - beta3*node3t2 + 
                      + .4*treatment + true_error + rand_int)
outcome[outcome<0] <- 1
example <- data.frame(treatment, outcome, duration, anxiety, cluster, age)
example$treatment <- factor(example$treatment, labels = c("Treatment 1", "Treatment 2"))
@

We created a dataset representing observations on 150 participants in a randomized clinical trial. Every participant was randomly assigned to Treatment~1 or Treatment~2, and has a value for the response variable, with which the effect of treatment is assessed: the posttreatment total score on a depression inventory. For all participants, three covariate values are available: duration of depressive symptoms prior to treatment in months (duration, range 0--15); age in years (age, range 18--75); anxiety inventory total score (anxiety, range 3--18). 

The simulated dataset has 3 subgroups with differential treatment effectiveness. The first subgroup consists of observations with duration $\leq 6$ and anxiety $\leq 10$. In this subgroup, Treatment~1 is more effective than Treatment~2: the mean of the response variable is 7 for Treatment~1, and 11 for Treatment~2. The second subgroup consists of observations with duration $\leq 6$ and anxiety $> 10$. In this subgroup, both therapies are equally effective: the mean value of the response variable is 9 for Treatment~1, and 9 for Treatment~2. The third subgroup consists of observations with duration $>6$. In this subgroup, Treatment~2 is more effective than Treatment~1: the mean value of the response variable is 12 for Treatment~1, and 7 for Treatment~2. 

Participants were part of one of ten clusters, each with a different value for the random intercept. Data were generated such that covariates and cluster-specific intercepts were uncorrelated. 43\% of variance in posttreatment depression scores was due to treatment-subgroup interactions, while 8\% of variance was due to cluster-specific variation. 

See Figure~\ref{fig:example_glimmertree} for the GLMM tree fitted to the simulated data set which recovers the true underlying structure.

<<example-trees>>=
exampleglm <- lmtree(outcome ~ treatment | age, data = example)
exampleglmtree <- lmtree(outcome ~ treatment | age + duration + anxiety, data = example)
exampleglmmtree <- lmertree(outcome ~ treatment | cluster | age + duration + anxiety, data = example)
@

\begin{figure}[t!]
<<exampleglmmtree, fig=TRUE, width=9, height=7>>=
plot(exampleglmmtree)
@
\caption{GLMM tree of the motivating example dataset. Three covariates (anxiety questionnaire score, duration of depressive symptoms at baseline in months and age) were used as potential splitting variables, and the clustering structure was taken into account by estimating random intercepts.}
\label{fig:example_glimmertree}
\end{figure}




\subsection{Model-based recursive partitioning}

The rationale behind MOB is that a global parametric model may not describe the data well, and when additional covariates are available it may be possible to partition the dataset with respect to these covariates, and find a better model in each cell of the partition \cite{ZeilyHoth08}. This is reminiscent of the classification and regression tree (CART) algorithm of \citeA{BreiyFrie84}, which splits the dataset into subsets, for which the distributions of the outcome variable are most different. However, CART trees detect differences in the mean (or median) value across terminal nodes, whereas MOB trees detect differences in parameters of more complex models across terminal nodes. 

For example, let us take a global GLM to estimate the overall treatment effect in the motivating dataset. The expectation $\mu_i$ of outcome $y_i$ given the treatment regressors $x_i$ is modeled through a linear predictor and suitable link function\footnote{An overview of notation used is provided in the appendix.}:
%
\begin{eqnarray}
	\label{eq:expected_value}
	E[y_i | x_i] & = & \mu_i, \\
	\label{eq:fixedeffects}
	g(\mu_{i}) & = & x_{i}^{\top}\beta,
\end{eqnarray}
%
where $x_{i}^{\top}\beta$ is the linear predictor for observation $i$ and $g$ is the link function. $\beta$ is a vector of fixed-effects regression coefficients, the first element representing the intercept, corresponding to the mean value of the linear predictor in the first treatment group, and the second element representing the slope, which is the mean difference in the linear predictor between the first and second treatment groups. Thus, for simplicity we assume $x_{i}$ and $\beta$ to have length 2 in the current paper. Also, for the continuous response variable in the motivating data set, we employ a Gaussian distribution with identity link and denote the error by $\epsilon_i = y_i - \mu_i$ with variance $\sigma_{\epsilon}^2$. However, the model can easily accomodate additional treatment conditions and covariates, and binary or count outcome variables.

\begin{figure}[t!]
\setkeys{Gin}{width=0.5\textwidth}
<<exampleglm, fig=TRUE, height=5, width=5>>=
plot(exampleglm, tp_args = list(mainlab = "Full sample (N = 150)"))
@
\caption{Example of a global GLM for treatment outcomes, based on the artificial motivating dataset ($N=150$). The dot for Treatment~1 represents the first, and the slope of the regression line represents the second element of $\beta$.}
\label{fig:fixedeffects}
\end{figure}

The result of fitting a global GLM to the motivating dataset is depicted in Figure~\ref{fig:fixedeffects}; the boxplots show the distribution of the posttreatment depression scores in both treatment groups. The global model does not describe the data well: there is substantial residual variance and the slope of the regression line is nearly zero. This does not necessarily mean that posttreatment depression score and treatment type are unrelated, as the effect of treatment may be moderated by variables not yet included in the model. 

The MOB algorithm can be used to detect such moderation, by testing for parameter stability over a set of auxiliary covariates, also known as \textit{partitioning variables}. When the partitioning is based on a GLM, instabilities are differences in $\hat{\beta}$ across partitions of the dataset, which are defined by one or more auxiliary covariates not included in the linear predictor. To find these partitions, the MOB algorithm cycles iteratively through the following steps \cite{ZeilyHoth08}: (1) fit the parametric model to the dataset, (2) test for parameter instability over a set of partitioning variables, (3) if there is some overall parameter instability, split the dataset with respect to the variable associated with the highest instability, (4) repeat the procedure in each of the resulting subgroups.

More specifically, in step (2), to test for parameter instability, the so-called \textit{scores} are computed, using the score function. When the model is correctly specified, the expected value of the score for each observation equals zero. Therefore, under the null hypothesis of parameter stability, the scores do not systematically deviate from the expected value of zero, when observations are ordered by the values of a potential partitioning variable $U_k$ \cite<c.f., >{MerkyZeil13}. To statistically test whether the scores systematically deviate from zero with respect to variable $U_k$, the class of generalized M-fluctuation tests is used \cite{Zeil05,ZeilyHorn07}. 

If the null hypothesis of parameter stability in step (2) can be rejected, that is, if at least one of the partitioning variables $U_{k}$ yields a p-value for the M-fluctuation test below the pre-specified significance level $\alpha$, the dataset is partitioned into two subsets in step (3). This partition is created using $U_{k*}$, the variable with the minimal p-value in step (2). The split point for $U_{k*}$ is selected, by taking the value that minimizes the sum of the values of the objective function in both partitions \cite{ZeilyHoth08}. In step (4), steps (1) through (3) are repeated in each partition, until the null hypothesis of parameter stability can no longer be rejected.

Due to the binary recursive nature of MOB, the resulting partition can be represented as a binary tree. If the partitioning is based on a GLM, the result is a GLM tree, with a local fixed-effects regression model in every $j$-th ($j = 1,\dots,J$) terminal node or subgroup:
%
\begin{equation}
	\label{eq:fixedeffects_MOB}
	g(\mu_{ij}) = x_{i}^{\top}\beta_{j}
\end{equation}
%
Note that, if the recursive subgroup structure (i.e., the partition) were known, the tree could be estimated as a single GLM where all $x$-variables interact with the subgroup indicator. Somewhat more formally, the model could then be written: $g(\mu_{i}) = x_{i}^{* \top}\beta^{*}$, where $x_{i}^{*}$ are the values of the $2J$ interactions between the subgroups from the tree, and the elements of $x_{i}$. $\beta^{*}$ would have length $2J$ as well, containing subgroup-specific fixed-effects coefficients.

\begin{figure}[t!]
\setkeys{Gin}{width=\textwidth}
<<exampleglmtree, fig=TRUE, width=12, height=9>>=
plot(exampleglmtree)
@
\caption{Example of a tree representation of model-based recursive partition, based on the artificial motivating dataset. Three additional covariates (anxiety questionnaire score, duration of depressive symptoms at baseline in months and age) were used as potential splitting variables.}
\label{fig:example_mobtree}
\end{figure}

Figure~\ref{fig:example_mobtree} shows the GLM tree grown on the motivating dataset. By using the three auxiliary covariates (anxiety, duration and age), MOB partitioned the observations into four subgroups, each with a different estimate for $\beta_j$. Age was correctly not detected as a partitioning variable, and the left- and rightmost subgroups are in accordance with the true treatment-subgroup interactions described above. However, the two subgroups in the middle do not represent true subgroups, which may be due to the clustered structure of the dataset not being taken into account.


\subsection{Generalized linear mixed-effects model trees}

For datasets containing observations from multiple clusters (e.g., trials or research centers), application of a GLMM would be more appropriate. The model in Equation~\ref{eq:fixedeffects} is then extended to include cluster-specific, or random effects:
%
\begin{equation}
	\label{eq:mixedeffects}
	g(\mu_{i}) = x_{i}^{\top}\beta + z_{i}^{\top}b
\end{equation}
%
Where $z_{i}$ is a unit vector of length $M$, of which the $m$-th element takes a value of 1, and all other elements take a value of 0; $m$ ($m=1,\dots,M$) denotes the cluster which observation $i$ is part of. Further, $b$ is a random vector of length $M$, each $m$th element representing the random intercept for cluster $m$; again, for simplicity we assume that only cluster-specific intercepts are included in the model, but multiple random-effects coefficients can easily be included. Furthermore, within the GLMM, it is assumed that $b$ is normally distributed, with mean zero and variance $\sigma^{2}_{b}$. The parameters of the GLMM can be estimated with, for example, maximum likelihood (ML) and restricted ML (REML).  

Note that, if the random-effects coefficients were known, the model could be estimated by a simple GLM as in Equation \ref{eq:fixedeffects} where $z_{i}^{\top}b$ would only be added as an offset (i.e., a variable with a fixed coefficient of 1) to the linear predictor.

Although the random-effects part of the GLMM in Equation \ref{eq:mixedeffects} accounts for the nested structure of the dataset, the global fixed-effects part may not describe the data well. Therefore, we propose the GLMM tree model, in which the fixed-effects part may be partitioned as in Equation \ref{eq:fixedeffects_MOB} and random effects are incorporated as well: 
%
\begin{equation}
	\label{eq:glimmertree}
	g(\mu_{i}) = x_{i}^{\top}\beta_{j} + z_{i}^{\top}b
\end{equation}
%
To estimate the parameters of this model, we take an approach similar to that of the mixed-effects regression tree (MERT) approach of \citeA{HajjyBell11} and \citeA{SelaySimo12}. In the MERT approach, the fixed-effects part of a GLMM is replaced by a CART tree with constant fits in the nodes, and the random-effects part is estimated as usual. To estimate a MERT, an iterative approach is taken, alternating between (1) assuming random effects known, allowing for estimation of the CART tree, and (2) assuming the CART tree known, allowing for estimation of the random effects. 

For estimating GLMM trees, we take this approach a step further: instead of a CART tree with constant fits to estimate the fixed-effects part of the GLMM, we use a GLM tree. This allows not only for detection of differences in main effects, but also for detection of differences in regression effects (e.g., of treatment type) across terminal nodes. In addition, GLMM trees can be estimated for continuous, as well as binary and count variables. The GLMM tree algorithm takes the following steps to estimate the model in Equation~\ref{eq:glimmertree}:

\begin{description}
  \item[Step 0:] Initialize by setting $r$ and all values $\hat{b}_{(r)}$ to 0.

  \item[Step 1:] Set $r = r+1$. Estimate GLM tree ($x_{i}^{\top}\hat{\beta}_{j(r)}$), with $z_{i}^{\top}\hat{b}_{(r-1)}$ as an offset.

  \item[Step 2:] Estimate random effects in the mixed-effects model $x_{i}^{\top}\hat{\beta}_{j(r)} + z_{i}^{\top}\hat{b}_{(r)}$ with subgroups $j(r)$ from the GLM tree.

  \item[Step 3:] Repeat Steps~1 and~2 until convergence.
\end{description}

The algorithm initializes by setting $b$ to $0$, since the random effects are initially unknown. In every iteration, the GLM tree and coefficients $\beta_{j(r)}$ and $b_{(r)}$ are re-estimated. The GLM tree is estimated, given the estimated random effects from the last iteration, and the random effects are estimated, given the estimated GLM tree from the current iteration. Iterations are continued until convergence, which is monitored by computing the log-likelihood criterion of the mixed-effects model in Equation~\ref{eq:glimmertree}. 

In Figure~\ref{fig:example_glimmertree}, the result of applying the GLMM tree algorithm to the motivating dataset is presented. As already mentioned above, by taking into account the clustering of observations, the true treatment subgroups have been recovered, and the spurious split involving the anxiety variable no longer appears in the tree.



\section{Simulation-based Evaluation: Method}

To assess the performance of GLMM tree, we performed three simulation studies. In Study I, we compared the accuracy of GLMM tree with that of GLM tree in datasets with treatment-subgroup interactions. In Study II, we compared the accuracy of GLMM tree with that of GLM tree in datasets without treatment-subgroup interactions, allowing for assessment of the Type-I error rate. In Study III, we compared the accuracy of GLMM tree with that of a more classical approach of interaction detection: a GLMM with pre-specified interactions. 


\subsection{Software}

R \cite{R14} was used for the generation and analysis of all datasets. The \verb|partykit| package (version 1.0-2; \citeNP{HothyZeil15}) was employed for estimating GLM trees, using the \verb|lmtree| function for normal linear regressions. For other response distributions, the \verb|glmtree| function would be available. For estimation of GLMMs the \verb|lmer| function (or \verb|glmer| function, respectively) from the \verb|lme4| package (version 1.1-7; \citeNP{BateyMeac12}) was employed, using restricted maximum likelihood (REML) estimation.

For estimation of GLMM trees the former two packages were combined in a new package \verb|glmertree| (version 0.1-0; \citeNP{FokkyZeil15}; available from R-Forge). This package provides functions \verb|lmertree| and \verb|glmertree| that iterate between estimation of the \verb|lmtree|/\verb|glmtree| model and the \verb|lmer|/\verb|glmer| model.

In all simulations, the significance level $\alpha$ for the parameter instability tests in the trees was set to .05, with a Bonferroni correction applied for multiple testing. The minimum number of observations per node in the tree was set to 20 and the maximum tree depth was set to four, thus limiting the number of potential subgroups to eight.


\subsection{Simulation design}

\subsubsection{Treatment-subgroup interactions} 
For generating datasets with treatment-subgroup interactions, we used one of the treatment-subgroup interaction designs from \citeA{DussyMech14}, which is depicted in Figure~\ref{fig:modelC}. Figure~\ref{fig:modelC} shows two subgroups with mean differences in treatment outcomes, and two subgroups without mean differences in treatment outcomes. The four subgroups are characterized by values on the (true) partitioning variables $U_2$, and $U_1$ or $U_5$. The other potential partitioning variables ($U_3$, $U_4$, $U_6$ through $U_{15}$) are noise variables.

\begin{figure}[t!]
\setkeys{Gin}{width=0.8\textwidth}
<<dgp-tree, fig=TRUE, height=5, width=7>>=
fig4 <- party(
  partynode(1L,
    split = partysplit(2L, breaks = 30),
    kids = list(
      partynode(2L,
        split = partysplit(1L, breaks = 17),
        kids = list(
          partynode(3L, info = c(
	    expression(''),
	    expression(beta[j0] == '17.5'),
	    expression(''),
	    expression(beta[j1] == -'5.0'),
	    expression(''),
	    expression(d[j] == -'1.0')
	  )),
          partynode(4L, info = c(
	    expression(''),
	    expression(beta[j0] == '30.0'),
	    expression(''),
	    expression(beta[j1] == '0.0'),
	    expression(''),
	    expression(d[j] == '0.0')
	  )))),
      partynode(5L,
        split = partysplit(3L, breaks = 63),
        kids = list(
          partynode(6L, info = c(
	    expression(''),
	    expression(beta[j0] == '30.0'),
	    expression(''),
	    expression(beta[j1] == '0.0'),
	    expression(''),
	    expression(d[j] == '0.0')
	  )),
          partynode(7L, info = c(
	    expression(''),
	    expression(beta[j0] == '42.5'),
	    expression(''),
	    expression(beta[j1] == '5.0'),
	    expression(''),
	    expression(d[j] == '1.0')
	  )))))),
  data.frame(U1 = numeric(0), U2 = numeric(0), U5 = numeric(0))
)
plot(fig4, tp_args = list(FUN = identity, width = 9), tnex = 1.5)
@
\caption{Data-generating model for treatment-subgroup interactions. Parameter $d$ denotes the standardized mean difference between the outcomes of Treatment~1 and~2 (i.e., $\beta_{j1} / \sigma_{\epsilon}$).}
\label{fig:modelC}
\end{figure}


\subsubsection{Continuous interactions}

The subgroups depicted in Figure~\ref{fig:modelC} are piecewise functions of the partitioning variables, therefore these interactions can be referred to as piecewise interactions. However, interactions may also consist of continuous functions of the partitioning variables. For comparing the accuracy of GLMM tree with that of GLMMs with pre-specified interaction terms, we generated datasets in which interactions were varied to be purely piecewise, purely continuous, or a combination of both. To generate purely continuous interactions, the outcome variable $y$ was generated as the sum of: 

\begin{enumerate}
	\item a main effect of $U_2$ (coefficient = 1.5) 
	\item an interaction between $U_1$ and $U_2$ with a negative effect (coefficient = -.25), and an interaction between $U_2$ and $U_5$ with a positive effect (coefficient = .25)
	\item an interaction between $U_1$, $U_2$ and treatment with a negative effect (coefficient = -.25), and an interaction between $U_2$, $U_5$ and the treatment indicator with a positive effect (coefficient = .25)
\end{enumerate}

Note that the direction (positive or negative) and type (main or interaction) of these effects correspond to those in Figure~\ref{fig:modelC}. All interactions were created by using centered $U_k$ variables, calculated by subtracting the variable means. 


\subsubsection{Data-generating parameters} 
In generating datasets, we varied seven parameters of the data-generating process:
 
\begin{enumerate} 
\item Three levels for sample size: $N=200$, $N=500$, $N=1000$.
\item Two levels for the number of potential partitioning covariates $U_1$ through $U_K$: $K=5$, $K=15$ (where only $U_1$, $U_2$ and $U_5$ are true partitioning variables).
\item Two levels of intercorrelations between the covariates $U_1$ through $U_K$: $\rho_{U_k,U_{k'}}=0.0$, $\rho_{U_k,U_{k'}}=0.3$.
\item Three levels for the number of clusters: $M=5$, $M=10$, $M=25$.
\item Three levels for the population standard deviation of the normal distribution from which the cluster specific intercepts were drawn: $\sigma_{b}=0$, $\sigma_{b}=5$, $\sigma_{b}=10$.
\item Three levels for the intercorrelations between $b$ and one of the $U_k$ variables: $b$ and $U_k$ uncorrelated, $b$ correlated with a true partitioning variable (i.e., $U_2$, $U_1$, or $U_5$, introducing a correlation of $\approx 0.42$), $b$ correlated with a non-partitioning covariate (i.e., $U_3$ or $U_4$, introducing a correlation of $\approx 0.42$)\footnote{Note that, when $\sigma_b = 0$, the correlation between $b$ and one of the $U_k$ variables is 0, by definition. However, datasets were created for this condition, to allow for a full factorial design of the simulation study; in reality, $b$ and $U$ are uncorrelated in these instances.}. 
\item Two levels for $\beta_{j1}$, the unstandardized mean difference in treatment outcomes. In datasets with treatment-subgroup interactions, the treatment effect difference varied only in nodes 4 and 7, with levels $|\beta_{j1}| = 2.5$ (corresponding to a medium effect size, Cohen's $d = 0.5$; \citeNP{Cohe92}) and $|\beta_{j1}| = 5.0$ (corresponding to a large effect size; Cohen's $d = 1.0$). 
\end{enumerate}


\subsubsection{Variable distributions}
Following the approach of \citeA{DussyMech14}, all covariates $U_1$ through $U_{K}$ were drawn from a multivariate normal distribution with means ${\mu_U}_1 = 10$, ${\mu_U}_2 = 30$, ${\mu_U}_4 = -40$, and ${\mu_U}_5 = 70$. The means for all other covariates (i.e., ${\mu_U}_3$, and ${\mu_U}_6$ through ${\mu_U}_{15}$) were drawn from a discrete uniform distribution on the interval $[-70,70]$. All covariates $U_1$ through $U_{15}$ have the same standard deviation: ${\sigma_U}_k = 10$. Correlations between $U$ variables vary according to the third facet of the data-generating design described above. 

To generate the cluster-specific intercepts $b_m$, we partitioned the sample into equally-sized clusters, conditional on one of the variables $U_1$ through $U_5$, producing the correlations in the sixth facet of the simulation design. For each cluster, a single value $b_m$ was drawn from a normal distribution with mean 0 and the value of $\sigma_{b}$ given by the fifth facet of the simulation design. When $b$ was correlated with one of the potential partitioning variables, this variable was randomly selected.

To generate node-specific fixed effects, we partitioned the sample according to the terminal nodes of the tree in Figure 4.3. In combination with the seventh facet of the simulation design, this determines the values of $\beta_j$. For every observation, we generated a binomial variable (with probability .5) as an indicator for treatment type. Random errors $\epsilon$ were drawn from a normal distribution with $\mu_{\epsilon} = 0$ and $\sigma_{\epsilon} = 5$. 

Finally, the response variable was calculated as the sum of the (node-specific) fixed effects, the random intercept and the error term: $y_{i} = x_{i}^{\top} \beta_{j} + z_{i}^{\top} b_{m} + \epsilon_{i}$.


\subsubsection{Assessment of performance} 

Firstly, the total number of nodes in estimated GLM and GLMM tree were calculated to assess the extent to which the algorithms may detect spurious subgroups. Also, the number of nodes allow for assessing Type-I (the extent to which datasets are erroneously partitioned) and Type-II (the extent to which datasets are erroneously not partitioned) error.

Secondly, in datasets with treatment-subgroup interactions, we assessed the accuracy of estimated models. For GLM and GLMM trees, an accurately recovered tree was defined as a tree with (1) the true tree size (i.e., tree size $= 7$ in datasets with treatment-subgroup interactions), (2) the first split in the tree involving variable $U_2$ and a value of $30 \pm 5$, (3) the next split on the left involving variable $U_1$ and a value of $17 \pm 5$, and (4) the next split on the right involving variable $U_5$ and a value of $63 \pm 5$. Note that the allowance of $\pm 5$ equals an allowance of plus or minus half the population standard deviation of the partitioning variable ($\sigma_{U_k}$). 

Predictive accuracy of each method was assessed by calculating the correlation between true and predicted treatment-effect differences ($\beta_{j1}$ in Figure~\ref{fig:modelC}) in each dataset. Consequently, predictive accuracy was only assessed in datasets with treatment-subgroup interactions, as the true treatment differences have a constant value in datasets without treatment-subgroup interactions. To prevent overly optimistic estimates of predictive accuracy \cite{HastyTibs09}, predictive accuracy was assessed using test datasets. Test datasets were generated from the same population as training datasets, but test observations were not drawn from the same clusters as the training observations, but from `new' clusters.



\section{Simulation-based Evaluation: Results}

\subsection{Study I: Detection of Treatment-Subgroup Interactions}

For each cell of the data-generating design described above, 50 datasets were generated, resulting in $50 \times 3 \times 2 \times 2 \times 3 \times 3 \times 3 \times 2$ = 32,400 training datasets with treatment-subgroup interactions. In these datasets, the true tree size was 7 (4 terminal nodes and 3 inner nodes; Figure~\ref{fig:modelC}).

<<simulation-data>>=
load("treespecs_long.dat")
treespecs.long$N <- factor(as.numeric(as.character(treespecs.long$N)), ordered=T)
treespecs.long$sigmab <- factor(as.numeric(as.character(treespecs.long$sigmab)), ordered=T)
treespecs.long$treatdiff <- factor(as.numeric(as.character(treespecs.long$treatdiff)), ordered=T)
treespecs.long$truetree.values <- as.numeric(treespecs.long$truetree.values)-1
levels(treespecs.long$corUb)[levels(treespecs.long$corUb)=="bi and splitting U correlated"] <- "b correlated with splitting U"
levels(treespecs.long$corUb)[levels(treespecs.long$corUb)=="bi and non-splitting U correlated"] <- "b correlated with non-splitting U"
levels(treespecs.long$corUb)[levels(treespecs.long$corUb)=="uncorrelated"] <- "b and U uncorrelated"
treespecs.long <- treespecs.long[treespecs.long$correlation.ind!="GLMM",]
treespecs.long$correlation.ind <- factor(treespecs.long$correlation.ind)
treespecs.long$treesize.ind <- factor(treespecs.long$treesize.ind)
@

\begin{figure}[t!]
<<treesize-xyplot, fig=TRUE, width=9, height=9>>=
aggdata.size <- aggregate(formula=treesize.values ~ treesize.ind + N + sigmab + corUb, FUN=mean, data=treespecs.long)	
print(xyplot(treesize.values ~ sigmab | N + corUb, data = aggdata.size, groups=treesize.ind, 
type="b", ylab="tree size", xlab=expression(sigma[b]), par.settings=standard.theme("pdf",color=F), 
abline=c(7,0), auto.key=list(space="top", columns=2, title=" ", cex.title=1,lines=T, points=T))
)
@
\caption{Average tree size of GLM and GLMM trees for datasets with treatment-subgroup interactions. Rows represent levels of dependence between random effects ($b$) and one of the partitioning variables $U_k$; columns represent levels of sample size.}
\label{fig:xyplot_treesize_interact}
\end{figure}


\subsubsection{Tree size} 

GLMM tree yielded trees with an average size of 7.15 nodes ($\mathrm{SD}=0.61$), whereas GLM tree yielded an average tree size of 8.15 nodes ($\mathrm{SD}=2.05$), indicating that GLM trees involved more spurious splits than GLMM trees, on average. The estimated probability that a dataset was erroneously not partitioned (the Type-II error) was 0 for both algorithms.

To find the most important predictors of tree size, we performed an ANOVA with algorithm type and the parameters of the data-generating process as independent variables. First-order interactions between algorithm type and each of the data-generating parameters were also included. The most important predictors of tree size were algorithm type, sample size, variance of the random intercept, and the correlation between partitioning variables. These effects were further assessed by means of a graphical display (Figure~\ref{fig:xyplot_treesize_interact}). 

Figure~\ref{fig:xyplot_treesize_interact} indicates that GLMM tree grows trees of about the true tree size in all conditions. On average, tree size increases slightly with sample size for GLMM tree, and dramatically for GLM tree. In the absence of random effects (i.e., $\sigma_{b}=0$), GLM and GLMM trees grow trees of about the same size. However, clear differences in tree size were observed when $\sigma_b > 0$. When sample size is small and random intercepts are not correlated with a partitioning covariate, GLM tree lacks power and grows trees that are too small, on average. When sample size is larger and random intercepts are not correlated with a partitioning covariate, GLM and GLMM trees are about equally sized. However, when random intercepts are correlated with a partitioning covariate, GLM starts to create spurious splits, especially with larger sample sizes (i.e., 500 or 1000) and larger $\sigma_b$ values (i.e., 10). This effect was somewhat stronger when the random intercept was correlated with a covariate that did not appear in the true tree. 

\begin{figure}[t!]
<<accuracy-xyplot, fig=TRUE, width=9, height=9>>=
aggdata.acc <- aggregate(formula=truetree.values ~ correlation.ind + N + sigmab + corUb, FUN=mean, data=treespecs.long)
print(xyplot(truetree.values ~ sigmab | N + corUb, data = aggdata.acc, groups=correlation.ind, type="b", 
ylab="tree accuracy", xlab=expression(sigma[b]), par.settings=standard.theme("pdf",color=FALSE), 
auto.key=list(space="top", columns=2, title=" ", cex.title=1,lines=TRUE, points=TRUE))
)
@
\caption{Tree accuracy of GLM and GLMM tree. Tree accuracy is defined as the proportion of datasets in which the true tree was accurately recovered. Rows represent levels of dependence between random effects ($b$) and one of the partitioning variables $U_k$, columns represent levels of sample size.}
\label{fig:xyplot_treeaccuracy}
\end{figure}


\subsubsection{Accuracy of recovered trees}

To assess the accuracy of trees recovered by both algorithms, we inspected variables and values that were selected for partitioning. For the first split, GLMM tree selected the true partitioning variable ($U_2$) in all datasets, and GLM tree in all but one datasets. The splitting value for $U_2$ selected for the first split was 29.94 for both GLM and GLMM tree, which is very close to the true splitting value of 30 (Figure~\ref{fig:modelC}).

However, further splits were more accurately recovered by GLMM tree, which accurately recovered the partition in 90.40\% of datasets, and GLM tree in only 61.44\% of datasets. To find the most important predictors of tree accuracy, we fitted a GLM with algorithm type and the parameters of the data-generating process as independent variables. First-order interactions between algorithm type and each of the data-generating parameters were also included. The most important predictors of tree accuracy were algorithm type, sample size, variance of the random intercept, and the level of dependence between the partitioning variables and the random intercept. These effects were further assessed by means of a graphical display (Figure~\ref{fig:xyplot_treeaccuracy}). 

Figure~\ref{fig:xyplot_treeaccuracy} indicates that in the absence of random effects, the trees recovered by GLM and GLMM tree were about equally accurate. In the presence of random effects, GLM trees were much less accurate than GLMM trees. This was found for all sample sizes, when random effects were correlated with a partitioning covariate. This effect was somewhat stronger when the correlated $U_k$ was not a true partitioning variable. However, when random intercepts were not correlated with one of the $U_k$ variables, GLMM tree outperformed GLM tree only when sample size was small (i.e., $N = 200$).


\begin{figure}[t!]
<<correlation-xyplot, fig=TRUE, width=9, height=7>>=
aggdata.cor <- aggregate(formula=correlation.values ~ correlation.ind + N + sigmab + treatdiff, FUN=mean, data=treespecs.long)
print(xyplot(correlation.values ~ sigmab | N + treatdiff, data = aggdata.cor, groups=correlation.ind, 
type="b", ylab="correlation", xlab=expression(sigma[b]), par.settings=standard.theme("pdf",color=F), 
auto.key=list(space="top", columns=2, title=" ", cex.title=1,lines=T, points=T),
scales=list(y=list(limits = c(0,1))))
)
@
\caption{Average predictive accuracy of GLM and GLMM trees. Predictive accuracy of trees is defined as the correlation between the true and predicted differences between Treatment~1 and~2. Rows represent the levels of the absolute value of the unstandardized treatment-effect difference in subgroups with treatment-effect differences, columns represent levels of sample size.}
\label{fig:xyplot_correlations}
\end{figure}

\subsubsection{Predictive accuracy of trees}
The predicted treatment-effect differences of GLMM tree were closer to the true differences than those of GLM tree, with a mean correlation of .93 ($\mathrm{SD}=0.12$) for GLMM tree and .88 ($\mathrm{SD}=0.19$) for GLM tree. An ANOVA indicated that the most important predictors of predictive accuracy were algorithm type, sample size, variance of the random intercept, and the treatment-difference effect size. These effects were further assessed by means of a graphical display (Figure~\ref{fig:xyplot_correlations}). 

Figure~\ref{fig:xyplot_correlations} shows clear main effects of sample size and treatment-effect differences for both algorithms. In the absence of random effects (i.e., $\sigma_b = 0$), predictions of GLM and GLMM tree were about equally accurate. In the presence of random effects, GLM tree predictions were clearly less accurate than those of GLMM tree when treatment-effect differences were smaller (i.e., Cohen's $d = .5$). This effect was also observed, but much less pronounced, when treatment-effect differences were larger (i.e., Cohen's $d = 1.0$). In other words, GLMM tree outperforms GLM tree in the presence of random effects, especially when sample size and treatment-effect differences are smaller.




\subsection{Study II: Type-I error}

\subsubsection{Design}
In addition to the accuracy of treatment-subgroup interaction detection, we assessed the Type-I error: the extent to which datasets without treatment-subgroup interactions may erroneously be partitioned. For assessing Type-I error of GLM and GLMM tree, we generated datasets without treatment-subgroup interactions, in which there was only a main effect of treatment in the population. Put differently, there was only a single global value of $\beta_j = \beta$ in every dataset. For these datasets, we varied the same parameters of the data-generating process as in Study I. However, the sixth facet of the data-generating process had only two levels for these datasets, as there were no `true' partitioning variables in these datasets. Therefore, $50 \times 3 \times 2 \times 2 \times 3 \times 3 \times 2 \times 2$ = 21,600 datasets without treatment-subgroup interactions were generated.

\subsubsection{Tree size and Type-I error}
In datasets without treatment-subgroup interactions, average tree size was 1.09 ($\mathrm{SD}=0.44$) for GLMM tree, and 2.02 ($\mathrm{SD}=1.68$) for GLM tree. The overall Type-I error rate was only .04 for GLMM tree, and .33 for GLM tree. Again, main predictors of tree size were found to be sample size, variance of the random intercepts, and dependence between the random intercept and one of the partitioning variables. These effects were further assessed by means of a graphical display (Figure~\ref{fig:xyplot_treesize_nointeract}). Figure~\ref{fig:xyplot_treesize_nointeract} indicates that in the absence of random effects (i.e., $\sigma_{b}=0$), both GLM and GLMM tree tend to create trees of size 1. In the presence of random effects, GLMM tree still tends to create trees of size 1, but GLM tree creates much larger trees, when the random effects are correlated with one of the partitioning covariates. This effect increases with sample size. 

\begin{figure}[t!]
<<treesize-nointeract-xyplot, fig=TRUE, width=9, height=7>>=
load("noint_treesizes_long.dat")
treesizes.long$sigmabm <- factor(as.numeric(as.character(treesizes.long$sigmabm)), ordered = TRUE)
treesizes.long$N <- factor(as.numeric(as.character(treesizes.long$N)), ordered = TRUE)
aggdata <- aggregate(formula=treesize.values ~ treesize.ind + N + sigmabm + corUbm, FUN=mean, data=treesizes.long)
print(xyplot(treesize.values ~ sigmabm | N + corUbm, data = aggdata, groups=treesize.ind, 
type="b", ylab="tree size", xlab=expression(sigma[b]), par.settings=standard.theme("pdf",color=FALSE), 
abline=c(1,0), auto.key=list(space="top", columns=2, title=" ", cex.title=1, 
lines=TRUE, points=TRUE)))
@
\caption{Average tree size of GLM and GLMM trees for datasets without treatment-subgroup interactions. Rows represent dependence between random effects ($b$) and one of the partitioning variables $U_k$; columns represent sample size.}
\label{fig:xyplot_treesize_nointeract}
\end{figure}



\subsection{Study III: Piecewise vs. Continuous Interactions}

\subsubsection{Design}

To compare the performance of GLMM tree with that of GLMMs with pre-specified interaction effects, we created datasets in which interactions were varied from purely continuous to purely piecewise. For these datasets, the seventh facet of the interaction design (effect size of treatment differences) was replaced by a factor with three levels, controlling the type of interactions: purely continuous interactions, purely piecewise interactions, and a combination of both. Purely continuous interactions were generated as described above, in the Method section. To allow for a smooth transition from purely continuous to purely continuous interactions, we aimed to keep the proportion of variance explained by each of the covariates equal across piecewise, continuous and combined interactions. Therefore, for piecewise interactions, we used the partition depicted in Figure 4, but not the coefficients. The coefficients used for data-generation were replaced by the subgroup-specific means, given purely continuous interactions. To generate the combined conitnuous and piecewise interactions, $y$ values according to the purely piecewise and continuous interaction models were summed and divided by 2.

Furthermore, in this simulation study, the number of cells in the simulation design was reduced by limiting the fourth facet of the data-generating design to a single level ($M=25$ clusters), as the earlier simulations indicated no effects of the number of clusters. The fifth facet of the data-generating design was limited to two levels ($\sigma_b = 2.5$ and $\sigma_b = 7.5$). As in Study II, we limited the sixth facet to two levels (the random intercept was either correlated to one of the covariates, or not). To counter unidentifiability due to potentially large numbers of pre-specified interaction terms in the GLMMs, the second level of the second facet (number of potential partitioning covariates) was set to $k=10$, instead of the value of $k=15$ used in the earlier simulations. As a result, $50 \times 3 \times 2 \times 2 \times 1 \times 2 \times 2 \times 3$ = 7,200 training datasets were generated for this study.

GLMMs were estimated by specifying main effects for all covariates $U_k$ and the treatment indicator, first-order (or two-way) interactions between all pairs of covariates $U_k$, and second-order (or three-way) interactions between all pairs of covariates $U_k$ and treatment. Accurately recovered GLMMs were defined to be models in which significant (i.e., absolute value of the $t$-test statistic $\geq 1.96$) effects were found for $U_2$ and (treatment) interactions of $U_1$ and $U_2$ and $U_2$ and $U_5$. Accurately recovered GLMM trees were defined to be trees in which the first split involved $U_2$, the second split to the right involved $U_1$ and the third split to the right involved $U_5$. Note that this criterion of accuracy is somewhat more lenient than in Study I.

<<linear-simulation-data>>=
load("pw_treespecs_long.dat")
treespecs.long$N <- factor(as.numeric(as.character(treespecs.long$N)), ordered=T)
treespecs.long$sigmab <- factor(as.numeric(as.character(treespecs.long$sigmab)), ordered=T)
treespecs.long$type <- factor(treespecs.long$type, ordered = TRUE, levels = 
c("continuous", "both", "piecewise"))
@


\subsubsection{Accuracy of recovered models}

Overall, GLMM tree accurately recovered main and interaction effects in 53.58\% of datasets, wheareas GLMMs accurately recovered main and interaction effects in 34.81\% of datasets. To find the most important predictors of model accuracy, we performed an ANOVA, in which the algorithm type, sample size, the number of covariates and type of interaction (continuous, piecewise or both) were found to be most important. These effects were further assessed by means of the graphical display depicted in Figure~\ref{fig:xyplot_accuracy_pw}.

Figure~\ref{fig:xyplot_accuracy_pw} shows a clear effect of interaction type: GLMM tree performs best in datasets with purely piecewise interactions, and poorest in datasets with purely continuous interactions. GLMMs perform best in datasets with purely continuous interactions, and poorest in datasets with purely piecewise interactions. Figure~\ref{fig:xyplot_accuracy_pw} also shows a clear effect of the number of covariates: with a large number of covariates, GLMMs never recover all true effects in the dataset, whereas they always recover the true effects when the number of covariates is small and interaction effects are at least partly continuous. At the same time, the accuracy of GLMM tree is unaffected by the number of covariates. Finally, the performance of both GLMM tree and GLMMs is affected by sample size: the effects are more often recovered in datasets with larger sample sizes. 

\begin{figure}[t!]
<<accuracy-pw-xyplot, fig=TRUE, width=9, height=7>>=
aggdata.acc <- aggregate(formula=truevars ~ truevars.ind + N + type + np, FUN=mean, 
data=treespecs.long)
xyplot(truevars ~ type | N + np, data = aggdata.acc, groups=truevars.ind, type="b",
ylab="proportion of accurately recovered models", xlab="interaction type", par.settings=standard.theme("pdf",color=F), 
auto.key=list(space="top", columns=2, title=" ", cex.title=1,lines=T, points=T))
@
\caption{Model accuracy for GLMMs and GLMM trees. In an accurate model, the true main and interaction effects were accurately recovered. Columns represent sample size, rows represent the number of covariates in the model.}
\label{fig:xyplot_accuracy_pw}
\end{figure}



\subsubsection{Predictive accuracy}


\begin{figure}[t!]
<<correlation-pw-xyplot, fig=TRUE, width=9, height=7>>=
aggdata.cor <- aggregate(formula=correlation.values ~ correlation.ind + np + type + N, FUN=mean, 
data=treespecs.long)
xyplot(correlation.values ~ type | N + np, data = aggdata.cor, groups=correlation.ind, type="b",
ylab="correlation", xlab="interaction type", par.settings=standard.theme("pdf",color=F), 
auto.key=list(space="top", columns=2, title=" ", cex.title=1,lines=T, points=T))
@
\caption{Average predictive accuracy of GLMMs and GLMM trees. Predictive accuracy of trees is defined as the correlation between the true and predicted differences between Treatment~1 and~2. Columns represent sample size, rows represent the number of covariates.}
\label{fig:xyplot_correlation_pw}
\end{figure}

Both algorithms showed about equal average correlations between the true and predicted treatment-effect differences: average accuracy was .60 (SD = .36) for GLMMs and .60 (SD = .32) for GLMM trees. In terms of bias, GLMM treatment-effect difference predictions deviated more from the true values than the predictions of GLMM tree. The mean true treatment-effect difference averaged over all datasets was .04 (SD = 1.22), whereas the mean predicted treatment-effect differences averaged over all datasets for GLMMs were -.26 (SD = 100.33) and for GLMM trees .03 (SD = 3.88). Furthermore, it should be noted that the predictive models for GLMM trees were simpler than those of the GLMMs. Predictions for GLMMs in datasets with 10 covariates involved 11 (significant or non-significant) main effects, 100 first-order interactions and 100 second-order interactions. Predictions for GLMM tree involved a maximum  of only 8 terminal nodes, as their maximum depth was restricted. 

The most important predictors of predictive accuracy were algorithm type, sample size, the number of covariates, and type of interaction (continuous, piecewise or both). These effects were further assessed by means of the graphical display depicted in Figure~\ref{fig:xyplot_correlation_pw}. As Figure~\ref{fig:xyplot_correlation_pw} indicates, GLMM trees show highest predictive accuracy in datasets with purely piecewise interactions, whereas GLMMs show highest predictive accuracy in datasets with purely continuous interactions. Furthermore, performance of GLMM tree is hardly affected by the number of covariates, whereas the predictive accuracy of GLMMs deteriorates when the number of covariates increases. This indicates that GLMM tree may be especially useful for exploratory purposes.

\FloatBarrier




\section{Application: Individual patient-level meta-analysis dataset on treatments for depression}

<<depression-data>>=
metadata <- read.dta("Database IPDMA CBT PHA Version 11.dta")
metadata[metadata == 999] <- NA
metadata[metadata == 888] <- NA
vars <- c("studyid", "Tx_group", "Age", "Gender", "education", "ComorbidAnxietyDisorder", "HRSDt0", "HRSDt1")
factors <- c("studyid", "Tx_group", "Gender", "education", "ComorbidAnxietyDisorder")
metadata$education <- factor(metadata$education, ordered = TRUE)
for (i in 1:length(factors)) {metadata[, factors[i]] <- factor(metadata[,factors[i]])}
metadata <- metadata[vars] # select only relevant variables
metadata <- metadata[complete.cases(metadata[, vars]), ] # select only complete data
metadata <- metadata[!metadata$Tx_group == "placebo", ] # remove placebo observations
metadata$Tx_group <- factor(metadata$Tx_group)
@



\subsection{Method}

To further illustrate the use of GLM and GLMM tree, we applied both algorithms to a dataset from a individual-patient data meta-analysis of \citeA{CuijyWeit14}. This meta-analysis was based on patient-level observations from 14 RCTs, comparing the effects of psychotherapy (cognitive behavioral therapy; CBT) and pharmacotherapy (PHA) in the treatment of depression. The study of \citeA{CuijyWeit14} was aimed at establishing whether gender is a predictor or moderator of the outcomes of psychological and pharmacological treatments for depression. Treatment outcomes were assessed by means of the 17-item Hamilton Rating Scale for Depression (HAM-D; \citeNP{Hami60}). \citeA{CuijyWeit14} found no indication that gender predicted or moderated treatment outcomes. Further details on the dataset can be found in \citeA{CuijyWeit14}.

In our analyses, posttreatment HAM-D score was the outcome variable, and potential partitioning variables were age, gender, level of education, presence of a comorbid anxiety disorder at baseline, and pretreatment HAM-D score. The predictor variable in the linear model was treatment type (0 = CBT and 1 = PHA). An indicator for study was used as the cluster indicator.

In RCTs, ANCOVAs are often employed, to linearly control posttreatment values on the outcome measure for pretreatment values. Therefore, we estimated the GLM and GLMM trees using posttreatment HAM-D scores, controlled for the linear effects of pretreatment HAM-D scores. The trees were grown using data of patients with complete observations; that is, observations with non-missing values for potential partitioning variables, and pre- and posttreatment HAM-D score. As a result, data from 694 patients from 7 studies were included in the analyses. Results of our analysis may therefore not be representative of the complete dataset of the meta-analysis by \citeA{CuijyWeit14}. 

To provide a standardized estimate of the treatment effect differences in the final nodes of the trees, we calculated node-specific Cohen's $d$ values. Cohen's $d$ was calculated by dividing the node-specific predicted treatment outcome difference by the node-specific pooled standard deviation. Confidence intervals for Cohen's $d$ could not be calculated, as these can not take into account the exploratory nature of our analyses (i.e., variable and split point selection). The predictive accuracy of GLM and GLMM trees was assessed by calculating average correlations between observed and predicted HAM-D posttreatment scores, based on 50-fold cross validation.

The results of recursive partitioning techniques are known to be potentially unstable, in the sense that small changes in the dataset may substantially alter the variables or values selected for partitioning. Therefore, we used the R-package \verb|stablelearner| \cite{PhilyZeil16} to assess the stability of the selected splitting variables and values. Using the \verb|stabletree| function, we calculated the number of times a variable and value were selected for partitioning, over 500 subsamples of size $.9 \times N$ of the dataset.  

<<depression-trees>>=
## offset
metadata$HRSDfit <- fitted(lm(HRSDt1 ~ HRSDt0, data = metadata))

## GLM tree
lmtree_app <- lmtree(HRSDt1 ~ Tx_group | Age + Gender + education + ComorbidAnxietyDisorder + HRSDt0,
  data = metadata, offset = HRSDfit)

## GLMM tree
lmertree_app <- lmertree(HRSDt1 ~ Tx_group | (1 | studyid) + offset(HRSDfit) | Age + Gender + education + ComorbidAnxietyDisorder + HRSDt0,
  data = metadata, ranefstart = metadata$HRSDfit)
 
## GLM tree with effect sizes: 
GLMtree_app_eff <- party(
	partynode(1L,
		split = partysplit(1L, breaks = 2), kids = list(
			partynode(2L, info = c(
				expression(''),
				expression(widehat(mu)[CBT] == '13.25'),
				expression(''),
				expression(widehat(mu)[PHA] == '10.29'),
				expression(''),
				expression(widehat(sigma)[pooled] == '7.52'),
				expression(''),
				expression(widehat(d) == '0.39'),
				expression(''))),
			partynode(3L, split = partysplit(2L, breaks = 1), kids = list(
				partynode(4L, info = c(
				expression(''),
				expression(widehat(mu)[CBT] == '7.82'),
				expression(''),
				expression(widehat(mu)[PHA] == '7.55'),
				expression(''),
				expression(widehat(sigma)[pooled] == '5.51'),
				expression(''),
				expression(widehat(d) == '0.05'),
				expression(''))),
			partynode(5L, info = c(
				expression(''),
				expression(widehat(mu)[CBT] == '10.35'),
				expression(''),
				expression(widehat(mu)[PHA] == '7.69'),
				expression(''),
				expression(widehat(sigma)[pooled] == '6.64'),
				expression(''),
				expression(widehat(d) == '0.40'),
				expression(''))))))),
	data.frame(education = metadata$education, ComorbidAnxietyDisorder = metadata$ComorbidAnxietyDisorder)
)

## GLMM tree with effect sizes:
GLMMtree_app_eff <- party(
	partynode(1L,
		split = partysplit(2L, breaks = 1), kids = list(
			partynode(2L, info = c(
				expression(''),
				expression(widehat(mu)[CBT] == '8.27'),
				expression(''),
				expression(widehat(mu)[PHA] == '7.99'),
				expression(''),
				expression(widehat(sigma)[pooled] == '5.86'),
				expression(''),
				expression(widehat(d) == '0.05'),
				expression(''))),
			partynode(3L, info = c(
				expression(''),
				expression(widehat(mu)[CBT] == '10.84'),
				expression(''),
				expression(widehat(mu)[PHA] == '8.21'),
				expression(''),
				expression(widehat(sigma)[pooled] == '6.80'),
				expression(''),
				expression(widehat(d) == '0.39'),
				expression(''))))),
	data.frame(education = metadata$education, ComorbidAnxietyDisorder = metadata$ComorbidAnxietyDisorder)
)
@


\begin{figure}[t!]
\setkeys{Gin}{width=0.75\textwidth}
<<depression-glmtree, fig=TRUE, height=6, width=8>>=
plot(lmtree_app)
@
<<depression-glmtree-effs, fig=TRUE, height=6, width=8>>=
plot(GLMtree_app_eff, tp_args = list(FUN = identity, height = 10, width = 14), tnex = 1.5)
@
\caption{Upper panel: GLM tree for prediction of posttreatment total scores on the Hamilton Rating Scale for Depression (HAM-D). The y-axes of the boxplots represent posttreatment HAM-D scores, and the x-axes represent treatment levels: cognitive behavior therapy (CBT) vs.\ pharmacotherapy (PHA). Lower panel: Subgroup-specific descriptive statistics.}
\label{fig:lmtree_C&W}
\end{figure}


\subsection{Results}

The tree and effects sizes resulting from application of GLM tree are presented in Figure~\ref{fig:lmtree_C&W}. Those resulting from application of GLMM tree are presented in Figure~\ref{fig:lmertree_C&W}. 

The GLM tree (Figure~\ref{fig:lmtree_C&W}) selected level of education as the first partitioning variable, and presence of a comorbid anxiety disorder as a second partitioning variable, for observations with a higher level of education. By taking into account study-specific intercepts, the GLMM tree (Figure~\ref{fig:lmertree_C&W}) indicates that the first split made by GLM tree may be a spurious one. The GLMM tree selected presence of a comorbid anxiety disorder as the only partitioning variable. The terminal nodes of Figure~\ref{fig:lmertree_C&W} show only a single treatment-subgroup interaction: for patients without a comorbid anxiety disorder, CBT and PHA provide more or less the same reduction in HAM-D scores (Cohen's $d = 0.05$; Figure~\ref{fig:lmertree_C&W}). For patients with a comorbid anxiety disorder, PHA provides a greater reduction in HAM-D scores (Cohen's $d = 0.39$; Figure~\ref{fig:lmertree_C&W}). The estimated intraclass correlation coefficient for the GLMM tree was .05. 

Assessment of predictive accuracy by means of 50-fold cross validation indicated better predictive accuracy for GLMM tree than GLM tree. The correlation between true and predicted posttreatment HAM-D total scores, averaged over the 50 folds, was .28 ($\mathit{var}=.067$) for GLMM tree, and .19 ($\mathit{var}=.084$) for GLM tree. This indicates that GLMM tree provided higher predictive accuracy, and also somewhat lower variability of predictive accuracy than GLM tree. 

Table \ref{tab:stability} presents statistics on the variables selected for partitioning in subsamples of the dataset. Note that the selection frequencies do not add up to 1, as trees may involve multiple, or no splits. Table \ref{tab:stability} indicates that the presence of a comorbid anxiety disorder was selected for partitioning in the majority ofGLMM trees grown on subsamples of the dataset, and all other variables were selected in less than 3\% of the subsamples. As the comorbid anxiety disorder variable involved only a single splitting value, further assessment of the stability of splitting values was not necessary.


\begin{figure}
\setkeys{Gin}{width=0.5\textwidth}
<<depression-glmmtree, fig=TRUE, height=4, width=4.7>>=
plot(lmertree_app)
@
<<depression-glmmtree-effs, fig=TRUE, height=4, width=4.7>>=
plot(GLMMtree_app_eff, tp_args = list(FUN = identity, height = 10, width = 14), tnex = 1.5)
@
\caption{Left panel: GLMM tree for prediction of posttreatment total scores on the Hamilton Rating Scale for Depression (HAM-D). The y-axes of the boxplots represent posttreatment HAM-D scores, and the x-axes represent treatment levels: cognitive behavior therapy (CBT) vs.\ pharmacotherapy (PHA). Right panel: Subgroup-specific descriptive statistics.}
\label{fig:lmertree_C&W}
\end{figure}





\begin{table}
	\small
	\caption{Variable selection statistics}
	\begin{tabular}{lcc}
		\thickline
		&	\multicolumn{2}{c}{Selection frequency} \\
		Variable				&	GLM tree&	GLMM tree	\\
		\hline
		Education               &	.956	&	.014		\\
		ComorbidAnxietyDisorder	&	.398	&	.528		\\
		HRSDt0                  &	.034	&	.002		\\
		Age                     &	.000	&	.022		\\
		Gender                  &	.002	&	.004		\\
		\hline
		\multicolumn{3}{l}{\textit{Note.} Frequencies are calculated over 500 random}\\
		\multicolumn{3}{l}{subsamples of the complete dataset. Frequencies}\\
		\multicolumn{3}{l}{do not add up to 1, as trees may involve multiple}\\
		\multicolumn{3}{l}{or no splits.}\\
	\end{tabular}
	\label{tab:stability}
\end{table}


\FloatBarrier

\section{Discussion}

In the current paper, we presented the GLMM tree algorithm, which allows for estimation of a GLM-based recursive partition, as well as estimation of random-effects parameters. As such, we hypothesized GLMM tree to be well suited for the detection of treatment-subgroup interactions in clustered datasets, which was confirmed by our simulation studies. We performed simulation studies to assess the accuracy of GLMM tree in detecting treatment-subgroup interactions and illustrated the application of GLMM tree on an existing dataset.

GLMM tree performed very well in recovering treatment-subgroup interactions, accurately recovering interactions in 90\% of datasets with treatment-subgroup interactions. In contrast, GLM tree accurately recovered interactions in only 61\% of these datasets. In the absence of treatment-subgroup interactions, GLMM tree erroneously detected subgroups in 4\% of the datasets, whereas GLM tree erroneously detected subgroups in 33\% of those datasets. Put differently, the Type-I error rate of GLMM tree very closely approximated the $\alpha$ level used for testing parameter stability, whereas the Type-I error rate of GLM tree clearly exceeded this value. 

The better performance of GLMM tree was mostly observed when random effects in the datasets were sizable, and random intercepts were correlated with potential partitioning variables. In these instances, random effects gave rise to spurious subgroup detection (spurious splits) by GLM tree, both in datasets with and without treatment-subgroup interactions. 

GLMM tree also provided better predictive accuracy than GLM tree, with an average correlation between true and predicted treatment differences of .94 for GLMM tree, and .88 for GLM tree. GLMM tree clearly outperformed GLM tree when random effects in the datasets were sizable, differences in treatment effects across terminal nodes were relatively small (i.e., Cohen's $d=.5$), and/or sample size was small (i.e., $ N < 1,000$). Such treatment-effect differences and sample sizes may be quite common, even in multi-center clinical trials, and GLMM tree may provide a helpful tool for subgroup detection in those instances. 

As expected, when random effects were absent from the simulated datasets, GLM and GLMM tree yielded very similar predictive accuracy. This indicates that GLMM tree can be applied whenever cluster-specific random effects are expected: In the absence of random effects, GLM tree and GLMM tree are expected to perform about equally well and in the presence of random effects GLMM tree is expected to outperform GLM tree. 

Compared to treatment-interaction detection by means of GLMMs with pre-specified interaction effects, GLMM trees provided similar predictive accuracy, on average. When interactions were purely continuous, GLMMs outperformed GLMM trees, and when interactions were purely piecewise, GLMM trees outperformed GLMMs. However, GLMM tree may have a clear advantage when there are a large number of potential moderator variables (i.e., $> 5$). With 10 potential moderator variables, $t$-tests of GLMMs were unable to identify the true moderator variables, whereas the number of potential moderator variables did not influence performance of GLMM tree. Therefore, our results indicate that GLMM trees are better suited than GLMMs for exploratory analyses, in which moderator variables need to be selected from a larger number of covariates. Furthermore, the number of terms in a GLMM increases quadratically with the number of potential moderator variables, yielding complex predictive models. The trees in our simulations were limited to a maximum number of 8 terminal nodes, and may therefore be much easier to use for prediction in practical decision-making contexts. 

These findings are encouraging for the use of GLMM tree in the detection of treatment-subgroup interactions in datasets with clustered structures. However, it should be noted that the simulations show that GLMM tree performs very well, if the model is correctly specified. That is, if there are subgroups with respect to the variables specified as potential partitioning variables and these subgroups have different values for the parameters of the GLM, then GLMM tree will accurately recover those subgroups. However, misspecification of the model will negatively affect performance. The most important source of misspecification would be the omission of relevant variables, either in the GLM or as partitioning variables. When relevant variables are omitted, GLMM tree can only approximate the true subgroups using the specified variables. Another source of misspecification would be the inclusion of irrelevant variables. Our simulations indicate that the performance of GLMM tree was not negatively affected by the number of potential moderator variables specified, but the power to detect subgroups may still be reduced with larger numbers of potential partitioning variables. Including irrelevant variables in the GLM may also negatively affect performance, although we have not assessed this in our simulations.  

In the Application, we found GLMM tree to provide results that were more easily interpretable, and also more accurate than a GLM tree without random effects. In addition, to judge clinical relevance of the findings, we calculated node-specific effect sizes, as would often be done in RCTs or meta-analysis. Although we have limited ourselves to calculating Cohen's $d$ in the current paper, equivalent values of the success rate difference or the number needed to treat can be calculated, but this would involve additional distributional assumptions \cite{KraeyKupf06}. Node-specific effect sizes can also be used to prune trees, when a researcher prefers to have a final tree which is based on statistical as well as clinical significance. A topic for further research would be the development of splitting procedures based on effect sizes, as this would allow for taking into account clinical significant in the tree-growing process.

As discussed in the Introduction, several tree-based methods for treatment-subgroup interaction detection are available. These methods have different objectives, and there is not yet an agreed-upon single best method. In a simulation study, \citeA{SiesyVanM16} found the method of \citeA{ZhanyTsia12Stat} to perform best, followed by model-based recursive partitioning. However, the method of Zhang et al. performed worst under some conditions of the simulation study in terms of the Type I error rate. Further research comparing tree-based methods for treatment-subgroup interaction detection is needed, especially  for clustered datasets, as our simulations were limited to GLM and GLMM-based MOB.

Furthermore, it should be stressed that tree-based methods are exploratory tools. They can be used to detect predictors, interactions and non-linear effects in a data-driven way, but users should take the exploratory nature of such analyses into account. The resulting trees are potentially unstable, and stability of the results should be assessed, preferably in a dataset not used for training, or by multi-fold cross-validation or resampling techniques. In the Application, we have shown how the stability of splitting variable selection can be assessed using resampling techniques.

In conclusion, GLMM tree provided highly accurate recovery of treatment-subgroup interactions and predictions of treatment effect differences, both in the presence and absence of cluster-specific random effects. Therefore, GLMM tree is a promising algorithm for the detection of treatment-subgroup interactions in datasets with a clustered structure, like for example in multi-center trials or individual-level patient data meta-analyses.

\nolinenumbers
\bibliographystyle{apacite}
\bibliography{bib}


\end{document}
