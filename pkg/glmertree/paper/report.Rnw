\documentclass[nojss]{jss}
\usepackage{amssymb,amsmath,amsthm}

\usepackage{thumbpdf}
\shortcites{CuijyWeit14,DrieySmit14}

%% for \usepackage{Sweave}
\SweaveOpts{echo=FALSE, results=hide}
\setkeys{Gin}{width=0.8\textwidth}

<<preliminaries>>=
library("foreign")
library("glmertree")
library("lattice")
@

\title{Detecting Treatment-Subgroup Interactions in Clustered Data with Generalized Linear Mixed-Effects Model Trees}
\Shorttitle{Detecting Treatment-Subgroup Interactions in Clustered Data with GLMM Trees}

\author{Marjolein Fokkema\\Universiteit Leiden \And
        Niels Smits\\Universiteit van Amsterdam \And
	Achim Zeileis\\Universit\"{a}t Innsbruck \AND
	Torsten Hothorn\\Universit\"{a}t Z\"{u}rich \And
	Henk Kelderman\\Universiteit Leiden\\Vrije Universiteit, Amsterdam}
\Plainauthor{Marjolein Fokkema, Niels Smits, Achim Zeileis, Torsten Hothorn, Henk Kelderman}

\Abstract{
  Identification of subgroups of patients for which treatment A is more effective than treatment B, and vice versa, is of key importance to the development of personalized medicine. Several tree-based algorithms have been developed for the detection of such treatment-subgroup interactions. In many instances, however, datasets may have a clustered structure, where observations are clustered within, for example, research centers, studies or persons. In the current paper we propose a new algorithm, generalized linear mixed-effects model (GLMM) trees, that allows for detection of treatment-subgroup interactions, as well as estimation of cluster-specific random effects. The algorithm uses model-based recursive partitioning (MOB) to detect treatment-subgroup interactions, and a GLMM for the estimation of random-effects parameters. In a simulation study, we evaluate the performance of GLMM tree and compare it with that of MOB without random-effects estimation. GLMM tree was found to have a much lower Type I error rate than MOB trees without random effects (4\% and 33\%, respectively). Furthermore, in datasets with treatment-subgroup interactions, GLMM tree recovered the true treatment subgroups much more often than MOB without random effects (in 90\% and 61\% of the datasets, respectively). Also, GLMM tree predicted treatment outcome differences more accurately than MOB without random effects (average predictive accuracy of .94 and .88, respectively). We illustrate the application of GLMM tree on a patient-level dataset of a meta-analysis on the effects of psycho- and pharmacotherapy for depression. We conclude that GLMM tree is a promising algorithm for the detection of treatment-subgroup interactions in clustered datasets.\\
}
\Keywords{model-based recursive partitioning, treatment-subgroup interactions, random effects, generalized linear mixed-effects model, classification and regression trees}

\Address{
  Marjolein Fokkema\\
  Universiteit Leiden\\
  Faculteit der Sociale Wetenschappen\\
  Instituut Psychologie, Methodologie \& Statistiek\\
  Pieter de la Court gebouw\\
  Wassenaarseweg 52\\
  2333 AK Leiden, The Netherlands\\
  E-mail: \email{m.fokkema@fsw.leidenuniv.nl}\\
  % URL: \url{http://www.socialsciences.leiden.edu/psychology/organisation/staff/fokkemam.html}	
}

\begin{document}


\section{Introduction} \label{sec:intro}

In research assessing the efficacy of treatments for somatic and psychological disorders, the one-size-fits-all paradigm is slowly losing ground, and personalized medicine is becoming increasingly important. Stratified medicine presents the challenge of finding which patients respond best to which treatments. This can be referred to as the detection of treatment-subgroup interactions \citep[e.g.,][]{DoovyDuss14}. In most cases, treatment-subgroup interactions are studied using linear models, such as factorial analysis of variance techniques, in which potential moderators have to be specified a-priori, have to be checked one at a time, and continuous moderator variables have to be discretized a-priori. This may hamper identification of which treatments work best for whom, especially when there are no a-priori hypotheses about treatment-subgroup interactions. As noted by \citet{KreayFran06}, there is a need for methods that generate, instead of test, hypotheses and that are specifically directed at the detection of treatment interactions.

Tree-based methods are such hypothesis-generating methods, as they can automatically detect subgroups which differ in the expected outcomes for one or more treatments. Due to their flexibility, tree-based methods are preeminently suited to the detection of treatment-subgroup interactions: they can handle many potential predictor variables at once and can automatically detect (higher order) interactions between predictor variables \citep{StroyMall09}. Several promising tree-based algorithms for the detection of treatment-subgroup interactions have been developed (e.g., \citealp{DussyMech14, DussyMeul04, SuyTsai09, FostyTayl11, LipkyDmit11, ZeilyHoth08}; see \citealp{DoovyDuss14} for an overview). Among these methods, model-based recursive partitioning (MOB; \citealp{ZeilyHoth08}) seems to be the most flexible tool for detecting treatment-subgroup interactions, as it offers a generic inferential framework that can be coupled with a broad range of parametric modeling strategies fitted by M-type estimators \citep{ZeilyHoth08}. Specifically, this model class encompasses the generalized linear model (GLM). GLM-based MOB has been successfully applied by \citet{DrieySmit14} in the detection of subgroups of patients with depression, which differ in the effect of two different psychotherapies. Also, \citet{SeibyZeil15} applied MOB for in the detection of subgroups of patients with amyotrophic lateral sclerosis (ALS), which differ in the effect of treatment with Riluzole. 

In many cases, researchers may want to detect treatment-subgroup interactions in datasets with a clustered structure. However, none of the aforementioned tree-based algorithms allow for taking into account the clustered structure of a dataset. For example, in individual-level patient data meta-analyses, in which datasets of multiple trials evaluating the effects of the same treatments are pooled \citep[e.g.,][]{KoopyHeij07}. In such analyses, the clustered structure of the dataset should be taken into account by including study-specific effects in the model, prompting the need for modeling random effects \citep[e.g.,][]{CoopyPatt09,HiggyWhit01}. Likewise, longitudinal datasets, and datasets from multi-center trials typically also require modeling of random effects. Ignoring the clustered structure of datasets may lead to biased inference due to underestimated standard errors \citep[e.g.,][]{BrykyRaud92,NooryOpde05}. More specifically, when the interest is in subgroup detection, ignoring random effects on the outcome variable may result in the detection of spurious subgroups \citep[e.g.,][]{SelaySimo12}.

In the current paper, we present a tree-based algorithm for detecting treatment-subgroup interactions, which takes the clustered nature of datasets into account. The algorithm combines MOB with random-effects estimates and therefore accounts for both the clustering structure \citep[which is not done in other tree-based treatment-subgroup interaction detection methods, e.g.,][]{ZeilyHoth08, SuyTsai09, DussyMech14} and the treatment effect estimation in models with continuous and non-continuous response variables \citep[which is not available in previously suggested regression trees with random effects, e.g.,][]{HajjyBell11,SelaySimo12}.

In Section~\ref{sec:framework}, we will introduce the existing frameworks for estimating treatment effects: the generalized linear model (GLM), model-based recursive partitioning (MOB), and the generalized linear mixed-effects model (GLMM). Then, we introduce our new algorithm, which combines MOB and the GLMM: generalized linear mixed-effects model trees. Subsequently, in the Section~\ref{sec:evaluation}, we evaluate the performance of the GLMM tree algorithm in simulated datasets. In the Section~\ref{sec:application}, we illustrate the application of the algorithm, using an existing dataset of a patient-level meta-analysis on the effects of psycho- and pharmacotherapeutic treatments for depression of \citet{CuijyWeit14}. But before we discuss the frameworks for estimating treatment effects, we will introduce an artificial motivating data set with which the frameworks and methods to be discussed, will be illustrated. 


\subsection{Artificial motivating dataset} \label{sec:data} 

<<artificial-data>>=
set.seed(123)
treatment <- rbinom(n=150,size=1,prob=1/2)
duration <- round(matrix(rnorm(150,mean=5,sd=3),ncol=1))
duration[duration<0] <- 1
anxiety <- round(rnorm(150,mean=10,sd=3))
age <- round(rnorm(150,mean=30,sd=10))
age[age<18] <- 18
age[age>75] <- 75
cutscore1 <- 5+.44*3
cutscore2 <- 10
node1t1 <- ifelse(duration<=cutscore1 & anxiety<=cutscore2 & treatment==0, 1, 0)
node1t2 <- ifelse(duration<=cutscore1 & anxiety<=cutscore2 & treatment==1, 1, 0)
node2t1 <- ifelse(duration<=cutscore1 & anxiety>cutscore2 & treatment==0, 1, 0)
node2t2 <- ifelse(duration<=cutscore1 & anxiety>cutscore2 & treatment==1, 1, 0)
node3t1 <- ifelse(duration>cutscore1 & treatment==0, 1, 0)
node3t2 <- ifelse(duration>cutscore1 & treatment==1, 1, 0)
beta1 <- -2
beta2 <- 0
beta3 <- 2.5
error <- rnorm(150,0,2)
cluster <- error+rnorm(150, 0, 6)
int_values <- rnorm(10, 0, 1)
tmp <- rep(int_values,each=15)
tmp <- tmp[order(tmp)]
rand_int <- rep(NA, times=150)
rand_int[order(cluster)] <- tmp
cluster[order(cluster)] <- rep(1:10, each=15)
cor(error,rand_int)
true_error <- error - rand_int
true_eff <- round(9 + beta1*node1t1 - beta1*node1t2 + beta2*node2t1 - beta2*node2t2 + beta3*node3t1 - beta3*node3t2 + 
     + .4*treatment)
outcome <- round(9 + beta1*node1t1 - beta1*node1t2 + beta2*node2t1 - beta2*node2t2 + beta3*node3t1 - beta3*node3t2 + 
                      + .4*treatment + true_error + rand_int)
outcome[outcome<0] <- 1
example <- data.frame(treatment,outcome,duration,anxiety,cluster, true_eff)
example$treatment <- factor(example$treatment,labels=c("Treatment 1","Treatment 2"))
#cor(outcome,rand_int)^2
#cor(outcome, true_eff)^2
#truetree <- lmtree(true_eff ~ treatment | age + duration + anxiety, data=example)
@

We created a simulated dataset of 150 observations, which were randomly assigned to Treatment~1 or Treatment~2. Every observation has a value for the response variable, with which the effect of treatment is assessed: the posttreatment total score on a depression inventory. Further, all observations have values for three covariates: duration of depressive symptoms prior to treatment in months (range 0--15); age in years (range 18--75); anxiety inventory total score (range 3--18). 

The simulated dataset has 3 subgroups with different treatment effectiveness. The first subgroup consists of observations with duration $\leq 6$ and anxiety $\leq 10$. In this subgroup, Treatment~1 is more effective than Treatment~2: the mean of the response variable is 7 for Treatment~1, and 11 for Treatment~2. The second subgroup consists of observations with duration $\leq 6$ and anxiety $> 10$. In this subgroup, both therapies are equally effective: the mean value of the response variable is 9 for Treatment~1, and 9 for Treatment~2. The third subgroup consists of observations with duration $>6$. In this subgroup, Treatment~2 is more effective than Treatment~1: the mean value of the response variable is 12 for Treatment~1, and 7 for Treatment~2. 

Observations were drawn from one of ten clusters, each with a different, cluster-specific (i.e., random) intercept. Data was generated such that covariates and cluster-specific intercepts were uncorrelated. Also, 43\% of variance in posttreatment depression scores was due to treatment-subgroup interactions, and 8\% of variance was due to cluster-specific variation. 




\section{General modeling framework} \label{sec:framework}

<<example-trees>>=
exampleglm <- lmtree(outcome ~ treatment | age, data = example)
exampleglmtree <- lmtree(outcome ~ treatment | age + duration + anxiety, data = example)
exampleglmmtree <- lmertree(outcome ~ treatment | cluster | age + duration + anxiety, data = example)
@

\subsection{GLM}
In a clinical trial, where the outcomes of two or more treatments are compared, an overall GLM is often used to estimate treatment effects. GLMs allow for the choice of a suitable response distribution -- for example normal, binomial, or Poisson - depending on whether the treatment outcome variable is continuous (e.g., an improvement score), binary (e.g., improved or not), or a count (e.g., number of events in a certain time span), respectively. In all cases the expectation $\mu_i$ of the outcome variable $y_i$ given the treatment regressors $x_i$ is modeled through a linear predictor and a suitable link function:
%
\begin{eqnarray}
\label{eq:expected_value}
	E[y_i | x_i] & = & \mu_i, \\
\label{eq:fixedeffects}
	g(\mu_{i}) & = & x_{i}^{\top}\beta,
\end{eqnarray}
%
where $x_{i}^{\top}\beta$ is the linear predictor for observation $i$ and $g$ is the link function\footnote{An overview of notation used is provided in the appendix.}. Further, $x_{i}$ is a vector of fixed-effects predictor variable values for observation $i$, of which the first element takes a value of 1 for the intercept, and the second element takes the value of a dummy indicator for treatment type (a value of 0 for the first, or reference treatment type, and a value of 1 for the second, or focal treatment type). $\beta$ is a vector of fixed-effects regression coefficients, the first element representing the intercept, which is the mean value of the linear predictor in the first treatment group, and the second element representing the slope, which is the mean difference in the linear predictor between the first and second treatment groups. In case of a continuous response variable, we employ a Gaussian distribution with identity link and denote the error by $\epsilon_i = y_i - \mu_i$ with variance $\sigma_{\epsilon}^2$.

To keep notation and examples simple, we assume $x_{i}$ and $\beta$ to have length 2. That is, the effects of only two treatment conditions are estimated and no additional covariates are included in the GLM. However, additional treatment conditions and covariates can easily be included. In addition, examples and datasets in the current paper will focus on continuous response variables with normally distributed errors, such as posttreatment severity of a disorder. But the models and algorithms to be discussed can also be applied with discrete outcomes, such as remission of a disorder (yes/no).

\begin{figure}[t!]
\centering
\setkeys{Gin}{width=0.5\textwidth}
<<exampleglm, fig=TRUE, height=5, width=5>>=
plot(exampleglm, tp_args = list(mainlab = "Full sample (N = 150)"))
@
\caption{Example of a normal GLM (with fixed effects only) for treatment outcomes, based on the artificial motivating dataset ($N=150$). The dot for Treatment~1 represents the first, and the slope of the regression line represents the second element of $\beta$.}
\label{fig:fixedeffects}
\end{figure}

To illustrate, the GLM estimated for the artificial motivating dataset is graphically represented in Figure~\ref{fig:fixedeffects}. The boxplots in Figure~\ref{fig:fixedeffects} show the distribution of the posttreatment depression scores in both treatment groups. There seems to be little overall difference in effects of both treatments, as the slope of the regression line is nearly zero. We shall see that this does not necessarily mean that posttreatment depression score and treatment type are unrelated, as the effect of treatment may be moderated by variables not yet included in the model.


\subsection{Model-based recursive partitioning}

The rationale behind MOB is that a global model for all observations, like the GLM in Equation~\ref{eq:expected_value} and~\ref{eq:fixedeffects}, may not describe all data well, and when additional covariates are available it may be possible to partition the dataset with respect to these covariates, and find a better model in each cell of the partition \citep{ZeilyHoth08}. This is reminiscent of the classification and regression tree (CART) algorithm of \citet{BreiyFrie84}, which splits the dataset into subsets, for which the distributions of the outcome variable are most different. However, CART trees detect differences in constant fits across terminal nodes, whereas MOB trees detect differences in parametric models across terminal nodes.

To find partitions and better-fitting local GLMs, the MOB algorithm tests for parameter instability. When the partitioning is based on a GLM, instabilities are differences in $\hat{\beta}$ across partitions of the dataset, which are defined by one or more auxiliary covariates not included in the linear predictor. To find partitions, the MOB algorithm cycles iteratively through the following steps \citep{ZeilyHoth08}: (1) fit the parametric model to the dataset, (2) test for parameter instability over a set of partitioning variables, (3) if there is some overall parameter instability, split the dataset with respect to the variable associated with the highest instability, (4) repeat the procedure in each of the resulting subgroups.

More specifically, in step (2), to test for parameter instability, the so-called \textit{scores} are computed, using the score function. By definition, the empirical scores of all observations in a dataset sum to zero, and when the model is correctly specified, the expected value of the score for each observation is also zero. Under the null hypothesis of parameter stability, the scores do not systematically deviate from the expected value of zero, when the observations are ordered by the values of a potential partitioning variable $U_k$ \citep[c.f.,][]{MerkyZeil13}. To statistically test whether the scores systematically deviate from zero with respect to variable $U_k$, the class of generalized M-fluctuation tests is used \citep{Zeil05,ZeilyHorn07}. 

If the null hypothesis of parameter stability in step (2) can be rejected, that is, if at least one of the partitioning variables $U_{k}$ has a p-value for the M-fluctuation test below the pre-specified significance level $\alpha$, the dataset is partitioned into two subsets in step (3). In step (3), a binary partition is created using $U_{k*}$, the variable with the minimal p-value in step (2). The split point for $U_{k*}$ is selected, by taking the value that minimizes the sum of the values of the objective function in both partitions \citep{ZeilyHoth08}. In step (4), steps (1) through (3) are repeated in each partition, until the null hypothesis of parameter stability can no longer be rejected.

Due to the binary recursive nature of MOB, the resulting partition can be represented as a binary tree. If the partitioning is based on the GLM, the result is a GLM tree, which has a local fixed-effects regression model in every $j$-th ($j = 1,\dots,J$) terminal node of the tree. As a result, in the GLM tree model, the value for $\beta$ depends on terminal node $j$ in which observation $i$ `falls':
%
\begin{equation}
	\label{eq:fixedeffects_MOB}
	g(\mu_{ij}) = x_{i}^{\top}\beta_{j}
\end{equation}
%
Note that, if the recursive subgroup structure (i.e., the partition) were known, the tree could be estimated as a single GLM where all coefficients interact with the factor indicating the subgroup. Somewhat more formally, the model could then be written: $g(\mu_{i}) = x_{i}^{* \top}\beta^{*}$, where $x_{i}^{*}$ are the values of the $2J$ interactions between the subgroups from the tree, and the elements of $x_{i}$. $\beta^{*}$ would also have length $2J$, and contain the subgroup-specific fixed-effects coefficients.

\begin{figure}[t!]
\centering
\setkeys{Gin}{width=\textwidth}
<<exampleglmtree, fig=TRUE, width=12, height=9>>=
plot(exampleglmtree)
@
\caption{Example of a tree representation of model-based recursive partition, based on the artificial motivating dataset. Three additional covariates (anxiety questionnaire score, duration of depressive symptoms at baseline in months and age) were used as potential splitting variables.}
\label{fig:example_mobtree}
\end{figure}

Figure~\ref{fig:example_mobtree} provides an example of the GLM tree model in Equation~\ref{eq:fixedeffects_MOB}, based on the artificial motivating dataset. By using the three additional covariates (anxiety, duration and age), MOB partitioned the observations into four subgroups, each with a different estimate for $\beta_j$. Age was correctly not detected as a partitioning variable, and the left- and rightmost subgroups are in accordance with the treatment-subgroup interactions as described above. However, the two subgroups in the middle result from a spurious split.


\subsection{GLMM}
When a dataset contains observations from multiple clusters (e.g., trials, research centers, or individuals in longitudinal datasets), the GLM in Equation~\ref{eq:fixedeffects} may be extended to include cluster-specific, or random effects, and the model becomes a GLMM:
%
\begin{equation}
	\label{eq:mixedeffects}
	g(\mu_{i}) = x_{i}^{\top}\beta + z_{i}^{\top}b
\end{equation}
%
Where $z_{i}$ is a unit vector of length $M$, of which the $m$-th element takes a value of 1, and all other elements take a value of 0; $m$ ($m=1,\dots,M$) denotes the cluster which observation $i$ is part of. Further, $b$ is a random vector of length $M$, with every element being the random intercept for cluster $m$. Within the GLMM, it is assumed that $b$ is normally distributed, with mean zero and variance $\sigma^{2}_{b}$. The parameters of the GLMM can be estimated with, for example, maximum likelihood (ML) and restricted ML (REML), as described in \citet{BrykyRaud92}, for example.  

For simplicity, we assume that only cluster-specific intercepts are included in the models. However, random-effects covariates and coefficients can easily be included.

Note that, if the random-effects coefficients were known, the model could be estimated by a simple GLM as in Equation \ref{eq:fixedeffects} where $z_{i}^{\top}b$ would only be added as an offset (i.e., a variable with a fixed coefficient of 1) to the linear predictor.


\subsection{GLMM tree}

As noted earlier, ordinary GLM(M)s are not well suited for the detection of treatment-subgroup interactions, whereas the MOB algorithm is, but does not allow for estimation of random effects. Therefore, we propose the GLMM tree, which combines the GLMM from Equation~\ref{eq:mixedeffects} with the tree from Equation~\ref{eq:fixedeffects_MOB}: 
%
\begin{equation}
	\label{eq:glimmertree}
	g(\mu_{i}) = x_{i}^{\top}\beta_{j} + z_{i}^{\top}b
\end{equation}
%
To estimate the parameters of this model, we take an approach similar to that of \citet{HajjyBell11} and \citet{SelaySimo12} but extend their ideas from classical CART trees with only random intercepts to a full GLMM algorithm. In the MERT approach, the fixed-effects part of a GLMM is replaced by a CART regression tree, and the random-effects part is estimated as usual. To estimate a MERT, an iterative approach is taken, alternating between (1) assuming random effects known, allowing for estimation of the regression tree, and (2) assuming the regression tree known, allowing for estimation of the random effects. 

\begin{figure}[t!]
\centering
<<exampleglmmtree, fig=TRUE, width=9, height=7>>=
plot(exampleglmmtree)
@
\caption{GLMM tree of the motivating example dataset. Three covariates (anxiety questionnaire score, duration of depressive symptoms at baseline in months and age) were used as potential splitting variables, and the clustering structure was taken into account by estimating random intercepts.}
\label{fig:example_glimmertree}
\end{figure}

For estimating GLMM trees, we take the MERT approach a step further: by using a GLM tree, instead of a CART regression tree with constant fits, to estimate the fixed-effects part of the GLMM. This allows not only for detection of differences in main effects, but also for detection of differences in regression effects (e.g., of treatment type) across terminal nodes. In addition, GLMM trees can be estimated for continuous, as well as binary and count variables. The GLMM tree algorithm takes the following steps to estimate the model in Equation~\ref{eq:glimmertree}:

\begin{description}
  \item[Step 0:] Initialize by setting $r$ and all values $\hat{b}_{(r)}$ to 0.

  \item[Step 1:] Set $r = r+1$. Estimate GLM tree ($x_{i}^{\top}\hat{\beta}_{j(r)}$), with $z_{i}^{\top}\hat{b}_{(r-1)}$ as an offset.

  \item[Step 2:] Estimate random effects in the mixed effects model $x_{i}^{\top}\hat{\beta}_{j(r)} + z_{i}^{\top}\hat{b}_{(r)}$ with subgroups $j(r)$ from the GLM tree.
  % Estimate random effects $z_{i}^{\top}\hat{b}_{(r)}$, with $x_{i}^{\top}\hat{\beta}_{j(r)}$ as an offset.

  \item[Step 3:] Repeat Steps~1 and~2 until convergence.
\end{description}

The algorithm initializes by setting all $b$ values to $0$, since the random-effects (and also the fixed-effects) parts are initially unknown. In every iteration, the GLM tree and random-effects coefficients $b$ are re-estimated. The GLM tree is estimated, given the estimated $\hat{b}$ from the last iteration, and the $b$ values are estimated, given the estimated GLM tree from the current iteration. Iterations are continued until convergence, which is monitored by computing the log-likelihood criterion of the mixed-effects model in Equation~\ref{eq:glimmertree}. 

In Figure~\ref{fig:example_glimmertree}, the GLMM tree that was grown on the artificial motivating dataset is presented. As can be seen, by taking into account the clustering of observations by estimating random intercepts, the spurious split involving the anxiety variable no longer appears in the tree. 



\section{Empirical evaluation} \label{sec:evaluation}

We will asses the performance of GLMM tree in recovering treatment-subgroup interactions, and predicting differences between the outcomes of two treatments, in simulated datasets with continuous outcomes. In addition, we will compare the performance of GLMM tree with that of GLM tree. In the simulation study, our main interest will be in the effects of sample size, the presence and magnitude of treatment-subgroup interactions, and the presence and magnitude of the random effects, but additonal parameters will be varied as well. 

When random effects are absent from the datasets, we expect GLM and GLMM tree to perform equally well. In the presence of random effects, we expect GLMM tree to outperform GLM tree. We expect the difference in performance between both algorithms to increase, with increasing differences in treatment outcomes, increasing variance of random-effects coefficients, and/or increasing sample sizes.


\subsection{Simulation design}

\subsubsection{Datasets with treatment-subgroup interactions}
For generating datasets with treatment-subgroup interactions, we used a treatment-subgroup interaction design from \citet{DussyMech14}, which is also depicted in Figure~\ref{fig:modelC}. Figure~\ref{fig:modelC} shows two subgroups with mean differences in treatment outcomes, and two subgroups without mean differences in treatment outcomes. The four subgroups are characterized by their values on the partitioning variables $U_2$, and $U_1$ or $U_5$. That is, $U_1$, $U_2$ and $U_5$ are true partitioning variables, whereas other potential partitioning variables ($U_3$, $U_4$, $U_6$ through $U_{15}$) are noise variables.



\begin{figure}[t!]
\centering
\setkeys{Gin}{width=0.8\textwidth}
<<dgp-tree, fig=TRUE, height=5, width=7>>=
fig4 <- party(
  partynode(1L,
    split = partysplit(2L, breaks = 30),
    kids = list(
      partynode(2L,
        split = partysplit(1L, breaks = 17),
        kids = list(
          partynode(3L, info = c(
	    expression(''),
	    expression(beta[j0] == '17.5'),
	    expression(''),
	    expression(beta[j1] == -'5.0'),
	    expression(''),
	    expression(d[j] == -'1.0')
	  )),
          partynode(4L, info = c(
	    expression(''),
	    expression(beta[j0] == '30.0'),
	    expression(''),
	    expression(beta[j1] == '0.0'),
	    expression(''),
	    expression(d[j] == '0.0')
	  )))),
      partynode(5L,
        split = partysplit(1L, breaks = 63),
        kids = list(
          partynode(6L, info = c(
	    expression(''),
	    expression(beta[j0] == '30.0'),
	    expression(''),
	    expression(beta[j1] == '0.0'),
	    expression(''),
	    expression(d[j] == '0.0')
	  )),
          partynode(7L, info = c(
	    expression(''),
	    expression(beta[j0] == '42.5'),
	    expression(''),
	    expression(beta[j1] == '5.0'),
	    expression(''),
	    expression(d[j] == '1.0')
	  )))))),
  data.frame(U1 = numeric(0), U2 = numeric(0))
)
plot(fig4, tp_args = list(FUN = identity, width = 9), tnex = 1.5)
@
\caption{Data-generating model for treatment-subgroup interactions. Parameter $d$ denotes the standardized mean difference between the outcomes of Treatment~1 and~2 (i.e., $\beta_{j1} / \sigma_{\epsilon}$).}
\label{fig:modelC}
\end{figure}



\subsubsection{Datasets without treatment-subgroup interactions}
For generating datasets without treatment-subgroup interactions, we used a design in which there is only a main effect of treatment in the population. Put differently, the number of subgroups or terminal nodes in these datasets was $J=1$, and there was only a single value of $\beta_j = \beta$ in every dataset. The mean of the outcome variable in the datasets without treatment-subgroup interactions was 30, which is the same value as in the datasets with treatment-subgroup interactions. As a result, $\beta = (27.5, 32.5)$ for all observations when $d=1$.

\subsubsection{Parameters of the data-generating process}

In generating datasets, we varied seven parameters of the data-generating process:
 
\begin{enumerate} 
\item Three levels for the total number of observations: $N=200$, $N=500$, $N=1000$.
\item Two levels for the number of potential partitioning covariates $U_1$ through $U_K$: $K=5$, $K=15$ (where only $U_1$, $U_2$ and $U_5$ are true partitioning variables).
\item Two levels of intercorrelations between the covariates $U_1$ through $U_K$: $\rho_{U_k,U_{k'}}=0.0$, $\rho_{U_k,U_{k'}}=0.3$.
\item Three levels for the number of clusters: $M=5$, $M=10$, $M=25$.
\item Three levels for the population standard deviation of the normal distribution from which the cluster specific intercepts are drawn: $\sigma_{b}=0$, $\sigma_{b}=5$, $\sigma_{b}=10$.
\item Three levels for the intercorrelations between $b$ and one of the $U_k$ variables: $b$ and $U_k$ uncorrelated, $b$ correlated with a true partitioning variable (i.e., $U_2$, $U_1$, or $U_5$, introducing a correlation of $\approx 0.42$), $b$ correlated with a non-partitioning covariate (i.e., $U_3$ or $U_4$, introducing a correlation of $\approx 0.42$)\footnote{Note that, when $\sigma_b = 0$, the correlation between $b$ and one of the $U_k$ variables is 0, by definition. However, datasets were created for this condition, to allow for a full factorial design of the simulation study; in reality, $b$ and $U$ are uncorrelated in these instances.}. 
\item Two different levels for $\beta_{j1}$, the unstandardized mean difference in treatment outcomes, in subgroups with differential treatment effects. The levels for mean differences in subgroups with differential treatment effect were $|\beta_{j1}| = 2.5$ (corresponding to a medium effect size, Cohen's $d = 0.5$; \citealp{Cohe92}) and $|\beta_{j1}| = 5.0$ (corresponding to a large effect size; Cohen's $d = 1.0$).
\end{enumerate}

For each cell, 50 datasets with treatment-subgroup interactions were generated, resulting in $50 \times 3 \times 2 \times 2 \times 3 \times 3 \times 3 \times 2$ = 32,400 training datasets. For the datasets without treatment-subgroup interactions, the 6th parameter of the data-generating process had only two levels ($b$ correlated with one of the $U_k$ variables, and $b$ not correlated with any of the $U_k$ variables). Therefore, $50 \times 3 \times 2 \times 2 \times 3 \times 3 \times 2 \times 2$ = 21,600 datasets without treatment-subgroup interactions were generated.




\subsubsection{Variable distributions}

As in \citet{DussyMech14}, all covariates $U_1$ through $U_{K}$ were drawn from a multivariate normal distribution with means ${\mu_U}_1$, ${\mu_U}_2$, ${\mu_U}_4$, and ${\mu_U}_5$ fixed at 10, 30, $-40$, and 70, respectively. The means for all other covariates (i.e., ${\mu_U}_3$, and ${\mu_U}_6$ through ${\mu_U}_{15}$) were drawn from a discrete uniform distribution on the interval $[-70,70]$. All covariates $U_1$ through $U_{15}$ have the same standard deviation: ${\sigma_U}_k = 10$. Correlations between the $U_k$ variables vary according to the third facet of the simulation design described above.

To generate the random error term $\epsilon$, for every observation we drew a value from a normal distribution with $\mu_{\epsilon} = 0$ and $\sigma_{\epsilon} = 5$. 

To generate the cluster-specific intercepts $b_m$, we partitioned the sample into equally-sized clusters, conditional on one of the variables $U_1$ through $U_5$, producing the correlations in the sixth facet of the simulation design. For each cluster, we drew a single value $b_m$ from a normal distribution with mean 0 and the value of $\sigma_{b}$ given by the fifth facet of the simulation design. When $b$ was correlated with one of the potential partitioning variables, the correlated potential partitioning variable was randomly selected.

To generate node-specific fixed effects, we partitioned the sample according to the terminal nodes of the tree in Figure 4.3. In combination with the seventh facet of the simulation design, this determines the values of $\beta_j$. For every observation, we generated a binomial variable (with probability .5) as an indicator for treatment type. 

Finally, the response variable was calculated as the sum of the (node-specific) fixed effects, random effects and the error term: $y_{i} = x_{i}^{\top} \beta_{j} + z_{i}^{\top} b_{m} + \epsilon_{i}$.




\subsection{Evaluation of performance}

\subsubsection{Tree size and accuracy} 

For every dataset, the total number of nodes in the resulting GLM and GLMM tree were calculated. For datasets without treatment-subgroup interactions, this allowed us to assess tree accuracy in terms of Type I error: the probability that the dataset is erroneously partitioned (i.e., a tree of size $>1$ is created). For datasets with treatment-subgroup interactions, this allowed us to assess the probability that the dataset is erroneously not partitioned, and the extent to which the algorithms may detect spurious subgroups (i.e., a tree of size $> 7$ is created).

For datasets with treatment-subgroup interactions, we assessed the accuracy of the GLM and GLMM trees. An accurately recovered tree was defined as a tree with (1) the true tree size (i.e., tree size $= 7$), (2) the first split in the tree involving variable $U_2$ and a value of $30 \pm 5$, (3) the next split on the left involving variable $U_1$ and a value of $17 \pm 5$, and (4) the next split on the right involving variable $U_5$ and a value of $63 \pm 5$. Note that the allowance of $\pm 5$ equals an allowance of plus or minus half the population standard deviation of the partitioning variable ($\sigma_{U_k}$). 

To assess the effects of the data-generating parameters on tree size for both algorithms, we performed ANOVAs with algorithm type and the parameters of the data-generating process as independent variables. In addition, interactions between algorithm type and each of the data-generating parameters were also entered as independent variables. The impact of predictors with main and/or interaction effects which explained a proportion of $> .01$ of variance was further assessed using graphical displays.

To assess the effects of the data-generating parameters on tree accuracy in datasets with treatment-subgroup interactions, we used a GLM with algorithm type and the parameters of the data-generating process as independent variables. In addition, interactions between algorithm type and each of the data-generating parameters were also entered as independent variables. The effects of predictors with main and/or interaction effects with unstandardized regression coefficients $> .5$ (i.e., an in- or decrease in the log-odds of .5) were further assessed using graphical displays.

\subsubsection{Predictive accuracy} 

We evaluated predictive accuracy of GLM and GLMM trees by calculating correlations between the true and predicted treatment-effect differences ($\beta_{j1}$ in Figure~\ref{fig:modelC}). Note that this correlation was only assessed for datasets with treatment-subgroup interactions, as the true treatment differences have a constant value in datasets without treatment-subgroup interactions.

Using the same data for training and evaluation of a model results in overly optimistic estimates of predictive accuracy \citep{HastyTibs09}. Therefore, GLM and GLMM trees were used for prediction of new observations from test datasets. Test datasets were generated from the same population as the training datasets. Because the cluster-specific intercepts $b$ were randomly generated for training as well as test datasets, test observations were from 'new' clusters. As a result, a model without random effects was used for prediction with GLMM tree.

For every dataset, correlation coefficients for each algorithm were calculated, representing the linear association between the true and predicted treatment-effect differences. To assess the effects of the data-generating parameters on predictive accuracy, we performed ANOVAs with algorithm type and the parameters of the data-generating process as independent variables. In addition, interactions between algorithm type and each of the data-generating parameters were also entered as independent variables. The effects of predictors with main and/or interaction effects which explained a proportion of $> .01$ of variance were further investigated using graphical displays.


\subsection{Software}

\proglang{R} \citep{R14} was used for generation and analysis of all datasets. The \pkg{partykit} package (version 1.0-2; \citealp{HothyZeil15}) was employed for estimating GLM trees using the \code{lmtree} function for normal linear regressions. For other response distributions, the \code{glmtree} function would be available. For estimation of GLMMs the \code{lmer} (or \code{glmer}, respectively) from the \pkg{lme4} package (version 1.1-7; \citealp{BateyMeac12}) was employed, using restricted maximum likelihood (REML) estimation.

For the estimation of GLMM trees the former two packages were combined in a new package \pkg{glmertree} (version 0.1-0; \citealp{FokkyZeil15}; available from R-Forge). This provides functions \code{lmertree} and \code{glmertree} that iterate between estimation of the \code{lmtree}/\code{glmtree} model and the \code{lmer}/\code{glmer} model.

In all applications, the significance level $\alpha$ for the parameter instability tests in the trees was set to .05, with a Bonferroni correction applied for multiple testing. The minimum number of observations per node in the tree was set to 20 and the maximum tree depth was set to four, thus limiting the number of potential subgroups to eight. Iterations of the GLMM tree algorithm were repeated until the log-likelihood changes between two subsequent iterations fell below .001.



\subsection{Results}

<<simulation-data>>=
load("treespecs_long.dat")
treespecs.long$N <- factor(as.numeric(as.character(treespecs.long$N)), ordered=T)
treespecs.long$sigmab <- factor(as.numeric(as.character(treespecs.long$sigmab)), ordered=T)
treespecs.long$treatdiff <- factor(as.numeric(as.character(treespecs.long$treatdiff)), ordered=T)
treespecs.long$truetree.values <- as.numeric(treespecs.long$truetree.values)-1
levels(treespecs.long$corUb)[levels(treespecs.long$corUb)=="bi and splitting U correlated"] <- "b correlated with splitting U"
levels(treespecs.long$corUb)[levels(treespecs.long$corUb)=="bi and non-splitting U correlated"] <- "b correlated with non-splitting U"
levels(treespecs.long$corUb)[levels(treespecs.long$corUb)=="uncorrelated"] <- "b and U uncorrelated"
@


\subsubsection{Tree size in datasets without treatment-subgroup interactions}

Overall, smaller trees were created by GLMM tree: the average tree size was 1.09 ($\mathrm{SD}=0.44$) for GLMM tree, and 2.02 ($\mathrm{SD}=1.68$) for GLM tree. The estimated probability that a dataset was erroneously partitioned was .04 for GLMM tree, and .33 for GLM tree. 

The effects of sample size, $\sigma_b$ and the correlation between $b$ and one of the $U_k$ variables on tree size were assessed with a graphical display (Figure~\ref{fig:xyplot_treesize_nointeract}). When random effects were absent (i.e., $\sigma_{b}=0$), both GLM and GLMM tree tended to create trees of size 1. In the presence of random effects, GLMM tree also tended to create trees of size 1, but GLM tree created much larger trees, when $b$ was correlated with one of the $U_k$ variables. This effect was stronger when sample size was larger. 

\begin{figure}[t!]
\centering
\setkeys{Gin}{width=0.75\textwidth}
<<treesize-nointeract-xyplot, fig=TRUE, width=9, height=7>>=
load("treesizes_long_nointeract.dat")
treesizes.long$sigmabm <- factor(as.numeric(as.character(treesizes.long$sigmabm)), ordered = TRUE)
treesizes.long$N <- factor(as.numeric(as.character(treesizes.long$N)), ordered = TRUE)
aggdata <- aggregate(formula=treesize.values ~ treesize.ind + N + sigmabm + corUbm, FUN=mean, data=treesizes.long)
print(xyplot(treesize.values ~ sigmabm | N + corUbm, data = aggdata, groups=treesize.ind, 
	type="b", ylab="tree size", xlab=expression(sigma[b]), par.settings=standard.theme("pdf",color=FALSE), 
	abline=c(1,0), auto.key=list(space="top", columns=2, title=" ", cex.title=1, 
	lines=TRUE, points=TRUE)))
@
\caption{Average tree size of GLM and GLMM trees for datasets without treatment-subgroup interactions. Values $200$, $500$ and $1000$ refer to sample size. Reference line at $y=1$ represents the true tree size.}
\label{fig:xyplot_treesize_nointeract}
\end{figure}





\subsubsection{Tree size in datasets with treatment-subgroup interactions}

In datasets with treatment-subgroup interactions, GLMM trees were also smaller than GLM trees. For these datasets, the true tree size was 7 (4 terminal nodes and 3 inner nodes; Figure~\ref{fig:modelC}). The average size of GLMM trees was 7.16 ($\mathrm{SD}=0.62$), and the average size of GLM trees was 8.12 ($\mathrm{SD}=2.05$). The estimated probability that a dataset was erroneously not partitioned was 0, for both GLM and GLMM tree. However, a proportion of .91 of GLMM trees matched the true tree size, whereas a proportion of only .63 of GLM trees matched the true tree size.

The effects of sample size, $\sigma_b$ and the correlation between $b$ and one of the $U_k$ variables on tree size were assessed with a graphical display (Figure~\ref{fig:xyplot_treesize_interact}). When random effects were absent (i.e., $\sigma_{b}=0$), both GLM and GLMM tree created trees with a size of about 7, on average. However, clear differences in performance between GLM and GLMMtree were observed when $\sigma_b > 0$. When $b$ is not correlated with one of the $U_k$ variables, when sample size is small (i.e., 200) and when $\sigma_b$ is large (i.e., 10), GLM tree has difficulty detecting splits and grows trees that are too small, on average. When $b$ is not correlated with one of the $U_k$ variables and when sample size is larger (i.e., 500 or 1000), GLM and GLMM trees are about the same size (i.e., $\approx 7$). When $b$ is correlated with one of the $U_k$ variables, GLM creates spurious splits, especially when sample size is larger (i.e., 500 or 1000) and when $\sigma_b$ is large (i.e., 10). This effect was stronger when $b$ was correlated to a non-splitting variable. 


\begin{figure}[t!]
\centering
\setkeys{Gin}{width=0.74\textwidth}
<<treesize-xyplot, fig=TRUE, width=9, height=9>>=
aggdata.size <- aggregate(formula=treesize.values ~ treesize.ind + N + sigmab + corUb, FUN=mean, data=treespecs.long)	
print(xyplot(treesize.values ~ sigmab | N + corUb, data = aggdata.size, groups=treesize.ind, 
	type="b", ylab="tree size", xlab=expression(sigma[b]), par.settings=standard.theme("pdf",color=F), 
	abline=c(7,0), auto.key=list(space="top", columns=2, title=" ", cex.title=1,lines=T, points=T))
)
@
\caption{Average tree size of GLM and GLMM trees for datasets with treatment-subgroup interactions. Values $200$, $500$ and $1000$ refer to sample size. Reference line at $y=7$ represents true tree size.}
\label{fig:xyplot_treesize_interact}
\end{figure}




 
\subsubsection{Tree accuracy in datasets with treatment-subgroup interactions}

To assess the accuracy of the trees created by GLM and GLMM tree, we inspected the variables and values that were selected for partitioning in every dataset. For the first split, GLMM tree always selected the true partitioning variable ($U_2$). GLM tree selected a wrong partitioning variable (I.e., $U_1$ in only one dataset. The splitting value for $U_2$ selected for the first split was 29.94 for both GLM and GLMM tree, which is very close to the true splitting value of 30 (Figure~\ref{fig:modelC}). However, GLM tree showed somewhat higher variability in recovering the splitting value for the first split (involving $U_2$), than did GLMM tree ($\mathrm{SD}=0.154$ and $\mathrm{SD}=0.127$, respectively).

Overall, GLMM tree performed well in recovering treatment-subgroup interactions, by accurately recovering the tree in 90.19\% of datasets. GLM tree performed less accurate, by accurately recovering the tree in 61.44\% of datasets. 

\begin{figure}[t!]
\centering
<<accuracy-xyplot, fig=TRUE, width=9, height=9>>=
aggdata.acc <- aggregate(formula=truetree.values ~ truetree.ind + N + sigmab + corUb, FUN=mean, data=treespecs.long)
print(xyplot(truetree.values ~ sigmab | N + corUb, data = aggdata.acc, groups=truetree.ind, type="b", 
	ylab="tree accuracy", xlab=expression(sigma[b]), par.settings=standard.theme("pdf",color=FALSE), 
	auto.key=list(space="top", columns=2, title=" ", cex.title=1,lines=TRUE, points=TRUE))
)
@
\caption{Average accuracy of GLM and GLMM trees. Accuracy of trees is defined as the proportion of datasets in which the true tree was accurately recovered. Values are correlated to one of the $U_k$ variables; values $200$, $500$ and $1000$ refer to sample size.}
\label{fig:xyplot_treeaccuracy}
\end{figure}


The effects of sample size, $\sigma_b$ and the correlation between $b$ and one of the $U_k$ variables on the probability of accurate tree recovery for GLM and GLMM tree were assessed with a graphical display (Figure~\ref{fig:xyplot_treeaccuracy}). When random effects were absent from the datasets (i.e., $\sigma_b = 0$), the trees recovered by GLM and GLMM tree were equally accurate, on average. In the presence of random effects, GLM trees were much less accurate than GLMM trees. This was found for all sample sizes, when $b$ was correlated to one of the $U_k$ variables, and the effect was somewhat stronger when the correlated $U_k$ was not a true partitioning variable. When $b$ was not correlated to one of the $U_k$ variables, GLMM tree clearly outperformed GLM tree only when sample size was small (i.e., 200).




\subsubsection{Predictive accuracy on test data}

To assess predictive accuracy, correlations between the true and predicted treatment-effect differences of both algorithms were calculated for every dataset. Overall, predicted treatment-effect differences of GLMM tree were closer to the true differences, than those of GLM tree. The average correlation between the true and predicted treatment-effect differences over all datasets with treatment-subgroup interactions was .94 ($\mathrm{SD}=0.11$) for GLMM tree, and .88 ($\mathrm{SD}=0.19$) for GLM tree.


\begin{figure}[t!]
\centering
<<correlation-xyplot, fig=TRUE, width=9, height=7>>=
aggdata.cor <- aggregate(formula=correlation.values ~ correlation.ind + N + sigmab + treatdiff, FUN=mean, data=treespecs.long)
print(xyplot(correlation.values ~ sigmab | N + treatdiff, data = aggdata.cor, groups=correlation.ind, 
	type="b", ylab="correlation", xlab=expression(sigma[b]), par.settings=standard.theme("pdf",color=F), 
	auto.key=list(space="top", columns=2, title=" ", cex.title=1,lines=T, points=T))
)
@
\caption{Average predictive accuracy of GLM and GLMM trees. Predictive accuracy of trees is defined as the correlation between the true and predicted differences between Treatment~1 and~2. Values $5$ and $2.5$ refer to the absolute value of the unstandardized treatment-effect difference in subgroups with treatment-effect differences; values $200$, $500$ and $1000$ refer to sample size.}
\label{fig:xyplot_correlations}
\end{figure}

The effects of sample size, $\sigma_b$ and the correlation between $b$ and one of the $U_k$ variables on the predictive accuracy of both algorithms were assessed with a graphical display (Figure~\ref{fig:xyplot_correlations}). Both algorithms showed higher predictive accuracy when sample size was larger, and when treatment-effect differences were larger. When random effects were absent from the datasets (i.e., $\sigma_b = 0$), predictions of GLM and GLMM tree were equally accurate. In the presence of random effects, GLM tree predictions were always much less accurate than those of GLMM tree. This effect was stronger when $\sigma_b$ was larger, sample size was larger, and/or treatment-effect differences were larger.


\section{Patient-level meta-analysis of depression treatments} \label{sec:application}

<<depression-data>>=
metadata <- read.dta("Database IPDMA CBT PHA Version 11.dta")
metadata[metadata == 999] <- NA
metadata[metadata == 888] <- NA
vars <- c("studyid", "Tx_group", "Age", "Gender", "education", "ComorbidAnxietyDisorder", "HRSDt0", "HRSDt1")
factors <- c("studyid", "Tx_group", "Gender", "education", "ComorbidAnxietyDisorder")
metadata$education <- factor(metadata$education, ordered = TRUE)
for (i in 1:length(factors)) {metadata[, factors[i]] <- factor(metadata[,factors[i]])}
metadata <- metadata[vars] # select only relevant variables
metadata <- metadata[complete.cases(metadata[, vars]), ] # select only complete data
metadata <- metadata[!metadata$Tx_group == "placebo", ] # remove placebo observations
metadata$Tx_group <- factor(metadata$Tx_group)
@



\subsection{Method}

To illustrate the application of the GLM and GLMM tree algorithms and the differences in their results, we applied both algorithms to a dataset from a meta-analytic study of \citet{CuijyWeit14}. This meta-analysis was based on a dataset, consisting of observations for individual patients from 14 RCTs, comparing the effects of psychotherapy (cognitive behavioral therapy; CBT) and pharmacotherapy (PHA) in the treatment of depression. The study of \citet{CuijyWeit14} was aimed at establishing whether gender is a predictor or moderator of the outcomes of psychological and pharmacological treatments for depression. Treatment outcomes were assessed by means of the 17-item Hamilton Rating Scale for Depression (HAM-D; \citealp{Hami60}). \citet{CuijyWeit14} found no indication that gender either predicted or moderated treatment outcomes. Further details on the dataset are provided in \citet{CuijyWeit14}.

In our analyses, posttreatment HAM-D score was the outcome variable, and potential partitioning variables were age, gender, level of education, presence of a comorbid anxiety disorder at baseline, and pretreatment HAM-D score. The predictor variable in the linear model was treatment type (0 = CBT and 1 = PHA). An indicator for study was used as the cluster indicator. 

In RCTs, treatment effects are often estimated after controlling posttreatment values on the outcome measure for the linear effect of pretreatment values on the same measure. Therefore, we included the predictions of a linear regression of HAM-D posttreatment on HAM-D pretreatment scores as an offset variable in growing the GLM and GLMM trees. An offset variable is a linear predictor with an a-priori specified coefficient of one. Including the predictions of a linear regression of HAM-D posttreatment on HAM-D pretreatment scores as an offset has the same effect as statistically controlling for the linear effects of pretreatment scores, as is often done in ANCOVA. 

We built all trees using data of patients with complete observations; that is, observations with non-missing values for potential partitioning variables, and pre- and posttreatment HAM-D score. As a result, data from 694 patients from 7 studies were included for the analyses. Results of our analysis may therefore not be representative of the complete dataset of the meta-analysis by \citet{CuijyWeit14}. 

Predictive accuracy of GLM and GLMM trees was assessed by calculating the average correlations between observed and predicted HAM-D scores, based on 50-fold cross validation.

<<depression-trees>>=
## offset
metadata$HRSDfit <- fitted(lm(HRSDt1 ~ HRSDt0, data = metadata))

## GLM tree
lmtree_app <- lmtree(HRSDt1 ~ Tx_group | Age + Gender + education + ComorbidAnxietyDisorder + HRSDt0,
  data = metadata, offset = HRSDfit)

## GLMM tree
lmertree_app <- lmertree(HRSDt1 ~ Tx_group | (1 | studyid) + offset(HRSDfit) | Age + Gender + education + ComorbidAnxietyDisorder + HRSDt0,
  data = metadata, ranefstart = metadata$HRSDfit)
@

\subsection{Results}

\begin{figure}[p!]
\centering
\setkeys{Gin}{width=0.78\textwidth}
<<depression-glmtree, fig=TRUE, height=6, width=8>>=
plot(lmtree_app)
@
\caption{GLM tree for prediction of posttreatment total scores on the Hamilton Rating Scale for Depression (HAM-D). The y-axes of the boxplots represent posttreatment HAM-D scores, and the x-axes represent treatment levels: cognitive behavior therapy (CBT) vs.\ pharmacotherapy (PHA).
\label{fig:lmtree_C&W}}

\setkeys{Gin}{width=0.6\textwidth}
<<depression-glmmtree, fig=TRUE, height=4, width=4.7>>=
plot(lmertree_app)
@
\caption{GLMM tree for prediction of posttreatment total scores on the Hamilton Rating Scale for Depression (HAM-D). The y-axes of the boxplots represent posttreatment HAM-D scores, and the x-axes represent treatment levels: cognitive behavior therapy (CBT) vs.\ pharmacotherapy (PHA).
\label{fig:lmertree_C&W}}
\end{figure}

Both tree-growing algorithms were applied to the dataset; the resulting GLM tree is presented in Figure~\ref{fig:lmtree_C&W} and the resulting GLMM tree is presented in Figure~\ref{fig:lmertree_C&W}. Note that the GLM tree in Figure~\ref{fig:lmtree_C&W} is also the tree in the first iteration of the GLMM tree algorithm. 

The GLM tree (Figure~\ref{fig:lmtree_C&W}) selected level of education as the first partitioning variable, and presence of a comorbid anxiety disorder as a second partitioning variable, for observations with a higher level of education. Node 2 of Figure~\ref{fig:lmtree_C&W} indicates that for patients with a low level of education, antidepressant medication provides the greatest reduction in HAM-D scores. Node 4 indicates that for patients with a higher level of education, and no comorbid anxiety disorder, the reduction in HAM-D scores is about the same for CBT and PHA. Node 5 indicates, that for patients with a higher level of education and a comorbid anxiety disorder, the reduction in HAM-D scores is greatest for PHA.

By taking into account study-specific intercepts, the final GLMM tree (Figure~\ref{fig:lmertree_C&W}) suggests that the first split made by GLM tree is a spurious split. The GLMM tree selected only presence of a comorbid anxiety disorder as a partitioning variable. The terminal nodes of Figure~\ref{fig:lmertree_C&W} show only a single treatment-subgroup interaction: for patients without a comorbid anxiety disorder, CBT and PHA provide more or less the same reduction in HAM-D scores, whereas for patients with a comorbid anxiety disorder, PHA provides a greater reduction in HAM-D scores. The estimated intraclass correlation coefficient for the random intercepts was .05. 

Assessment of predictive accuracy by means of 50-fold cross validation showed that the GLMM tree had higher predictive accuracy than the GLM tree. The correlation between true and predicted posttreatment HAM-D total scores, averaged over the 50 folds, was .28 ($\mathit{var}=.067$) for GLMM tree, and .19 ($\mathit{var}=.084$) for GLM tree. This indicates that GLMM tree provided higher predictive accuracy, on average, and also somewhat lower variability of predictive accuracy than GLM tree. 

\section{Discussion} \label{sec:discussion}

In the current paper, we presented the GLMM tree algorithm, which allows for the estimation of a GLM-based recursive partition, as well as the estimation of random-effects parameters. Therefore, the GLMM tree algorithm seems preeminently suited for the detection of treatment-subgroup interactions in clustered datasets. In the empirical evaluation, we have assessed the performance of GLMM tree in a large number of simulated dataets, and compared it with GLM tree, an algorithm that creates GLM-based recursive partitions, without estimating random effects. In the application, we applied GLM and GLMM tree to an existing dataset of a patient-level dataset of a meta-analysis on the effects of psycho- and pharmacotherapy for depression. The application showed that GLMM tree provides results that are easily interpretable, and also more accurate than a GLM tree without random effects.

The results of our simulation study show that GLMM tree performed very well in recovering treatment-subgroup interactions, as it accurately recovered the interactions in 90\% of the simulated datasets with treatment-subgroup interactions. In contrast, GLM tree accurately recovered the interactions in only 61\% of the datasets with treatment-subgroup interactions. In the absence of treatment-subgroup interactions, GLMM tree erroneously detected subgroups in only 4\% of the datasets, whereas GLM tree erroneously detected subgroups in 33\% of those datasets. In other words, the Type I error rate of GLMM tree very closely resembled the $\alpha$ level used for evaluating significance of parameter instability, whereas the Type I error rate of GLM tree clearly exceeded this value. 

The better performance of GLMM tree was mostly observed when random effects in the datasets were sizable, and random intercepts were correlated with potential partitioning variables. In these instances, the random effects gave rise to spurious subgroup detection (spurious splits) by GLM tree, both in datasets with and without treatment-subgroup interactions. 

Predictive accuracy of GLMM tree was also higher than that of GLM tree. The average correlation between the true treatment differences and those predicted by GLMM tree was .94. The average correlation between the true treatment differences and those predicted by GLM tree was .88. In terms of predictive accuracy, GLMM tree clearly outperformed GLM tree when random effects in the datasets were sizable, and the differences in treatment effects were relatively small (i.e., $d=.5$).

As expected, when random effects were absent from the simulated datasets, GLM tree and GLMM tree showed high and equal predictive accuracy. This finding indicates that GLMM tree can be applied, whenever cluster-specific random effects are expected. In the absence of random effects, GLM tree and GLMM tree are expected to perform equally well, and in the presence of random effects, GLMM tree will outperform GLM tree. This may especially be the case with large sample sizes ($N > 200$), as the increased power will likely cause GLM tree to create spurious splits, when random effects are present in the data. 

Not surprisingly, for both algorithms, accuracy of predicted treatment differences was less when sample size was low (i.e., $N=200$). Sample size influenced performance of GLM and GLMM tree similarly, suggesting that a larger number of estimated parameters for GLMM tree does not adversely influences accuracy at low sample sizes. Our simulation results do warrant some caution for the detection of treatment-subgroup interactions or treatment moderators in small datasets (e.g., single RCTs), but irrespective of the algorithm used.  

These findings are encouraging for the use of GLMM tree in the detection of treatment-subgroup interactions in datasets with clustered structures. However, it should be noted that the simulations show that GLMM tree performs very well, if the model is correctly specified. That is, if there are subgroups with respect to the partitioning variables, so that there are different parameters of the GLM in each of these subgroups, then GLMM tree will accurately recover those subgroups. However, misspecification of the model can reduce performance. One source of misspecification would be, when relevant variables are not included in the GLM or as partitioning variables. If there are actual subgroups, but the variables describing them are not entered as partitioning variables, the algorithm can only approximate the subgroups using the partitioning variables that are available. Or, if the coefficients of other variables vary across subgroups, then those variables should also be included in the linear predictor of the GLM. Another source of misspecification would be the inclusion of irrelevant variables, either in the linear predictor of the GLM or as partitioning variables, which may reduce the power to detect the actual subgroups. However, it should be noted that in our simulations, the number of partitioning variables did not substantially influence performance of the algorithm(s). 

In conclusion, GLMM tree provided highly accurate recovery of treatment-subgroup interactions and predictions of treatment effect differences, both in the presence and absence of cluster-specific random effects. Therefore, GLMM tree is a promising algorithm for the detection of treatment-subgroup interactions in datasets with a clustered structure, like for example in multi-center trials, individual-level patient data meta-analyses, and longitudinal studies.

\section*{Acknowledgments}

The authors would like to thank Prof.~Pim Cuijpers, Prof.~Jeanne Miranda, Dr.~Boadie Dunlop, Prof.~Rob DeRubeis, Prof.~Zindel Segal, Dr.~Sona Dimidjian, Prof.~Steve Hollon and Erica Weitz,~MA, for granting access to the dataset for the application. The work for this paper was partially done while MF, AZ and TH were visiting the Institute for Mathematical Sciences, National University of Singapore in 2014. The visit was supported by the Institute.

\bibliography{ref}

\begin{appendix}
\section{Notation}

\begin{tabular}{lp{11cm}}
$1,\dots,i,\dots,N$ & {observation number}\\
$1,\dots,j,\dots,J$ & {terminal node number in a tree}\\
$1,\dots,k,\dots,K$ & {partitioning variable number}\\
$1,\dots,m,\dots,M$ & {cluster number}\\
$\beta_{j}$	 & {column vector of fixed-effects coefficients in terminal node $j$}\\
$b_{m}$ 	 & {column vector of random-effects coefficients in cluster $m$}\\
$d_{j}$		 & {$\beta_{j1} / \sigma_{\epsilon}$; effect size of treatment-effect differences between Treatment~1 and Treatment~2 in terminal node $j$}\\
$\epsilon$	 & {deviation of observed treatment outcome $y$ from its expected value}\\
$r$		 & {iteration number}\\
$\sigma_{b}$	 & {standard deviation of $b$}\\
$\sigma_{\epsilon}$ & {standard deviation of $\epsilon$}\\
$U_k$		 & {(potential) partitioning variable $k$}\\
$x_i$ 		 & {column vector of fixed-effects predictor variable values for observation~$i$}\\
$y_i$ 		 & {treatment outcome for observation $i$}\\
$z_i$ 		 & {column vector of random-effects predictor variable values for observation~$i$}\\
\end{tabular}

\end{appendix}

\end{document}
