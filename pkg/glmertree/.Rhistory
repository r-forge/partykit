# combine linear terms and rules:
newdata <- cbind(newdata, newrulevars)
colnames(newdata)
model.frame(bdi ~., data = newdata[,-1])
model.frame(bdi ~., data = newdata)
newdata
colnames(newdata)
newdata <- cardata.fac
newdata <- model.frame(object$call$formula, newdata)
newdata
newdata <- cardata.fac
all(unlist(sapply(object$data, levels)) ==
unlist(sapply(newdata[names(object$data)], levels)))
newdata <- cardata.fac
if(is.null(newdata)) {
newdata <- model.frame(object$call$formula, object$data)
# check if newdata has the same columns as object$data, and if they are from
} else {
# the same class:
if(!all(names(object$data) %in% names(newdata))) {
stop("newdata does not contain all predictor variables from the ensemble")
} else {
# check if all variables have the same levels:
newdata[,object$y_name] <- NA
newdata <- model.frame(object$call$formula, newdata)
if(!all(unlist(sapply(object$data, levels)) ==
unlist(sapply(newdata[names(object$data)], levels)))) {
stop("At least one variable in newdata is has different levels than the
variables used to create the ensemble")
}
}
}
# evaluate all rules with non-zero coefficients for the new dataset:
coefs <- as(coef.glmnet(object$glmnet.fit, s = penalty.par.val),
Class = "matrix")
if(object$type != "linear") {
# get names of rules with nonzero coefficients (-1 is for removing intercept):
nonzerorulenames <- names(coefs[coefs!=0,])[grep("rule", names(coefs[coefs!=0,]))]
if(length(nonzerorulenames) > 0) {
nonzerorules <- as.character(
object$rules$description[object$rules$rule %in% nonzerorulenames])
newrulevars <- data.frame(r1 = as.numeric(with(newdata, eval(parse(
text = nonzerorules[1])))))
names(newrulevars) <- nonzerorulenames[1]
if(length(nonzerorulenames)>1) {
for(i in 2:length(nonzerorules)) {
newrulevars[,nonzerorulenames[i]] <- as.numeric(
with(newdata, eval(parse(text = nonzerorules[i]))))
}
}
}
# set all rules with zero coefficients to 0:
zerorulenames <- names(coefs[coefs==0,])[grep("rule", names(coefs[coefs==0,]))]
if(length(zerorulenames) > 0) {
newrulevars[,zerorulenames] <- 0
}
}
# linear terms normalized before application of glmnet should also be
# normalized prior to applying predict.glmnet:
newdata
newdata <- cardata
if(is.null(newdata)) {
newdata <- model.frame(object$call$formula, object$data)
} else {
# check if newdata has the same columns as object$data, and if they are from
# the same class:
if(!all(names(object$data) %in% names(newdata))) {
stop("newdata does not contain all predictor variables from the ensemble")
} else {
# check if all variables have the same levels:
newdata[,object$y_name] <- NA
newdata <- model.frame(object$call$formula, newdata)
if(!all(unlist(sapply(object$data, levels)) ==
unlist(sapply(newdata[names(object$data)], levels)))) {
stop("At least one variable in newdata is has different levels than the
variables used to create the ensemble")
}
}
}
newdata
newdata <- cardata
newdata
newdata[,object$y_name]
newdata[,object$y_name] <- NA
newdata
newdata <- model.frame(object$call$formula, newdata)
newdata
newdata <- cardata
newdata[,object$y_name] <- 1
newdata <- model.frame(object$call$formula, newdata)
newdata
tmp <- 1:3
class(tmp)
class(tmp) <- "factor"
tmp
is.numeric(tmp)
1:3
tmp
?class
is.numeric(1:#)
is.numeric(1:3)
is.interger(1:3)
is.integer(1:3)
factor(NA)
cardata.fac$open4
cardata.fac$open4[1]
tmp <- data.frame(open4 = NA, bliep = 1:6)
tmp$open4 <- cardata.fac$open4[1]
tmp
tmp$open4
newdata[,object$y_name] <- object$data[,y_name][1]
newdata <- model.frame(object$call$formula, newdata)
newdata
newdata <- cardata
if(is.null(newdata)) {
newdata <- model.frame(object$call$formula, object$data)
} else {
# check if newdata has the same columns as object$data, and if they are from
# the same class:
if(!all(names(object$data) %in% c(names(newdata), object$y_name))) {
stop("newdata does not contain all predictor variables from the ensemble")
} else {
newdata[,object$y_name] <- object$data[,y_name][1]
newdata <- model.frame(object$call$formula, newdata)
# check if all variables have the same level:
if(!all(unlist(sapply(object$data, levels)) ==
unlist(sapply(newdata[names(object$data)], levels)))) {
stop("At least one variable in newdata is has different levels than the
variables used to create the ensemble")
}
}
}
# evaluate all rules with non-zero coefficients for the new dataset:
coefs <- as(coef.glmnet(object$glmnet.fit, s = penalty.par.val),
Class = "matrix")
if(object$type != "linear") {
# get names of rules with nonzero coefficients (-1 is for removing intercept):
nonzerorulenames <- names(coefs[coefs!=0,])[grep("rule", names(coefs[coefs!=0,]))]
if(length(nonzerorulenames) > 0) {
nonzerorules <- as.character(
object$rules$description[object$rules$rule %in% nonzerorulenames])
newrulevars <- data.frame(r1 = as.numeric(with(newdata, eval(parse(
text = nonzerorules[1])))))
names(newrulevars) <- nonzerorulenames[1]
if(length(nonzerorulenames)>1) {
for(i in 2:length(nonzerorules)) {
newrulevars[,nonzerorulenames[i]] <- as.numeric(
with(newdata, eval(parse(text = nonzerorules[i]))))
}
}
}
# set all rules with zero coefficients to 0:
zerorulenames <- names(coefs[coefs==0,])[grep("rule", names(coefs[coefs==0,]))]
if(length(zerorulenames) > 0) {
newrulevars[,zerorulenames] <- 0
}
}
# linear terms normalized before application of glmnet should also be
# normalized prior to applying predict.glmnet:
if(object$normalize) {
newdata[,names(object$x_scales)] <- scale(
newdata[,names(object$x_scales)], center = FALSE, scale = object$x_scales)
}
newdata[,sapply(newdata, is.ordered)] <- as.numeric(as.character(
newdata[,sapply(newdata, is.ordered)]))
# convert unordered factors to dummy variables:
if(any(sapply(object$data[,object$x_names], is.factor))) {
newdata <- model.matrix(formula(paste(paste(object$y_name, " ~ "), paste(
object$x_names, collapse = "+"))), data = newdata)
}
newdata <- cbind(newdata, newrulevars)
?model.matrix
newdata <- model.matrix(formula(paste(paste(object$y_name, " ~ "), paste(
object$x_names, collapse = "+"))), data = newdata)
newdata <- cardata
if(is.null(newdata)) {
newdata <- model.frame(object$call$formula, object$data)
} else {
# check if newdata has the same columns as object$data, and if they are from
# the same class:
if(!all(names(object$data) %in% c(names(newdata), object$y_name))) {
stop("newdata does not contain all predictor variables from the ensemble")
} else {
newdata[,object$y_name] <- object$data[,y_name][1]
newdata <- model.frame(object$call$formula, newdata)
# check if all variables have the same level:
if(!all(unlist(sapply(object$data, levels)) ==
unlist(sapply(newdata[names(object$data)], levels)))) {
stop("At least one variable in newdata is has different levels than the
variables used to create the ensemble")
}
}
}
# evaluate all rules with non-zero coefficients for the new dataset:
coefs <- as(coef.glmnet(object$glmnet.fit, s = penalty.par.val),
Class = "matrix")
if(object$type != "linear") {
# get names of rules with nonzero coefficients (-1 is for removing intercept):
nonzerorulenames <- names(coefs[coefs!=0,])[grep("rule", names(coefs[coefs!=0,]))]
if(length(nonzerorulenames) > 0) {
nonzerorules <- as.character(
object$rules$description[object$rules$rule %in% nonzerorulenames])
newrulevars <- data.frame(r1 = as.numeric(with(newdata, eval(parse(
text = nonzerorules[1])))))
names(newrulevars) <- nonzerorulenames[1]
if(length(nonzerorulenames)>1) {
for(i in 2:length(nonzerorules)) {
newrulevars[,nonzerorulenames[i]] <- as.numeric(
with(newdata, eval(parse(text = nonzerorules[i]))))
}
}
}
# set all rules with zero coefficients to 0:
zerorulenames <- names(coefs[coefs==0,])[grep("rule", names(coefs[coefs==0,]))]
if(length(zerorulenames) > 0) {
newrulevars[,zerorulenames] <- 0
}
}
# linear terms normalized before application of glmnet should also be
# normalized prior to applying predict.glmnet:
if(object$normalize) {
newdata[,names(object$x_scales)] <- scale(
newdata[,names(object$x_scales)], center = FALSE, scale = object$x_scales)
}
# convert ordered categorical predictor variables to linear terms:
newdata[,sapply(newdata, is.ordered)] <- as.numeric(as.character(
newdata[,sapply(newdata, is.ordered)]))
names(newdata)
newdata <- model.matrix(formula(paste(paste(object$y_name, " ~ "), paste(
object$x_names, collapse = "+"))), data = newdata)
names(newdata)
colnames(newdata)
source("C:/Users/tobii/Desktop/swReg/upre/R/upre.R")
cor(preds, cardata$bdi[101:111])
preds <- predict(car.ens, newdata = cardata[101:111,])
tmpdata <- data.frame(x1 = 1:6, x2 = c(TRUE, FALSE), y = 1:3)
tmpdata
tmpmodframe <- model.frame(y ~ x1+x2)
tmpmodframe <- model.frame(y ~ x1+x2, data = tmpdata)
tmpdata <- data.frame(y = 1:8, x1 = c(1:4, 1:4), x2 = c(TRUE, FALSE),
x3 = factor(letters[1:2]), x4 = factor(1:3, ordered = TRUE)
)
tmpdata <- data.frame(y = 1:8, x1 = c(1:4, 1:4),
x2 = rep(c(TRUE, FALSE), times = 2),
x3 = factor(rep(letters[1:2], times = 4),
x4 = factor(rep(1:4, times = 2), ordered = TRUE))
)
rep(1:4, times = 2)
tmpdata <- data.frame(y = 1:8, x1 = c(1:4, 1:4),
x2 = rep(c(TRUE, FALSE), times = 2),
x3 = factor(rep(letters[1:2], times = 4)),
x4 = factor(rep(1:4, times = 2), ordered = TRUE))
)
tmpdata <- data.frame(y = 1:8, x1 = c(1:4, 1:4),
x2 = rep(c(TRUE, FALSE), times = 2),
x3 = factor(rep(letters[1:2], times = 4)),
x4 = factor(rep(1:4, times = 2), ordered = TRUE))
formula <- y ~ x1 + x2 + x3 + x4
tmpframe <- model.frame(formula, tmpdata)
tmpframe
tmpmodmat <- model.matrix(formula, tmpdata)
tmpmodmat
exdata <- data.frame(y = 1:8, x1 = c(1:4, 1:4),
x2 = rep(c(TRUE, FALSE), times = 2),
x3 = factor(rep(letters[1:2], times = 4)),
x4 = factor(rep(1:4, times = 2), ordered = TRUE))
exformula <- y ~ x1 + x2 + x3 + x4
exmodframe <- model.frame(formula, exdata)
exmodframe
exmodmat1 <- model.matrix(exformula, exdata)
exmodmat1
exmodmat2 <- model.matrix(exformula, exmodframe)
exmodmat2
exmodmat1 == exmodmat2
sapply(exmodframe, class)
sapply(exmodmat1, class)
apply(exmodmat1, 2, class)
exmodmat2 <- model.matrix(exformula, exmodframe)
exmodmat2
apply(exmodmat2, 2, class)
## Create example dataset:
exdata <- data.frame(y = 1:8, x1 = c(1:4, 1:4),
x2 = rep(c(TRUE, FALSE), times = 2),
x3 = factor(rep(letters[1:2], times = 4)),
x4 = factor(rep(1:4, times = 2), ordered = TRUE))
## Create example dataset and model formula:
exdata <- data.frame(y = 1:8, x1 = c(1:4, 1:4),
x2 = rep(c(TRUE, FALSE), times = 2),
x3 = factor(rep(letters[1:2], times = 4)),
x4 = factor(rep(1:4, times = 2), ordered = TRUE))
exformula <- y ~ x1 + x2 + x3 + x4
##
exmodframe <- model.frame(formula, exdata)
exmodframe
sapply(exmodframe, class)
exmodframe <- model.frame(formula, exdata)
exmodframe
sapply(exmodframe, class)
## Create example dataset and model formula:
exdata <- data.frame(y = 1:8, x1 = c(1:4, 1:4),
x2 = rep(c(TRUE, FALSE), times = 2),
x3 = factor(rep(letters[1:2], times = 4)),
x4 = factor(rep(1:4, times = 2), ordered = TRUE))
exformula <- y ~ x1 + x2 + x3 + x4
## Create an example model.frame:
exmodframe <- model.frame(formula, exdata)
exmodframe
sapply(exmodframe, class)
## Create an example model.frame:
exmodmat1 <- model.matrix(exformula, exdata)
exmodmat1
apply(exmodmat1, 2, class)
## It does not make a difference if we create a model.matrix directly from the
## data, instead of from a model.frame of the data:
exmodmat2 <- model.matrix(exformula, exmodframe)
exmodmat2
apply(exmodmat2, 2, class)
exmodmat1 == exmodmat2
exmodframe
apply(exmodmat1, 2, class)
library(partykit)
library(glmnet)
source("C:/Users/tobii/Desktop/swReg/upre/R/upre.R")
## test on air quality data:
airq <- airquality[complete.cases(airquality),]
dim(airq)
airq.ens <- upre(Ozone ~ ., data=airq)
coef(airq.ens$glmnet.fit, s="lambda.min")
predict(airq.ens)
plot(airq.ens$glmnet.fit)
## test on psychological data:
library(foreign)
cardata <- read.spss("data Carillo et al.sav", to.data.frame = TRUE)
summary(cardata)
car.ens <- upre(bdi ~ ., data=cardata[1:100,])
plot(car.ens$glmnet.fit)
coefs <- coef(car.ens)
# something going wrong here:
preds <- predict(car.ens, newdata = cardata[101:111,])
cor(preds, cardata$bdi[101:111])
cor(preds, cardata$bdi[101:111])^2 * var(cardata$bdi[101:111])
coefs
singleplot(car.ens, "ntot")
pairplot(car.ens, c("n3","ntot"))
?contr.poly
library(partykit)
library(glmnet)
source("C:/Users/tobii/Desktop/swReg/upre/R/upre.R")
## test on air quality data:
airq <- airquality[complete.cases(airquality),]
dim(airq)
airq.ens <- upre(Ozone ~ ., data=airq)
coef(airq.ens$glmnet.fit, s="lambda.min")
predict(airq.ens)
plot(airq.ens$glmnet.fit)
## test on psychological data:
library(foreign)
cardata <- read.spss("data Carillo et al.sav", to.data.frame = TRUE)
summary(cardata)
car.ens <- upre(bdi ~ ., data=cardata[1:100,])
plot(car.ens$glmnet.fit)
coefs <- coef(car.ens)
# something going wrong here:
preds <- predict(car.ens, newdata = cardata[101:111,])
cor(preds, cardata$bdi[101:111])
cor(preds, cardata$bdi[101:111])^2 * var(cardata$bdi[101:111])
coefs
singleplot(car.ens, "ntot")
pairplot(car.ens, c("n3","ntot"))
library(partykit)
library(glmnet)
source("C:/Users/tobii/Desktop/swReg/upre/R/upre.R")
## test on air quality data:
airq <- airquality[complete.cases(airquality),]
dim(airq)
airq.ens <- upre(Ozone ~ ., data=airq)
coef(airq.ens$glmnet.fit, s="lambda.min")
predict(airq.ens)
plot(airq.ens$glmnet.fit)
library(foreign)
cardata <- read.spss("data Carillo et al.sav", to.data.frame = TRUE)
summary(cardata)
car.ens <- upre(bdi ~ ., data=cardata[1:100,])
plot(car.ens$glmnet.fit)
coefs <- coef(car.ens)
# something going wrong here:
preds <- predict(car.ens, newdata = cardata[101:111,])
cor(preds, cardata$bdi[101:111])
cor(preds, cardata$bdi[101:111])^2 * var(cardata$bdi[101:111])
coefs
singleplot(car.ens, "ntot")
pairplot(car.ens, c("n3","ntot"))
cardata.fac <- cardata
cardata.fac[,"open4"] <- factor(cut(cardata.fac[,"open4"], breaks = 8, labels = FALSE))
sapply(cardata.fac, is.factor)
car.ens.fac <- upre(bdi ~ ., data=cardata.fac[1:100,])
plot(car.ens$glmnet.fit)
coefs <- coef(car.ens.fac)
predict(car.ens.fac, newdata = cardata.fac[101:111,])
object <- airq.ens
newdata <- airq[,1:5]
penalty.par.val = "lambda.min"
newdata
newdata <- airq[1:5,]
newdata
if(is.null(newdata)) {
newdata <- model.frame(object$call$formula, object$data)
} else {
# check if newdata has the same columns as object$data, and if they are from
# the same class:
if(!all(names(object$data) %in% c(names(newdata), object$y_name))) {
stop("newdata does not contain all predictor variables from the ensemble")
} else {
newdata[,object$y_name] <- object$data[,object$y_name][1]
newdata <- model.frame(object$call$formula, newdata)
# check if all variables have the same levels:
if(!all(unlist(sapply(object$data, levels)) ==
unlist(sapply(newdata[names(object$data)], levels)))) {
stop("At least one variable in newdata is has different levels than the
variables used to create the ensemble")
}
}
}
newdata
coefs <- as(coef.glmnet(object$glmnet.fit, s = penalty.par.val),
Class = "matrix")
coefs
if(object$type != "linear") { # if there are any rules in the ensemble:
# get names of rules with nonzero coefficients (-1) is for removing intercept):
nonzerorulenames <- names(coefs[coefs!=0,])[grep("rule", names(coefs[coefs!=0,]))]
if(length(nonzerorulenames) > 0) {
nonzerorules <- as.character(
object$rules$description[object$rules$rule %in% nonzerorulenames])
newrulevars <- data.frame(r1 = as.numeric(with(newdata, eval(parse(
text = nonzerorules[1])))))
names(newrulevars) <- nonzerorulenames[1]
if(length(nonzerorulenames)>1) {
for(i in 2:length(nonzerorules)) {
newrulevars[,nonzerorulenames[i]] <- as.numeric(
with(newdata, eval(parse(text = nonzerorules[i]))))
}
}
}
# set all rules with zero coefficients to 0:
zerorulenames <- names(coefs[coefs==0,])[grep("rule", names(coefs[coefs==0,]))]
if(length(zerorulenames) > 0) {
newrulevars[,zerorulenames] <- 0
}
newdata <- cbind(newdata, newrulevars)
}
newdata
object$formula
object$call$formula
# convert ordered categorical variables to numeric variables:
newdata[,sapply(newdata, is.ordered)] <- as.numeric(as.character(
newdata[,sapply(newdata, is.ordered)]))
newdata
names(newdata)
if(object$normalize) {
newdata[,names(object$x_scales)] <- scale(
newdata[,names(object$x_scales)], center = FALSE, scale = object$x_scales)
}
names(newdata)
newdata
newdata <- model.matrix(formula(paste(paste(object$y_name, " ~ "), paste(
colnames(newdata), collapse = "+"))), data = newdata))
paste(paste(object$y_name, " ~ "), paste(
colnames(newdata), collapse = "+")))
paste(paste(object$y_name, " ~ "), paste(
colnames(newdata), collapse = "+")
)
colnames(object$modmat)
formula(paste(paste(object$y_name, " ~ "), paste(
c(names(object$rulevars, object$x_names), collapse = "+")))
)
formula(paste(paste(object$y_name, " ~ "), paste(
c(names(object$rulevars), object$x_names), collapse = "+")))
newdata
newdata <- model.matrix(formula(paste(paste(object$y_name, " ~ "), paste(
c(object$x_names, names(object$rulevars)), collapse = "+"))), data = newdata)
newdata <- Matrix::Matrix(as.matrix(newdata), sparse = TRUE)
# Get predictions:
predict.cv.glmnet(object$glmnet.fit, newx = newdata, s = penalty.par.val)
source("C:/Users/tobii/Desktop/swReg/upre/R/upre.R")
predict(airq.ens)
plot(airq.ens$glmnet.fit)
## test on psychological data:
preds <- predict(car.ens, newdata = cardata[101:111,])
cor(preds, cardata$bdi[101:111])
cor(preds, cardata$bdi[101:111])^2 * var(cardata$bdi[101:111])
coefs
singleplot(car.ens, "ntot")
pairplot(car.ens, c("n3","ntot"))
# convert a var to factor and see what happens:
cardata.fac <- cardata
cardata.fac[,"open4"] <- factor(cut(cardata.fac[,"open4"], breaks = 8, labels = FALSE))
sapply(cardata.fac, is.factor)
car.ens.fac <- upre(bdi ~ ., data=cardata.fac[1:100,])
plot(car.ens$glmnet.fit)
coefs <- coef(car.ens.fac)
predict(car.ens.fac, newdata = cardata.fac[101:111,])
setwd("C:/Users/tobii/Desktop/swReg")
library(devtools)
library(roxygen2)
setwd("./upre")
document()
setwd("..")
check("upre")
setwd("./upre")
document()
setwd("..")
check("upre")
