\documentclass[nojss]{jss}

%\VignetteIndexEntry{Detecting Treatment-Subgroup Interactions With Generalized Linear Mixed-Effects Model Trees}
%\VignetteDepends{glmertree}
%\VignetteKeywords{mixed-effects model trees, recursive partitioning, decision trees}
%\VignettePackage{glmertree}

%% packages
\usepackage{amstext}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{thumbpdf}
\usepackage{rotating}
\usepackage{subfig}

\title{Detecting Treatment-Subgroup Interactions with Generalized Linear Mixed-Effects Model Trees}
\Shorttitle{Generalized Linear Mixed-Effects Model Trees}
\author{Marjolein Fokkema\\Universiteit Leiden \And Achim Zeileis\\Universit\"at Innsbruck}
\Plainauthor{Marjolein Fokkema, Achim Zeileis}

\Abstract{
This vignette describes how generalized linear mixed-effects model trees (glmertrees or GLMM trees) can be fit. In the example, trees are fit to detect treatment-subgroup interactions in clustered datasets, which is only one possible application. The \code{glmertree} package allows for fitting a wider range of partitioned generalized linear mixed-effects models. 
}

\Keywords{recursive partitioning, mixed-effects model trees, decision trees}

\Address{
  Marjolein Fokkema\\
  Department of Methods \& Statistics, Intitute of Psychology\\
  Universiteit Leiden\\
  Wassenaarseweg 52\\
  2333 AK Leiden, The Netherlands\\
  E-mail: \email{m.fokkema@fsw.leidenuniv.nl}\\
  URL: \url{http://www.marjoleinfokkema.nl/}\\
  \\
  Achim Zeileis \\
  Department of Statistics \\
  Faculty of Economics and Statistics \\
  Universit\"at Innsbruck \\
  Universit\"atsstr.~15 \\
  6020 Innsbruck, Austria \\
  E-mail: \email{Achim.Zeileis@R-project.org} \\
  URL: \url{http://eeecon.uibk.ac.at/~zeileis/} \\
}


\begin{document}

\SweaveOpts{engine=R, keep.source=TRUE}

\section{Introduction}

This vignette describes how generalized linear mixed-effects model trees (glmertrees or GLMM trees) can be fit, to detect treatment-subgroup interactions in clustered datasets. In the example, we assess main and interaction effects of a categorical variable (treatment) on a continuous response (treatment outcome). The \code{glmertree} package may be used to detect predictors and moderators in a wider range of generalized linear mixed-effects models. For example, the response variable may be categorical, predictor variables may be continuous, or the interest may be in assessing main and interaction effects of multiple predictor variables at once. 

Generalized linear mixed-effects model trees estimate a global random-effects model, using all training observations. The fixed-effects model is estimated locally: the dataset is partitoned with respect to additional covariates or partitioning variables and a fixed-effects model is estimated in each cell of the partition. The \code{glmertree} package makes use of the \code{partykit} package \cite{HothyZeil15} to find the partition and the \code{lme4} package \cite{BateyMeac15} to fit the mixed-effects model. The mixed-effects model tree framework is described in more detail in \cite{FokkySmit15}.

The current CRAN version of the package can be installed as follows:

<<eval = FALSE, echo = TRUE>>=
install.packages("glmertree", repos="http://R-Forge.R-project.org")
@

Alternatively, the current development version can be installed from R-Forge:

<<eval = FALSE, echo = TRUE>>=
install.packages("glmertree")
@

After installation, the package can be loaded as follows:

<<eval = TRUE, echo = FALSE>>=
library("glmertree")
@


\section{Fitting and interpreting mixed-effects model trees}

The main functions in the \code{glmertree} package are \code{lmertree()}, for continuous outcome variables, and \code{glmertree()}, for binary or count outcome variables. Both functions require the user to specify at least two arguments: \code{formula} and \code{data}. We will use an artificial motivating dataset from \cite{FokkySmit15}, which can be recreated using the code provided in the Appendix, or can be loaded as follows: 

<<echo = TRUE, eval = TRUE>>=
data(DepressionDemo)
summary(DepressionDemo)
@

The dataset includes seven variables: A continuous response variable (\code{depression}), a predictor variable for the linear model (\code{treatment}), three potential partitioning variables (\code{age}, \code{anxiety}, \code{duration}), an indicator for cluster (\code{cluster}) and a binarized response variable (\code{depression_bin}).

The model formula to be specified consists of a left- and right hand side. The left hand side of the model formula (preceding the tilde symbol) specifies the outcome variable. The right hand side consists of three parts, separated by vertical bars: The first part specifies the predictor variable(s) of the (generalized) linear model, the second part specifies the random effects and the third part specifies the potential partitioning variables:

<<eval = TRUE, echo = TRUE>>=
## Continuous response variable:
lmm_tree <- lmertree(depression ~ treatment | cluster | age + duration + 
                              anxiety, data = DepressionDemo)
@

Note that in the example above, the partitioning variables are continuous, but (ordered) categorical partitioning variables may also be specified. Also, we specified only a single variable in the random-effects part, resulting in estimation of a random intercept with respect to \code{cluster}. More complex random effects can also be specified: for example, specifying the random-effects part as \code{(1 + age | cluster)} would yield a model with a random intercept as well as a random slope for age with respect to cluster. The brackets are necessary to protect the vertical bars in the formulation of the randomeffects.

Alternativelty, using the \code{glmertree()} function, a tree may be fitted to binary or count response variables. To fit a model to a count response variable, the \code{family} argument has to be set to \code{"poisson"}. By default, a binary response is assumed and the \code{family} argument is set to \code{"binomail"}:

<<eval = TRUE, echo = TRUE>>=
## Binary response variable:
glmm_tree <- glmertree(depression_bin ~ treatment | cluster | age + duration +
                              anxiety, data = DepressionDemo)
@

Using the \code{plot} method, we can plot the resulting tree and random effects:

<<eval = FALSE, echo = TRUE>>=
plot(lmm_tree)
@

\begin{figure}[h!]
\centering
\setkeys{Gin}{width=0.8\textwidth}
<<eval = TRUE, echo = FALSE, fig = TRUE, width = 9, height = 7>>=
plot(lmm_tree, which = "tree")
@
\caption{\label{fig:tree} Linear mixed-effects model tree}
\end{figure}

\begin{figure}[h!]
\centering
\setkeys{Gin}{width=0.5\textwidth}
<<echo = FALSE, results = hide, fig = TRUE>>=
plot(lmm_tree, which = "ranef")
@
\caption{\label{fig:ranef} Random effects}
\end{figure}

Using the argument \code{which}, we can also specify which part of the model should be plotted: \code{which = "tree"} plots only the tree, \code{which = "ranef"} plots only the predicted random effects and \code{which = "all"} (the default) plots the tree as well as the random effects. 

The plotted tree is depicted in Figure~\ref{fig:tree}. In every inner node of the plotted tree, the splitting variable and corresponding p-value from the parameter stability test is reported. To control for multiple testing, the p-values are Bonferroni corrected, by default. This can be turned off by adding \code{bonferroni = FALSE} to the function call, yielding a less conservative criterion for the parameter stability tests, but note that this will increase the likelihood of overfitting. The significance level $\alpha$ equals .05 by default, but a different value, say for example .01, can be specified by including \code{alpha = .01} in the function call.  

The plotted tree shows that there are three subgroups with differential treatment effectiveness: node 3 indicates that for patients with lower duration and lower anxiety, Treatment 1 leads to lower post-treatment depression. Node 4 indicates that for patients with lower duration and higher anxiety, both treatments yield more or less the same expected outcome. Node 5 indicates, that for patients with higher duration, Treatment 2 leads to lower post-treatment depression.

The predicted random effects are plotted in Figure~\ref{fig:ranef}. Patients from cluster 10 have somewhat higher expected post-treatment depression scores, whereas patients from cluster 4 have somewhat lower expected post-treatment depression scores.

To obtain numerical results, \code{print}, \code{coef} and \code{ranef} methods are available:

<<echo = TRUE, eval = TRUE>>=
print(lmm_tree)
coef(lmm_tree)
ranef(lmm_tree)
@

To obtain predicted values, the \code{predict} method can be used: 

<<echo = TRUE, eval = TRUE>>=
predict(lmm_tree, newdata = DepressionDemo[1:7,])
@

When \code{newdata} is not specified, predictions for the training observations are returned, by default. Random effects can be excluded from the predictions by adding \code{re.form = NA}. This is useful, for example, when \code{newdata} is specified, but the new observations do not have a cluster indicator or are from new clusters:

<<echo = TRUE, eval = TRUE>>=
predict(lmm_tree, newdata = DepressionDemo[1:7, -3], re.form = NA)
@


\section{Inspecting residuals}

Residuals of the fitted GLMM tree can be obtained with the \code{residuals} method. This can be useful for assessing potential misspecification of the model (e.g., heteroscedasticity):

<<eval = FALSE, echo = TRUE>>=
resids <- residuals(lmm_tree)
preds <- predict(lmm_tree)
plot(DepressionDemo$cluster, resids)
scatter.smooth(preds, resids)
@


\begin{figure}[h!]
\setkeys{Gin}{width=0.5\textwidth}
\centering
\subfloat{
<<eval = TRUE, echo = FALSE, fig = TRUE>>=
resids <- residuals(lmm_tree)
preds <- predict(lmm_tree)
plot(DepressionDemo$cluster, resids, xlab = "Cluster indicator", ylab = "Residuals")
@
}
\subfloat{
<<eval = TRUE, echo = FALSE, fig = TRUE>>=
scatter.smooth(preds, resids, xlab = "Predicted values", ylab = "Residuals")
@
}
\caption{\label{fig:residuals} Residuals of the fitted linear mixed-effects model tree}
\end{figure}

The plotted residuals are depicted in Figure~\ref{fig:residuals}. The first plot does not indicate substantial variation in error variances across levels of the random effects. The second plot of fitted values against residuals also does not reveal a pattern indicating model misspecification.



\bibliography{glmertree}

\section*{Appendix}

\subsection*{R code for generating artificial motivating dataset}

<<appendixA_1, echo = TRUE>>=
## Generate predictor variables:
set.seed(123)
treatment <- rbinom(n = 150, size = 1, prob = .5)
duration <- round(rnorm(150, mean = 7, sd = 3))
anxiety <- round(rnorm(150, mean = 10, sd = 3))
age <- round(rnorm(150, mean = 45, sd = 10))
## Generate error:
error <- rnorm(150, 0, 2)
## Generate random intercepts:
cluster <- error + rnorm(150, 0, 6)
rand_int <- sort(rep(rnorm(10, 0, 1), each = 15))
rand_int[order(cluster)] <- rand_int 
error <- error - rand_int
cluster[order(cluster)] <- rep(1:10, each = 15)
## Generate treatment subgroups:
node3t1 <- ifelse(duration <= 8 & anxiety <= 10 & treatment == 0, -2, 0)
node3t2 <- ifelse(duration <= 8 & anxiety <= 10 & treatment == 1, 2, 0)
node5t1 <- ifelse(duration > 8 & treatment == 0, 2.5, 0)
node5t2 <- ifelse(duration > 8 & treatment == 1, -2.5, 0)
## Generate continuous outcome variable:
depression <- round(9 + node3t1 + node3t2 + node5t1 + node5t2 + .4*treatment + 
                   error + rand_int)
## Generate dichotomous outcome variables:
depression_bin <- factor(as.numeric(depression > 9))
## Make treatment indicator a factor:
treatment <- factor(treatment, labels = c("Treatment 1", "Treatment 2"))
## Combine variables in a dataframe:
DepressionDemo <- data.frame(depression, treatment, cluster, age, anxiety, 
                             duration, depression_bin)
@


\end{document}
