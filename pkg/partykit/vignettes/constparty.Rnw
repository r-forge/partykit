\documentclass[nojss]{jss}

%\VignetteIndexEntry{partykit: A Toolkit for Recursive Partytioning}
%\VignetteDepends{partykit, rpart, RWeka, pmml, datasets}
%\VignetteKeywords{recursive partitioning, regression trees, classification trees, decision trees}
%\VignettePackage{partykit}

%% packages
\usepackage{amstext}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{thumbpdf}
\usepackage{rotating}
%% need no \usepackage{Sweave}

%% additional commands
\newcommand{\squote}[1]{`{#1}'}
\newcommand{\dquote}[1]{``{#1}''}
\newcommand{\fct}[1]{{\texttt{#1()}\index{#1@\texttt{#1()}}}}
\newcommand{\class}[1]{\dquote{\texttt{#1}}}
\newcommand{\fixme}[1]{\emph{\marginpar{FIXME} (#1)}}

%% further commands
\renewcommand{\Prob}{\mathbb{P} }
\renewcommand{\E}{\mathbb{E}}
\newcommand{\V}{\mathbb{V}}
\newcommand{\Var}{\mathbb{V}}
\newcommand{\R}{\mathbb{R} }
\newcommand{\N}{\mathbb{N} }
\newcommand{\C}{\mathbb{C} }
\newcommand{\argmin}{\operatorname{argmin}\displaylimits}
\newcommand{\argmax}{\operatorname{argmax}\displaylimits}
\newcommand{\LS}{\mathcal{L}_n}
\newcommand{\TS}{\mathcal{T}_n}
\newcommand{\LSc}{\mathcal{L}_{\text{comb},n}}
\newcommand{\LSbc}{\mathcal{L}^*_{\text{comb},n}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\A}{\mathcal{A}}
\newcommand{\yn}{y_{\text{new}}}
\newcommand{\z}{\mathbf{z}}
\newcommand{\X}{\mathbf{X}}
\newcommand{\Y}{\mathbf{Y}}
\newcommand{\sX}{\mathcal{X}}
\newcommand{\sY}{\mathcal{Y}}
\newcommand{\T}{\mathbf{T}}
\newcommand{\x}{\mathbf{x}}
\renewcommand{\a}{\mathbf{a}}
\newcommand{\xn}{\mathbf{x}_{\text{new}}}
\newcommand{\y}{\mathbf{y}}
\newcommand{\w}{\mathbf{w}}
\newcommand{\ws}{\mathbf{w}_\cdot}
\renewcommand{\t}{\mathbf{t}}
\newcommand{\M}{\mathbf{M}}
\renewcommand{\vec}{\text{vec}}
\newcommand{\B}{\mathbf{B}}
\newcommand{\K}{\mathbf{K}}
\newcommand{\W}{\mathbf{W}}
\newcommand{\D}{\mathbf{D}}
\newcommand{\I}{\mathbf{I}}
\newcommand{\bS}{\mathbf{S}}
\newcommand{\cellx}{\pi_n[\x]}
\newcommand{\partn}{\pi_n(\mathcal{L}_n)}
\newcommand{\err}{\text{Err}}
\newcommand{\ea}{\widehat{\text{Err}}^{(a)}}
\newcommand{\ecv}{\widehat{\text{Err}}^{(cv1)}}
\newcommand{\ecvten}{\widehat{\text{Err}}^{(cv10)}}
\newcommand{\eone}{\widehat{\text{Err}}^{(1)}}
\newcommand{\eplus}{\widehat{\text{Err}}^{(.632+)}}
\newcommand{\eoob}{\widehat{\text{Err}}^{(oob)}}
\newcommand{\bft}{\mathbf{t}}

\hyphenation{Qua-dra-tic}

\title{Growing and Handling Trees with Constant Fits}
\Plaintitle{Growing and Handling Trees with Constant Fits}

\author{Torsten Hothorn\\Universit\"at Z\"urich
   \And Achim Zeileis\\Universit\"at Innsbruck}
\Plainauthor{Torsten Hothorn, Achim Zeileis}

\Abstract{
We describe how one can coerse objects representing trees to objects represented by 
\pkg{partykit} classes and how one can grow trees using the \pkg{partykit}.
}
\Keywords{recursive partitioning, regression trees, classification trees, decision trees}

\Address{
  Torsten Hothorn\\
  Institut f\"ur Sozial- und Pr\"aventivmedizin, Abteilung Biostatistik \\
  Universit\"at Z\"urich \\
  Hirschengraben 84\\
  CH-8001 Z\"urich, Switzerland \\
  E-mail: \email{Torsten.Hothorn@R-project.org}\\
  URL: \url{http://user.math.uzh.ch/hothorn/}\\

  Achim Zeileis\\
  Department of Statistics \\
  Universit\"at Innsbruck \\
  Universit\"atsstr.~15 \\
  6020 Innsbruck, Austria \\
  E-mail: \email{Achim.Zeileis@R-project.org}\\
  URL: \url{http://eeecon.uibk.ac.at/~zeileis/}
}


\begin{document}


\SweaveOpts{eps=FALSE, keep.source=TRUE, eval = TRUE}

<<setup, echo = FALSE, results = hide>>=
options(width = 70)
library("partykit")
set.seed(290875)
@

\section{Converting tree objects}

For the illustrations, we use the Titanic data set from package \pkg{datasets}, consisting of
four variables on each of the $2201$ Titanic passengers: gender (male, female), age (child, adult), 
class (1st, 2nd, 3rd, or crew), and first (male and adult vs.~ female or child)
set-up as follows:
<<Titanic>>=
data("Titanic", package = "datasets")
ttnc <- as.data.frame(Titanic)
ttnc <- ttnc[rep(1:nrow(ttnc), ttnc$Freq), 1:4]
names(ttnc)[2] <- "Gender"
ttnc <- transform(ttnc, First = factor(
    Gender == "Female" | Age == "Child",
    levels = c(FALSE, TRUE), labels = c("Male&Adult",
    "Female|Child")))
@
The response variable describes wheather or not the passenger survived the sinking of the ship.

We first use the \code{rpart} function from package \pkg{rpart}
\citep{rpart} to fit a classification tree to this data set:
<<rpart>>=
library("rpart")
(rp <- rpart(Survived ~ ., data = ttnc))
@
The \code{rp} object of class \Sexpr{class(rp)} can be coerced to an object of class \code{party}
by
<<rpart_party>>=
(party_rp <- as.party(rp))
@
and, instead of the print method for \code{rpart} objects, the print method
for \Sexpr{class(party_rp)} objects creates a textual display of the tree
structure.  The \code{plot} generic produces a graphical representation of
this tree, see Figure~\ref{party_plot}.

\begin{figure}
\begin{center}
<<rpart-plot, fig = TRUE, width = 10, height = 6>>=
plot(party_rp)
@
\caption{\code{rpart} tree of Titanic data plotted using \pkg{partykit}
         infrastructure. \label{party_plot}}
\end{center}
\end{figure}

By default, the \code{predict} method for \code{rpart} object computes conditional
class probabilities. The same numbers are returned by the \code{predict} method
for \Sexpr{class(party_rp)} objects with the \code{type = "prob"} argument:
<<rpart-pred>>=
all.equal(predict(rp), predict(party_rp, type = "prob"), 
          check.attributes = FALSE)
@

Some software packages can output a PMML description of a tree, we use the \pkg{pmml}
package to create a PMML file containing the \code{rpart} tree for the Titanic data
<<PMML-write>>=
library("pmml")
tfile <- tempfile()
write(toString(pmml(rp)), file = tfile)
@
\fixme{Does not work}
<<PMML-read>>=
try(party_pmml <- pmmlTreeModel(tfile))
#isTRUE(all.equal(party_rp, party_pmml))
#all.equal(predict(party_rp, newdata = Titanic, type = "prob"), 
#          predict(party_pmml, newdata = Titanic, type = "prob"),
#          check.attributes = FALSE)
@
\fixme{Does not work}
<<PMML-Audit>>=
if (!file.exists("AuditTree.xml"))
    download.file("http://www.dmg.org/pmml_examples/rattle_pmml_examples/AuditTree.xml",
                  destfile = "AuditTree.xml")
try(pmmlTreeModel("AuditTree.xml"))
@

\fixme{Seems to work}
<<PMML-Iris>>=
if (!file.exists("IrisTree.xml"))
    download.file("http://www.dmg.org/pmml_examples/rattle_pmml_examples/IrisTree.xml",
                  destfile = "IrisTree.xml")
pmmlTreeModel("IrisTree.xml")
@

The \pkg{RWeka} package \citep{RWeka} provides and interface to the
\proglang{WEKA} machine learning library and we can use the \code{J48} function to
fit a J4.8 tree to the Titanic data
<<J48>>=
library("RWeka")
(j48 <- J48(Survived ~ ., data = ttnc))
@
This object can be coerced to a \code{party} object using
<<J48_party>>=
(party_j48 <- as.party(j48))
@
and, again, the print method from the \pkg{partykit} package creates a textual display. Note
that, unlike the \code{rpart} trees, this tree included multiway splits. The \code{plot} method
draws this tree, see Figure~\ref{J48_plot}.

\begin{sidewaysfigure}
\begin{center}
<<J48-plot, fig = TRUE, width = 15, height = 9>>=
plot(party_j48)
@
\caption{\code{J48} tree of Titanic data plotted using \pkg{partykit}
         infrastructure. \label{J48_plot}}
\end{center}
\end{sidewaysfigure}

The conditional class probabilities computed by the \code{predict} methods implemented
in packages \pkg{RWeka} and \pkg{partykit} are equivalent:
<<J48-pred>>=
all.equal(predict(j48, type = "prob"), 
          predict(party_j48, type = "prob"), 
          check.attributes = FALSE)
@


\section{Growing a simple regression tree} 

Package \pkg{partykit} does not offer unified infrastructure for growing trees. However,
once you know how to estimate splits from data, it is fairly straightforward to
implement trees. Consider a very simple tree algorithm. We assume that both response
and features are numeric. We search for the binary best split by means of $t$-test 
$p$-values, i.e., we cycle through all variables and potential split points and assess
the quality of the split by comparing the distributions of the response in the so-defined
two groups. We select the feature/split point combination with lowest two-sided $p$-value,
however only if this result is significant at level $\alpha = 0.05$.

This strategy can be implemented based on the data (response and features) and 
some case weights as follows (\code{response} is just the name of the response
and \code{data} is a data frame with all variables):
<<mytree-1, echo = TRUE>>=
findsplit <- function(response, data, weights) {

  ### extract response values from data
  y <- data[[response]]

  logpmin <- 0
  xselect <- NULL

  ### cycle through all features
  for (i in which(names(data) != response)) {

    ### expand data
    x <- data[[i]]
    xt <- rep(x, weights)
    yt <- rep(y, weights)

    ### potential split points (not too many)
    qx <- unique(quantile(xt, 
        	 prob = seq(from = 0.1, to = 0.9, by = 0.05)))

    ### assess all potential splits by their t-test
    ### log-p-value
    logp <- sapply(qx, function(q) {
      tt <- t.test(yt[xt <= q], yt[xt > q])
      pt(-abs(tt$statistic), tt$parameter, log = TRUE) + log(2)
    })

    ### if the best split in variable i significant AND
    ### better than what we already had store this information
    if (min(logp) < logpmin & min(logp) < log(0.05)) {
      logpmin <- min(logp)
      xselect <- i
      splitpoint <- qx[which.min(logp)]
    }
  }

  ### no significant split found, give up
  if (is.null(xselect)) return(NULL)

  ### return split as partysplit object
  return(partysplit(
      varid = as.integer(xselect),	 ### which variable?
      breaks = as.numeric(splitpoint),   ### which split point?
      info = list(pvalue = exp(logpmin)  ### save p-value in addition
  )))
}
@

In order to actually grow a tree on data, 
we have to set-up the recursion for growing a recursive 
\class{partynode} structure:
<<mytree-2, echo = TRUE>>=
growtree <- function(id = 1L, response, data, weights) {

  ### for less than 30 obs. stop here
  if (sum(weights) < 30) return(partynode(id = id))

  ### find best split
  sp <- findsplit(response, data, weights)
  ### no split found, stop here
  if (is.null(sp)) return(partynode(id = id))

  ### actually split the data
  kidids <- kidids_split(sp, data = data)

  ### set-up all daugther nodes
  kids <- vector(mode = "list", length = max(kidids))
  for (kidid in 1:max(kidids)) {
  ### select obs for current node
  w <- weights
  w[kidids != kidid] <- 0
  ### get next node id
  if (kidid > 1) {
    myid <- max(nodeids(kids[[kidid - 1]]))
  } else {
    myid <- id
  }
  ### start recursion on this daugther node
  kids[[kidid]] <- growtree(id = as.integer(myid + 1), response, data, w)
  }

  ### return nodes
  return(partynode(id = as.integer(id), split = sp, kids = kids))
}
@

A very rough sketch of formula-based user-interface needs
to set-up the data and call \fct{growtree}:
<<mytree-3, echo = TRUE>>=
mytree <- function(formula, data, weights = NULL) {

  ### name of the response variable
  response <- all.vars(formula)[1]
  ### data without missing values, response comes last
  data <- data[complete.cases(data), c(all.vars(formula)[-1], response)]
  ### data is numeric
  stopifnot(all(sapply(data, is.numeric)))

  if (is.null(weights)) weights <- rep(1, nrow(data))
  ### weights are case weights, i.e., integers
  stopifnot(length(weights) == nrow(data) &
    max(abs(weights - floor(weights))) < .Machine$double.eps)

  ### grow tree
  nodes <- growtree(id = 1L, response, data, weights)

  ### compute terminal node number for each obs.
  fitted <- fitted_node(nodes, data = data)
  ### return rich object
  ret <- party(nodes, 
    data = data,
    fitted = data.frame(
      "(fitted)" = fitted,
      "(response)" = data[[response]],
      "(weights)" = weights,
      check.names = FALSE),
    terms = terms(formula))
  as.constparty(ret)
}
@

We now can fit this tree, for example to the airquality data; the
\fct{print} method provides us with a first overview on the 
resulting model
<<mytree-4, echo = TRUE>>=
aqt <- mytree(Ozone ~ Solar.R + Wind + Temp, data = airquality)
aqt
@

\begin{figure}[t!]
\centering
<<mytree-5, echo = TRUE, fig = TRUE, width = 10, height = 6>>=
plot(aqt)
@
\caption{Tree. \label{plottree}}
\end{figure}

\begin{figure}[t!]
\centering
<<mytree-5-ecdf, echo = TRUE, fig = TRUE, width = 10, height = 6>>=
plot(aqt, terminal_panel = node_ecdf)
@
\caption{Tree. \label{plottree_ecdf}}
\end{figure}



We depict the model graphically using \fct{plot} (see Figure~\ref{plottree})
and compute predictions using
<<mytree-6, echo = TRUE>>=
predict(aqt, newdata = airquality[1:10,])
@

An interesting feature is the ability to extract subsets of trees:
<<mytree-7, echo = TRUE>>=
aqt4 <- aqt[4]
aqt4
@
which again are objects inheriting from \class{party} and thus
can be plotted easily (see Figure~\ref{subtree}).

\begin{figure}[t!]
\centering
<<mytree-8, echo = TRUE, fig = TRUE, width = 10, height = 6>>=
plot(aqt4)
@
\caption{Subtree. \label{subtree}}
\end{figure}

We also might be interested in extracting the $p$-values in the
inner nodes in a nicely formatted way:
<<mytree-10, echo = TRUE>>=
fun <- function(x) format.pval(info_split(split_node(x))$pvalue,
  digits = 3, eps = 0.001)
nid <- nodeids(aqt)
iid <- nid[!(nid %in% nodeids(aqt, terminal = TRUE))]
unlist(nodeapply(aqt, ids = iid, FUN = fun))
@

\section{Predictions}

tbd

\begin{table}
\begin{center}
\begin{tabular}{l|lll}
               & \multicolumn{3}{l}{\code{predict(<party>, }} \\
Response class & \code{type = "node"} & \code{type = "response"} & \code{type = "prob"} \\ \hline
\code{factor}  & terminal node number & majority class & class probabilities \\
\code{numeric} & terminal node number & mean  & ECDF \\
\code{Surv} & terminal node number & median survival time  & Kaplan-Meier \\
\end{tabular}
\caption{Overview on type of predictions computed by the \code{predict}
         method for \code{constparty} objects. For multivariate responses,
         combinations thereof are returned.}
\end{center}
\end{table}
    


\end{document}
