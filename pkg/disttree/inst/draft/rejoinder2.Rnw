\documentclass[american,foldmarks=false,noconfig]{uibklttr}
\usepackage{amsmath,sfmath,hyperref,color,enumitem,soul}
    
\let\code=\texttt
\let\pkg=\emph
\let\proglang=\textsf
\newenvironment{review}{\fontshape{\itdefault}\fontseries{\bfdefault} \selectfont \smallskip}{\par}

\setkomavar{signature}{Lisa Schlosser}

\makeatletter
\@setplength{refvpos}{68mm}
\makeatother
\setlength{\textheight}{25cm}
\definecolor{quotecolor}{rgb}{0.4,0.4,0.5}

\definecolor{fixmecol}{rgb}{1,1,0.7}
\newcommand{\fixme}[1]{{\sethlcolor{fixmecol}\hl{\textit{FIXME: #1}}}}



\begin{document}
\SweaveOpts{concordance=TRUE}

\begin{letter}{
Nicoleta Serban\\
Area Editor\\
The Annals of Applied Statistics}


\setkomavar{subject}{Revision of AOAS1811-010}

\opening{Dear Professor Serban,}

please find attached the revised version of our manuscript 
``Distributional regression forests for probabilistic precipitation 
forecasting in complex terrain'' (AOAS1804-015).

Thank you very much for the positive and constructive feedback from you, 
the associate editor, and the two referees. We have incorporated all
the remaining comments and, in particular, added a new subsection
discussing more complex distributions with non-orthogonal parameters.
All changes are explained in more detail in the point-to-point reply
on the next pages. 

\closing{Best regards,
\vspace*{1cm}
}

%\vspace*{-2.8cm}
%\hspace*{-0.3cm} 
%\includegraphics[width = 0.23\textwidth]{signature-Schlosser}

\end{letter}

\newpage


\textbf{\LARGE Associate Editor}

\begin{review}
{\color{quotecolor} \textit{page 19, last paragraph:} 
To assess whether these differences in predictive performance 
are due to differences in the topography \ldots .}\\
It is not clear to me how conclusions 
about topography-related differences in predictive perfomance can be drawn from Fig. 8. 
The terrain seems to be rather complex everywhere in the study area. What is different 
in the south-eastern part of Tyrol? And why do these differences negatively affect 
the performance of distributional regression forests, the most flexible of all four 
methods compared here? Is it possible that the patterns in this figure are due to 
(spatially correlated) sampling variability, i.e. not statistically significant? 
\end{review}

East Tyrol differs from North Tyrol as it is located south of the main Alpine Ridge and thus
in a different climate zone. Consequently, both long-term climatological characteristics
and precipitation patterns in 2009--2012 differ. This is not visible from Figure~8 directly,
though, and hence we added a short explanation at the end of Section~3.4

Moreover, sampling variability clearly also plays a role as the differences from Figure~8
are somewhat evened out in the cross-validation, specifically for some of the East Tyrolian 
stations. This is shown in Supplement~B and was already discussed in the corresponding
paragraph in Section~4 (Axams vs.\ other meteorological stations). Additionally, we now
include some comments on this at the end of Section~3.4 where this was admittedly lacking
in the previous version of the manuscript.

% Thank you very much for your comment! One important fact that could be a reason for the
% different results is that East Tyrol does not lie in the same climate zone as the rest of Tyrol 
% indicating different meteorological characteristics. For example, a covariate
% might have a linear effect on the expected amount of rain in East Tyrol while it has a
% non-additive effect in Northern Tyrol. In this case, in East Tyrol an additive model such as 
% GAMLSS will capture this influence better than a tree model, particularly if this covariate
% is correctly specified in the model (which might be the case in the prespecified GAMLSS).
% Of course, this is just an assumption and there could be other reasons for the performance
% difference between the GAMLSS and the distributional forest models in East Tyrol. However, 
% looking at the results of the cross-validation in Supplement~B it can be observed that this 
% difference as seen in the single evaluation evens out for several stations in East Tyrol, 
% hence the specific choice of learning and validation period seems to have an impact as well.
% These two aspects are now also discussed more in detail in the main manuscript.


\newpage


\textbf{\LARGE Reviewer 1}

\bigskip

\textbf{General Comments:}

\begin{review}
The authors have well addressed the reviewers' comments. The two added supplementary 
materials give a more solid ground to the proposed post-processing method by showing 
it is robustness to some choice of forecast distribution and that the results presented 
in the main manuscript does not hold only for the specific station.
I recommend the paper to be accepted after the minor revisions proposed
hereafter have been addressed.
\end{review}

Thank you very much for the positive feedback and the helpful comments regarding the paper. 

\bigskip

\textbf{Specific comments:}

\textbf{Main Article:}

\begin{review}
1. {\color{quotecolor} \textit{page 14:} mtry, minsplit, minbucket, alpha.}\\
You have not yet given any detail about the statistical software you used. 
Please refer here to the ``computational~details'' section at the end of article. 
Also, please indicate to which function these parameters pertain to (ctree?).
\end{review}

We now point out that the arguments pertain to our function \code{distforest}
and include a forward reference to the ``computational details''.

You are also correct, though, that \code{ctree} takes these arguments. Internally,
\code{distforest}/\code{disttree} pass the arguments on to \code{cforest}/\code{ctree}.
This is now pointed out more clearly in the ``computational details''.


\begin{review}
2. {\color{quotecolor}\textit{page 15:} The figure shows that the model properly 
depicts the point masses at zero (i.e., the probability of a dry day) and the forecasted 
probability density function for the total amount of precipitation.}\\
It is not possible to assess a probabilistic forecast with only one example. 
Please erase or rephrase this sentence.
\end{review}

We have rephrased this sentence, emphasizing that the \emph{forecasted} distributions
are depicted and avoiding an assessment.


\begin{review}
3. {\color{quotecolor}\textit{page 25:} 
The smaller the $\boldsymbol{p}$-value corresponding to the standardized test statistic 
$\boldsymbol{c(t_l, \mu_l, \Sigma_l)}$}\\
Please specify the distribution of the test statistic under the null hypothesis.
\end{review}

Depending on whether a maximum or a quadratic form of the test statistic is considered,
the asymptotic conditional distribution is either normal ($c_{max}$) or $\chi^2$ ($c_{quad}$). 
We have added this information in Appendix~A.


\textbf{Supplement B:}

\begin{review}
4. {\color{quotecolor}\textit{page 1 (Abstract):} Moreover, further details including a 
crossvalidation analysis are preformed for only one station, Axams.}\\
Please change ``preformed'' into ``performed''.
\end{review}

This has been corrected in Supplement B.


\begin{review}
5. {\color{quotecolor}\textit{page 3:} The Resiudal QQ plots and the PIT histograms 
visualize the same values, however, on different scales.}\\
Please change into \textit{the Residual}
\end{review}

This has been corrected in Supplement B.





\newpage


\textbf{\LARGE Reviewer 2}

\textbf{Comments:}

\begin{review}
I think the authors tried to address my comments and invested considerable additional work 
on simulations and predictions on more stations. I appreciate this but am still no completely 
convinced that the models can provide benefits in distributional regression problems in 
particular when the distribution is more complex. The reason is that in all models considered, 
the distribution parameters are ``orthogonal'' in the sense that the mean and the variance 
parameter separate well.
\end{review}

Thank you for emphasizing this issue. We have now included some explicit pointers in Section~4
to the previous random forest literature where it is indeed shown that the advantages of score-based
split selection are particularly pronounced when the parameters are orthogonal. In contrast,
when parameters are closely correlated with the distribution mean then the advantages are
diminished and different random forest flavors typically perform similarly.

Our results confirm these findings in the context of parametric distributional modeling,
showing that results are quite robust to the distributional specification. Note also that
in our models mean and variance are typically quite closely correlated due to the substantial
censoring at zero (or truncation/zero-inflation in Supplement~A).

\begin{review}
This is not the case for many other distributions like the Dagum, Zero-inflated models, etc. 
I am wondering how well the distributional forest in these cases works with respect to the 
splits in the different distribution parameters. For instance, the expectation of the response 
for a Dagum distribution is a function of all distribution parameters and I have doubts that 
splitting the forests works without identification issues such that the forests may get very 
sensitive with respect to the test and training data.
\end{review}

We do not expect identification issues but agree that the advantages over a method like
Meinshausen's quantile regression forests will likely decrease or even disappear. However,
we do not speculate about these properties in the manuscript but do point out that this
deserves exploration in future research.

\begin{review}
In addition, overall I would say the method performs as well as the competitors but loses 
interpretation and for the prespecified GAMLSS also uncertainty estimates. With uncertainty 
I mean uncertainty of the estimates no the variance of the response.

Overall I found the paper interesting but not innovative and general enough to make a 
contribution qualified for AOAS but rather for instance JRSSC.
\end{review}

FIXME: Torsten, should we comment on this? In a predictive setup like the precipitation
forecasting the uncertainty of the estimates is not of so much concern. Also, the 
uncertainty due to variation in the response is typically much larger.

\end{document}
