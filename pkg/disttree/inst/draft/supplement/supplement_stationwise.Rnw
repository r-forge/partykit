\documentclass[nojss, shortnames]{jss}

\usepackage{graphicx, natbib}
\pagestyle{empty}
\usepackage{Sweave}
\usepackage{amstext,amsfonts,amsmath,bm,thumbpdf,lmodern,pdfpages,hyperref,bookmark}

\title{Supplement 2: Stationwise Evaluation}

\author{Lisa Schlosser\\Universit\"at Innsbruck
   \And Torsten Hothorn\\Universit\"at Z\"urich
   \And Reto Stauffer\\Universit\"at Innsbruck
   \And Achim Zeileis\\Universit\"at Innsbruck}
\Plainauthor{Lisa Schlosser, Torsten Hothorn, Reto Stauffer, Achim Zeileis}


\Abstract{
  In the case study presented in the main manuscript ``Distributional Regression
  Forests for Probabilistic Precipitation Forecasting in Complex Terrain''
  the novel distributional regression forests are evaluated and compared with
  other distributional regression approaches on 95 meteorological stations.
  Moreover, further details -- including a cross-validation analysis -- are
  preformed for only one station, Axams. To show that Axams is a fairly typical
  station and similar insights can be obtained for other stations as well,
  this supplements presents the same analysis as in Section~3.3 of the main
  manuscript for 14~further meteorological stations.
}

\Keywords{random forests, GAMLSS, evaluation, meteorological stations}



\Address{
  Lisa Schlosser, Reto Stauffer, Achim Zeileis \\
  Universit\"at Innsbruck \\
  Department of Statistics \\
  Faculty of Economics and Statistics \\
  Universit\"atsstr.~15 \\
  6020 Innsbruck, Austria \\
  E-mail: \email{Lisa.Schlosser@uibk.ac.at}, \email{Reto.Stauffer@uibk.ac.at},\\
  \email{Achim.Zeileis@R-project.org} \\
  URL: \url{https://www.uibk.ac.at/statistics/personal/schlosser-lisa/},\\
  \phantom{URL: }\url{https://retostauffer.org/},\\
  \phantom{URL: }\url{https://eeecon.uibk.ac.at/~zeileis/}\\
  
  Torsten Hothorn\\
  Universit\"at Z\"urich \\
  Institut f\"ur Epidemiologie, Biostatistik und Pr\"avention \\
  Hirschengraben 84\\
  CH-8001 Z\"urich, Switzerland \\
  E-mail: \email{Torsten.Hothorn@R-project.org}\\
  URL: \url{http://user.math.uzh.ch/hothorn/}\\
  
}


\begin{document}


\section{Setup}

\subsection{Models}

As introduced in Section~3.2 of the main manuscript, a distributional forest
based on a Gaussian distribution, left-censored at zero, is evaluated together
with three other zero-censored Gaussian models. Table~2 of the manuscript provides
an overview of all models considered and their specifications. As a reminder
the approaches are briefly summarized below.
%
\begin{itemize}

\item \emph{Distributional forest:} All predictor variables are
considered for learning a forest where subsampling is employed 
for each tree. Parameters are estimated by
adaptive local likelihood based on forest weights.

\item \emph{EMOS} \citep{Gneiting+Raftery+Westveld:2005}: 
Ensemble model output statistics uses the ensemble 
mean of total precipitation as regressor in the location submodel 
and the corresponding ensemble standard deviation in the scale submodel.
The parameters are estimated by maximum likelihood.

\item \emph{Prespecified GAMLSS:} Smooth additive splines are selected for
the most relevant predictors based on meteorological expert knowledge
following \cite{Stauffer+Umlauf+Messner:2017}. The model is estimated by maximum
penalized likelihood using a backfitting algorithm \citep{Stasinopoulos+Rigby:2007}.

\item \emph{Boosted GAMLSS:} Smooth additive splines are selected
automatically from all available variables, using non-cyclic boosting
for parameter estimation \citep{Hofner+Mayr+Schmid:2016, Messner+Mayr+Zeileis:2017}.
The optimal stopping point for the iterations is determined based on 
a (computationally intensive) out-of-bag bootstrap estimate of the log-likelihood.

\end{itemize}

\subsection{Learning and test samples}

The models are always learned on data from 24 years and tested on the 
remaining 4 years. Splitting the data into these two subsets is done
in two different ways leading to the two following evaluation settings.
%
\begin{itemize}

\item \emph{Single split}: The data is time-ordered. The learning data consists of the
first 24 years (1985--2008) and the testing data of the following 4 years
(2009--2012). 

\item \emph{Cross-validation}: In order to not just split the data at one splitpoint
the 28 years are randomly split into 7 blocks of 4 years which are not
necessarily successive. Each of the blocks is chosen once as testing data while
the remaining 6 blocks are the learning data. This procedure is repeated 10
times resulting in a 10 times 7-fold cross-validation framework.

\end{itemize}
%
The performances of the models are compared based on numerical and graphical evaluations.

\subsection{Numerical evaluation}

Several numerical summary statistics are computed in both
settings. For the single-split setting one value is calculated for each
observation in the test data and then their mean is reported. For the
cross-validation setting, the same is done for all 70~splits considered and
again their mean is reported. The following summary statistics are used.
%
\begin{itemize}

\item \emph{CRPS}: The continuous ranked probability score (CRPS) is calculated to
assess the predictive performance in terms of full probabilistic forecasts.

\item \emph{Computation time}: For all models fitting times and predictions times
are measured on the same 16-core Linux computer. In particular,
\textit{fit time} refers to the time needed to fit the model to the learning
data in a particular split. The \textit{predict time} refers to the time needed
to compute the out-of-sample prediction. In the single-split setting, the
predictions are computed observation by observation, i.e., emulating the
realistic setup where predictions are made once the new NWP model outputs become
available. In the cross-validation setting, the predictions for the full 4-year
out-of-sample period in one go. Although this is not realistic in this
particular application, it might be an interesting quantity for comparing the
competing regression approaches.

\end{itemize}
%
\textit{Note:} For a few splits in the cross-validation, the prespecified GAMLSS
(as computed by the \proglang{R} package \pkg{gamlss}) failed, leading to \code{NA}s
in the corresponding summary statistics. As mentioned by \cite{Hofner+Mayr+Schmid:2016}
such problems are not unusual because GAMLSS ``can be unstable, especially when it comes
to selecting possibly different sets of variables for multiple distribution parameters''.

\subsection{Graphical evaluation}

The following methods of visualization are applied to
provide further means of comparison of all models but also to investigate on the
distributional forest in particular.
%
\begin{itemize}

\item \emph{Boxplot of the CRPS skill score:} With EMOS as the reference model
the CRPS skill scores are calculated on each of the 70~splits considered in the
cross-validation setting and illustrated in a boxplot.

\item \emph{Barplot of variable importance:} For the distributional forest it is
investigated which variables have the strongest influence on the model and its
goodness of fit. For each variable this is measured based on mean decrease in
CRPS after permutation. The 10 variables showing the highest values in the
single-split setting are listed in a barplot.

\item \emph{Residual QQ plots:} For each of the models an out-of-sample residual
QQ plot for the single-split setting provides a graphical goodness-of-fit
assessment.

\item \emph{PIT histograms:} Similarly, the out-of-sample probability integral
transform (PIT) in the single-split setting is amployed as an alternative
goodness-of-fit visualization.

\end{itemize}


\section{Stations}

Out of the 95~observation stations 15 are considered for this 
supplemental study. They have been selected to cover a wide range regarding
geographical location, altitude, and which of the competing models performed
best in the single-split setting reported in Section~3.4 of the main manuscript.

Selected stations: \hyperlink{sumAxams.1}{Axams},
\hyperlink{sumLech.1}{Lech},
\hyperlink{sumZuers.1}{Zuers},
\hyperlink{sumSeeimPaznaun.1}{See im Paznaun},
\hyperlink{sumJungholz.1}{Jungholz},
\hyperlink{sumLadisNeuegg.1}{Ladis-Neuegg},
\hyperlink{sumOetz.1}{Oetz},
\hyperlink{sumOchsengartenObergut.1}{Ochsengarten-Obergut},
\hyperlink{sumGinzling.1}{Ginzling},
\hyperlink{sumRotholz.1}{Rotholz},
\hyperlink{sumWalchsee.1}{Walchsee},
\hyperlink{sumKoessen.1}{Koessen},
\hyperlink{sumInnervillgraten.1}{Innervillgraten},
\hyperlink{sumMatreiinOsttirol.1}{Matrei in Osttirol},
\hyperlink{sumStJohannimWalde.1}{St.~Johann im Walde}.



\begin{figure}[h]
\setkeys{Gin}{width=0.99\textwidth}
\vspace*{-3cm}
<<map_stationwise, fig=TRUE, echo=FALSE>>=
##  map
data("StationsTyrol", package = "RainTyrol")
data("MapTyrol", package = "RainTyrol")
library("sp")
sp <- SpatialPointsDataFrame(subset(StationsTyrol, select = c(lon, lat)),
                             data = subset(StationsTyrol, select = -c(lon, lat)),
                             proj4string = raster::crs(MapTyrol$RasterLayer))

plot(MapTyrol$SpatialPolygons)
points(sp, pch = 21, col = "darkgray", las = 1, cex = 0.6)
points(sp[c(5, 6, 20, 23, 25, 32, 33, 46, 47, 56, 57, 70, 79, 82, 83),], pch = 21, bg = hcl(325, 100, 70), cex = 1.5)
# stationname beneath
text(sp[c(25, 47, 57, 70),], 
     labels = StationsTyrol$name[c(25, 47, 57, 70)],
     pos=1, cex=0.75)
# stationname left
text(sp[c(20, 32, 46, 79, 83),], 
     labels = StationsTyrol$name[c(20, 32, 46, 79, 83)],
     pos=2, cex=0.75)
# stationname above
text(sp[c(6, 33, 82),], 
     labels = StationsTyrol$name[c(6, 33, 82)],
     pos=3, cex=0.75)
# stationname right
text(sp[c(5, 23, 56),], 
     labels = StationsTyrol$name[c(5, 23, 56)],
     pos=4, cex=0.75)
@
\vspace*{-3.5cm}
\caption{\label{fig:map}Map of Tyrol with all 95 observation stations and the 15 considered stations highlighted in pink.}
\end{figure}



\section{Results}

\subsection{Forecasting skill} 

Based on the out-of-sample CRPS results it can be concluded that the
distributional forest generally performs well on all stations and is typically
close to (e.g., \hyperlink{sumLech.1}{Lech}) or somewhat better than
the (next-)best method (e.g., \hyperlink{sumSeeimPaznaun.1}{See im Paznaun} and
\hyperlink{sumGinzling.1}{Ginzling}). Naturally, there is more variation
in the single-split results with another models performing better than the
distributional forest. However, in the cross-validation such differences
often even out, showing that distributional forests are on par. Examples for
this include \hyperlink{sumRotholz.1}{Rotholz},
\hyperlink{sumMatreiinOsttirol.1}{Matrei in Osttirol}, and 
\hyperlink{sumOchsengartenObergut.1}{Ochsengarten-Obergut}, where the 
best models in the single split are EMOS, prespecified GAMLSS and boosted
GAMLSS, respectively. The only station, where another model performs
clearly better than distributional forests in both settings, is
\hyperlink{sumSt.JohannimWalde.1}{St.~Johann im Walde}.

Overall, the results support the conclusion that distributional forests
perform well for this prediction task -- they are often on par and sometimes
even better than the other models considered. Moreover, it is shown that the
results for Axams are fairly typical and not particularly unusual compared
to the other stations considered.


\subsection{Computation time}

Distributional forests are comparable with respect to the computation times
to the other two flexible GAMLSS models. Only the basic EMOS model is clearly
the fastest. Moreover, unlike the other models, the boosted GAMLSS requires
a time-consuming cross-validation to determine the optimal stopping value
\code{mstop}. This is crucial for selecting the appropriate model complexity
and relevant covariates and hence cannot be neglected in the analysis.

The observation-wise prediction times in the single-split setting are in the same
order of magnitude for the three flexible distributional models. However, when
many predictions are computed simultaneously in the cross-validation setting,
then distributional forests are slower than the GAMLSS models. The reason for this
is that the GAMLSS can set up the model matrices once and then carry out a matrix
product while the distributional forest necessitates fitting a separate set of
parameters for each observation-specific weight vector.


\subsection{Variable importance}

Two NWP model outputs based on total precipitation (\code{tp\_max} and
\code{tp\_mean}) are clearly the most important predictors for precipitation
at all stations considered. The remaining variables typically follow with
some margin and vary slightly in their exact order. However, they typically
encompass some NWP model outputs for total precipitation, total column-integrated
condensate, and temperature differences.


\subsection{Calibration}

The PIT histograms and residual QQ plots show that overall all four models are
reasonably well-calibrated at the majority of stations while at some stations
they all fit better (e.g., at station \hyperlink{sumOetz.1}{Oetz}) or worse (e.g.,
at station \hyperlink{sumMatreiinOsttirol.1}{Matrei in Osttirol}) than on
average. For several stations, however, the boosted GAMLSS does not capture
the heavy upper tail as well as the other methods which is best seen in the
residual QQ plots but also the PIT histograms.


\includepdf[pages=-, link, linkname=sumAxams]{Axams.pdf}
\bookmark[dest=sumAxams.1]{Axams}
\includepdf[pages=-, link, linkname=sumLech]{Lech.pdf}
\bookmark[dest=sumLech.1]{Lech}
\includepdf[pages=-, link, linkname=sumZuers]{Zuers.pdf}
\bookmark[dest=sumZuers.1]{Zuers}
\includepdf[pages=-, link, linkname=sumSeeimPaznaun]{SeeimPaznaun.pdf}
\bookmark[dest=sumSeeimPaznaun.1]{See im Paznaun}
\includepdf[pages=-, link, linkname=sumJungholz]{Jungholz.pdf}
\bookmark[dest=sumJungholz.1]{Jungholz}
\includepdf[pages=-, link, linkname=sumLadisNeuegg]{LadisNeuegg.pdf}
\bookmark[dest=sumLadisNeuegg.1]{Ladis-Neuegg}
\includepdf[pages=-, link, linkname=sumOetz]{Oetz.pdf}
\bookmark[dest=sumOetz.1]{Oetz}
\includepdf[pages=-, link, linkname=sumOchsengartenObergut]{OchsengartenObergut.pdf}
\bookmark[dest=sumOchsengartenObergut.1]{Ochsengarten-Obergut}
\includepdf[pages=-, link, linkname=sumGinzling]{Ginzling.pdf}
\bookmark[dest=sumGinzling.1]{Ginzling}
\includepdf[pages=-, link, linkname=sumRotholz]{Rotholz.pdf}
\bookmark[dest=sumRotholz.1]{Rotholz}
\includepdf[pages=-, link, linkname=sumWalchsee]{Walchsee.pdf}
\bookmark[dest=sumWalchsee.1]{Walchsee}
\includepdf[pages=-, link, linkname=sumKoessen]{Koessen.pdf}
\bookmark[dest=sumKoessen.1]{Koessen}
\includepdf[pages=-, link, linkname=sumInnervillgraten]{Innervillgraten.pdf}
\bookmark[dest=sumInnervillgraten.1]{Innervillgraten}
\includepdf[pages=-, link, linkname=sumMatreiinOsttirol]{MatreiinOsttirol.pdf}
\bookmark[dest=sumMatreiinOsttirol.1]{Matrei in Osttirol}
\includepdf[pages=-, link, linkname=sumStJohannimWalde]{StJohannimWalde.pdf}
\bookmark[dest=sumStJohannimWalde.1]{St.~Johann im Walde}


%bibliographystyle{jss}
\bibliography{ref_supplement.bib}

\end{document}

%% https://cran.r-project.org/web/packages/gamboostLSS/vignettes/gamboostLSS_Tutorial.pdf
%% As a consequence, gamboostLSS is a convenient alternative to the AIC-based variable selection methods implemented in gamlss. The latter methods can be unstable, especially when it comes to selecting possibly different sets of variables for multiple distribution parameters.
