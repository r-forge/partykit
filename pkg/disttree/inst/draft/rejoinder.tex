\documentclass[american,foldmarks=false,noconfig]{uibklttr}
%\documentclass{article}
\usepackage{sfmath,hyperref,color,enumitem,soul}
%% additional style file to include bibliograph in class uibklttr
%\usepackage{letterbib}
%\usepackage{natbib,hyperref}
    
\let\code=\texttt
\let\pkg=\emph
\let\proglang=\textsf
\newenvironment{review}{\fontshape{\itdefault}\fontseries{\bfdefault} \selectfont \smallskip}{\par}

\setkomavar{signature}{Lisa Schlosser}

\makeatletter
\@setplength{refvpos}{75mm}
\makeatother
\setlength{\textheight}{25cm}
\definecolor{quotecolor}{rgb}{0.4,0.4,0.5}

\newenvironment{reto}{
    \begin{color}{uibkorange}
    \textbf{Reto:~}
        \itshape
}{
    \end{color}
}
\usepackage{amsmath}


\begin{document}
\begin{letter}{
Nicoleta Serban\\
Area Editor\\
The Annals of Applied Statistics}


\setkomavar{subject}{Revision of AOAS1804-015: Distributional 
regression forests for probabilistic precipitation forecasting 
in complex terrain}

\opening{Dear Professor Serban,}

please find attached the revised version of our manuscript 
``Distributional regression forests for probabilistic precipitation 
forecasting in complex terrain'' (AOAS1804-015).

Thank you very much for the constructive and helpful feedback from you, 
the associate editor and the two referees. The manuscript has been 
improved and additional results haven been obtained from further evaluations.

The most important changes are:
\begin{itemize}

\item The evaluations performed for all 95 observation stations 
in the main manuscript have been carried out under different 
distribution assumptions for 15 observation stations in order to 
test for robustness against distributional misspecifications. 
Results are provided in an online supplement 
(Supplement 1: Different Response Distributions) 
which comes with our revised manuscript.

\item The more extensive evaluations for station Axams have been 
carried out for 14 other observation stations. Results are 
provided in an online supplement 
(Supplement 2: Stationwise Evaluation)
which comes with our revised manuscript.

\item The mathematical notation in the Appendix is now more precise.

\item In the calculation of variable importance we have detected some inconsistencies.
Thus, we have revised the applied method to evaluate this measurement and recalculated
variable importance for the distributional forest.

\end{itemize}

All changes and additions are explained in much more detail in the
point-to-point reply on the next pages. 

\closing{Best regards,
\vspace*{1cm}
}

\vspace*{-2.8cm}
\hspace*{-0.3cm}signature %\includegraphics{zeileis-signature}

\end{letter}

\newpage


\textbf{\LARGE Associate Editor}

\begin{review}
This manuscript proposes a framework for distributional regression 
forests which combine the idea of random forests with distributional 
regression in order to obtain a flexible class of forecast models 
where the full forecast distribution depends on the predictors. 
This new approach is demonstrated in the context of probabilistic 
precipitation forecasting where it is used to construct full 
predictive distributions based on the output of an ensemble 
weather prediction model. The paper is very well written, the 
proposed methodology is useful, and the data example used to 
illustrate this method is practically relevant and discussed 
thoroughly.
\end{review}

Thank you very much for your advice and the positive feedback, 
it is highly appreciated!


\begin{review}
A typical limitation of very flexible modeling approaches like 
the one proposed here is that a sufficiently large sample is 
required to fit the model. Can the authors provide some 
guidelines as to how large the training sample needs to be for 
this method to be effective? Does the stopping criterion 
guarantee that the model is not overfitted? 
Is it obvious how to define the specific stopping criterion and 
if not, can general guidelines for doing so be provided?
\end{review}

The required size of the training data heavily depends on the complexity 
of the model, however, in different applications where we have tested the 
distributional forest it performed quite well with at least 50 observations. \\
Applying the Law of Large Numbers it can be shown that random forests do not overfit, 
not even for an increasing number of trees (Breiman 2001, Hastie et al. 2001, 
Biau et al. 2016). Therefore, it is recommended to build forests with a large number 
of trees as this generally yields more accurate predictions. 
However, ``[\dots] the computational cost for inducing a forest increases linearly 
with the number of trees, so a good choice results from a trade-off between 
computational complexity and accuracy'' (Biau et al. 2016, p.~205). Following this 
advice, we decided to build forests consisting of 100 trees.\\
Moreover, Hastie et al. (2001, p.~596) recommend to build trees of maximal depth:
``Our experience is that using full-grown trees seldom costs much, and 
results in one less tuning parameter.''
Thus, the stopping criteria \texttt{minbucket} and \texttt{minsplit} (both 
determining the minimal number of observations in a node) and \texttt{alpha} 
(the significance level for the statistical tests in the tree algorithm) should 
be kept rather low. However, in a distributional framework it also has to be 
considered that the minimal number of observations in a node needs to be high 
enough in order to allow for estimating the distribution parameters reasonably well.
In our application we have set \texttt{minsplit} to 50 and \texttt{minbucket} to 20.
These tuning parameters are now also listed in the main manuscript in Sections~3.2.
and discussed in Section~4.


\begin{review}
The equations are not numbered but the authors refer to equations 
by number (e.g. bottom of p7)
\end{review}

We apologize for the confusion the missing equation numbers 
might have caused. They are now added.

\begin{review}
In the last section where computational details are discussed, 
can you also provide some information on the computational cost? 
In a weather forecasting contest like the one discussed here, 
forecasts are often provided on a high-resolution grid, 
so it would be important to understand if the approach 
proposed here is computationally affordable. This is not clear 
to me because the nearest neighbor weights are specific 
to each new observation, so in a forecasting context these 
computations have to be done in realtime.
\end{review}

We have measured fitting time and prediction time for our 
application. For single predictions the distributional forest 
can keep up with the other models. However, as you already 
stated correctly, each prediction made by the forest is based 
on an observation-specific weight matrix and therefore has to 
be calculated separately. For that reason prediction time for a 
set of observations is clearly higher for the forest model than 
the GAMLSS models or the EMOS. The exact results and times can 
be found in Supplement 2 (Stationwise Evaluation).


\begin{review}
abstract: the acronym 'GAMLSS' should be spelled out the first 
time it is used
\end{review}

\begin{review}
p3: I'm not sure if people outside the weather forecasting 
community is familiar with the notion of an 'ensemble', so 
this should be explained briefly
\end{review}

\begin{reto}
Wo baut man das am besten ein?
\end{reto}


\begin{review}
p7: What is meant by 'domain knowledge'?
\end{review}

We have rephrased this as 'expert knowledge in the application domain'
in Section~2.2.


\begin{review}
p14: Was there any particular rationale for choosing Axams 
as the station to be studied in detail
\end{review}

Axams was chosen as the observation station being closest 
to Innsbruck, the capital of Tyrol and the work place of 
three of the authors, but not based on any other particular 
features. Furthermore, it has been checked whether it 
is an adequate representative of all stations regarding 
the results of our evaluations. This is now also 
confirmed by further analysis in Supplement 2 (Stationwise Evaluation) 
and discussed in Section~4.

\begin{review}
Fig. 4: Are these the plots for residuals of precipitation 
at the original or at the transformed scale?
\end{review}

The residual QQ plots (Dunn et al. 1996) illustrate the probability 
integral transform (PIT, Gneiting et al. 2007) values of the observations 
in the testing data and are therefore scale invariant. A more detailed 
explanation can be found in Supplement 2 (Stationwise Evaluation).

\begin{review}
p17: Is there any explanation why the prespecified GAMLSS 
method is the best-performing method in East Tyrol? Any 
explanation why the distributional regression forests 
performed less well than the simple EMOS method in this area?
\end{review}

This seems to result from the one specific training and validation period 
(training: 1985--2008, validation: 2009-2012).
The advantages of the GAMLSS model even out at most of the stations when looking 
on the results of a cross-validation. We have extended Section~4 to discuss this 
issue. The results of a the extended cross-validation for a set of $15$ stations 
can be found in Supplement 2 (Stationwise Evaluation).

\newpage


\textbf{\LARGE Reviewer 1}

\bigskip

\textbf{General comments:}

\begin{review}
The article presents a new parametric methodology, called 
distributional forests, to estimate the probability 
distribution of some random variables, based on information 
from covariates. The methodology is new in that it mixes the
automatic variable selection properties of random forests 
with a parametric assumption on the forecast distribution. 
This allows to keep the interpretability of parametric 
distributions with the flexibility of random forests in 
dealing with local fitting, non-linearity, interactions 
and variable selection.

This approach may be used in applied statistics, as 
illustrated with its application to forecasting daily 
precipitation amount in the mountainous region of Tyrol, 
Austria. The mountains make it very difficult for numerical 
weather prediction models to forecast local precipitation. 
Statistical post-processing of weather forecasts allows 
downscaling the prediction.

The paper is well written and is a pleasant reading. 
The methodology is introduced clearly and well grounded 
in statistical practices, but some points need to be 
made clearer (see later).

The article shows on the Tyrol rain forecasts that the 
proposed method performs better than three other methods, 
among which is the current state-of-the-art in statistical 
post-processing in meteorology (EMOS). Thus distributional
forests may be added to the several statistical post-processing 
techniques, as an efficient and easy-to-use parametric 
probabilistic forecast.

I recommend the paper to be published after the following 
minor revisions have been taken into account.
\end{review}

Thank you very much for the positive and constructive 
comments regarding the manuscript. These helped to 
substantially improve the manuscript.

\bigskip

\textbf{Specific comments:}

\begin{review}
1. {\color{quotecolor} page 2: exceedence}\\
This spelling is not wrong, but less common than ``exceedance''.
Please change into \textit{exceedance}
\end{review}

\begin{review}
2. {\color{quotecolor}\textit{page 2:} 10$\%$ to 90\% quantile}\\
Please change into \textit{10\% to 90\% quantiles}
\end{review}

\begin{review}
3. {\color{quotecolor}\textit{page 5:} Fig 3, caption: Observations 
are left-censored at 0}\\
Since observations are precipitation amount, they are truncated, not 
left-censored (which may let think that they could be negative). 
Please change into \textit{Observations are truncated at 0}
\end{review}

You are right, our explanation was incorrect, thank you for pointing
this out! We have now clarified that the model employs a censored
distribution but the observations are not censored, just non-negative
with a point mass at 0.


\begin{review}
4. {\color{quotecolor}\textit{page 5:} Fig 3, caption: censoring point}\\
Please change into \textit{truncation point}
\end{review}

We have rephrased this part of the caption to ``Observations are non-negative 
and modeled by a Gaussian distribution, left-censored at 0.
The observations are depicted by crosses and the predicted point mass
from the model by filled circles.'' to clearly distinguish between the model
and the observations.


\begin{review}
5. {\color{quotecolor}\textit{page 5:} Fig 3, legend: Point mass at 
censoring point}\\
Please change into \textit{Point mass at truncation point}
\end{review}

See point 4.

\begin{review}
6. {\color{quotecolor}\textit{page 5:} Fig 3, x label: $mm^{(1/1.6)}$/24\textit{h}}\\
This is not a very common unit, which make the figure not easily 
interpretable. Furthermore, since you have not yet said that 
observations have been power transformed, this may be surprising 
here at first reading. Please redraw this figure with 
observations in $mm$/24$h$.
\end{review}

Thank you for the advice, the figure is now redrawn on the scale $mm$/24$h$.


\begin{review}
7. {\color{quotecolor}\textit{page 7:} see Equation 2.1}\\
Your equations have no numbering. Please add one.
\end{review}

We apologize for the confusion the missing equation numbers 
might have caused. They are now added.

\begin{review}
8. {\color{quotecolor}\textit{page 8:} $\hat{\Theta}(z) = \cdots$}\\
This expression may lead to think that the parameter is estimated 
for each new prediction. If I am right, this is not the case, 
since the weights $w_i^{tree}$ are either $0$ or $1$. Thus the 
estimated parameter vector is the same as the one for the 
observations in the same segments as the new observation.
Please make this clear in the text.
\end{review}

For each new observation $z$ the corresponding 
parameter vector $\hat{\Theta}(z)$ can be calculated following 
the given formula. But you are right, one can also just evaluate 
the predicted terminal node for $z$ if the predicted parameter
vector for this node is already known as there is one unique 
parameter vector for all observations in the same terminal node.
This is now also explained at the end of Section~2.2..


\begin{review}
9. {\color{quotecolor}\textit{page 9:} Each of the distributional trees}\\
Please change into \textit{Each of the distributional tree}
\end{review}

We have rephrased the second paragraph of Section~2.3.

\begin{review}
10. {\color{quotecolor}\textit{page 9:} $w_i^{forest}$}\\
The normalization with $|B_b^t|$ makes the weight $w_i^{forest}$ 
take their value in $[0; 1]$. If I am not wrong, this means the 
parameter vector has to be estimated for each new prediction. 
How long does it take? For operational applications, the time 
to produce post-processed forecast may be a constraint. It may 
be interesting to compare the prediction time with distributional 
forest and with GAMLSS, since you claim in the abstract that
GAMLSS are computationally demanding. Please add some information
about the computation time to train your models and produce predictions.
\end{review}

Yes, in the forest model the parameter vector has to be estimated 
separately for each new prediction as it is based on an 
observation-specific weight matrix. For that reason, making 
predictions for a set of new observations is clearly more 
time consuming for the forest model than the GAMLSS models 
or the EMOS model. However, the time needed to make one single 
prediction is similar for all methods. The exact results 
concerning fitting and prediction times can now be found in
Supplement 2 (Stationwise Evaluation).


\begin{review}
11. {\color{quotecolor}\textit{page 10:} While this approach 
alone is already highly effective in the plains, it typically 
does not perform as well in complex terrain due to unresolved 
effects in the NWP system. For example, in the Tyrolean 
Alps -- considered in the following case study -- the NWP grid 
cells of $50 \times 50$ km$^2$ are too coarse to capture single 
mountains, narrow valleys, etc.}\\
Do you have references about this lack of performance of NWP 
in complex terrains? If so, please add them.
\end{review}

\textit{TO DO}

\begin{reto}
Es gibt da ein klassisches MOS-Paper in welchem Postprocessing
mit einem Globalmodell und einem Lokalmodell gemacht werden.
Das ist nicht die Referenz die der Reviewer will.
Das Problem ist, dass es explizit dazu nix gibt. Das ist einfach
jedem von uns klar. M\"uller zeigt aber in seinen Figures (f\"ur
Wind und Temperatur), dass ein Modell mit h\"oherer Aufl\"osung
einen geringeren Fehler aufweist und sagt folgendes:

``\textit{The largest differences are found in the raw
model forecast for stations in complex terrain. For wind
speed, the increase in resolution is more beneficial than
for temperature but is again negligible for MOS forecasts.
[\dots]
A higher resolution will
further reduce the model bias, especially in complex
terrain, but this can also be achieved with statistical
postprocessing if observations are available. Furthermore,
a postprocessed temperature forecast at 12-km
resolution outperforms a raw forecast at 3-km, regardless
of the complexity of the terrain}''.

\begin{verbatim}
@article{mueller2011,
    author = {M{\"u}ller, M. D.},
    title = {Effects of Model Resolution and Statistical Postprocessing on Shelter Temperature and Wind Forecasts},
    journal = {Journal of Applied Meteorology and Climatology},
    volume = {50},
    number = {8},
    pages = {1627--1636},
    year = {2011},
    doi = {10.1175/2011JAMC2615.1},
}
\end{verbatim}

Oder Meyers and Steenburgh (2013) der aufzeigt, dass auch der Mensch sich mit
der Wettervorhersage im Gebirge schwer tut bzw. dort die groessten Challenges
zu finden sind mit all den lokalen und kleinraeumigen Eigenschaften und Einfluessen.
Habe das Buch grad nicht rumliegen, ist wohl aber auch nicht zwingend notwendig.

\begin{verbatim}
@Inbook{meyers2013,
    author = {Meyers, Michael P. and Steenburgh, W. James},
    editor = {Chow, Fotini K. and De Wekker, Stephan F.J. and Snyder, Bradley J.},
    title = {Mountain Weather Prediction: Phenomenological Challenges and Forecast Methodology},
    bookTitle = {Mountain Weather Research and Forecasting: Recent Progress and Current Challenges},
    year = {2013},
    publisher = {Springer Netherlands},
    pages = {1--34},
    isbn = {978-94-007-4098-3},
    doi = {10.1007/978-94-007-4098-3_1},
}
\end{verbatim}
\end{reto}


\begin{review}
12. {\color{quotecolor}\textit{page 11:} Table 1, caption}\\
Please move the caption above the table.
\end{review}


\begin{review}
13. {\color{quotecolor}\textit{page 12:} Parameters are estimated 
by adaptive local likelihood based on the forest weights as 
described in Section 2.}\\
Please explain what is your stopping criterion.
\end{review}

As stopping criteria the minimal number of observations to perform 
a split (\texttt{minsplit}) is set to 50, the minimal number of 
observations in a terminal node (\texttt{minbucket}) is set to 20 
and the significance level for variable selection (\texttt{alpha}) 
is kept at the default value 1. We have added this information in 
the manuscript in Section~3.2., 'Distributional forest' and
also discussed the choice of these tuning parameter in Section~4. and
in the answer to the second point of the associate editor.


\begin{review}
14. {\color{quotecolor}\textit{page 13:} Table 2, caption}\\
Please move the caption above the table.
\end{review}


\begin{review}
15. {\color{quotecolor}\textit{page 17:} Thus, while the covariates 
themselves are not surprising, selecting a GAMLSS with a particular 
combination of all the transformations would be much more challenging.}\\
Did you compare the most important covariates in distributional forests
with the ones in preselected GAMLSS? If so, is there some insightful
information you could add?
\end{review}

Figure 6 shows the variable importance of the distributional forest
for one specific case (similar for other sites and cross-folds) 
using a CRPS based variable importance measure. The subset of 
most important covariates is similar to the set of covariates 
used for the prespecified GAMLSS but not equivalent.
The selection of different variations of the same covariate (cf., Table 2)
is not surprising as the covariates are often highly correlated.
Moreover, in the distributional forest for each node only a randomly
drawn subset of covariates is considered. Hence, if for example the most 
influential covariate is not included in this subset for a specific node 
a similar covariate is very likely to be selected instead.
Compared to the prespecified GAMLSS the forest seems to depict some
features via differences among the different variations of a specific
covariate (e.g., use \code{tp\_max}, \code{tp\_mean}, and \code{tp\_min}).
Unfortunately the analysis does not allow to get more insights
of (the importance of) interactions between different covariates.


\begin{review}
16. {\color{quotecolor}\textit{page 20:} If $Z_l$ is numeric 
then $v_l$ is simply the identity function $v_l(z_l^i) = z_l^i$. 
If $Z_l$ is a categorical variable with $H$ categories then 
$v_l(z_l^i) = e_H(z_l^i) = (I(z_j^i = 1), \dots , I(z_l^i = H))$ 
such that $v_l$ is a unit vector}\\
Based on this sentence, $v_l$ can be a vector or a scalar, 
which makes not very clear what $T_l$ is: is it a vector 
or a scalar? Please clarify.
\end{review}

Apologies for the unclear notation in Appendix A.
Depending on whether the split variable $Z_l$ is a numeric 
or a categorical variable, $t_l$ is either a
$k$~-~or~$k \cdot H$~-~dimensional vector.
We have revised the corresponding parts in the manuscript (also 
regarding your comments 17--20) and we hope that it now clarifies 
the content.


\begin{review}
17. {\color{quotecolor}\textit{page 20:} the observed 
multivariate linear statistic $t$}\\
What is $t$? Is it the vector with $m$ components $T_l$? 
Please clarify.
\end{review}

Here we are actually referring to the linear statistic $t_l$ (instead of $t$) 
which is the observed value of $T_l$, the test statistic for the $l$-th split 
variable $Z_l$. This has been adjusted in the Appendix of the manuscript.

\begin{review}
18. {\color{quotecolor}\textit{page 20:} $c_{quad}(t, \mu, \Sigma)$}\\
$\mu$ and $\Sigma$ have not been defined. What is their relationship 
with $\mu_l$ and $\Sigma_l$? Please clarify.
\end{review}

As in the foregoing point this was just a general notation, but 
actually the variables corresponding to the $l$-th split variable 
are considered, i.e. $t_l$, $\mu_l$ and $\sigma_l$. Thank you for
pointing this out, the missing indices have been added in the
Appendix of the manuscript.

\begin{review}
19. {\color{quotecolor}\textit{page 21:} it has to be assessed 
whether any of the resulting p-values is beneath the selected 
significance level. If so, the partitioning variable $Z_l$
with the lowest p-value is chosen as splitting variable.}\\
What if no p-value is beneath the selected significance level. 
Is it a stopping criterion? Please clarify.
\end{review}

Yes, one stopping criterion is that no p-value is beneath the 
selected significance level. Therefore, no further 
split is performed in the considered node in this case.

\begin{review}
20. {\color{quotecolor}\textit{page 21:} $B_{1r}$ is the first 
of the two new subgroups that are defined by splitting in split 
point $r$ of variable $Z_{l^{\ast}}$}\\
What do you mean by ``first of the two new subgroups''? Is it 
the subgroup with values $Z_{l^{\ast}} > r$? I don't see how 
such an ordering can be achieved if $Z_{l^{\ast}}$ is an 
unordered categorical variable. Please clarify how the two
subgroups are ordered.
\end{review}

The two subgroups are not ordered which is also not necessary as only 
the sum of scores over the two subgroups is considered for the linear 
statistic $T_{l^{\ast}}^{qr}$. We have adjusted the Appendix of
the manuscript to clarify this issue.

\newpage


\textbf{\LARGE Reviewer 2}

\begin{review}
The authors propose an extension of non-homogeneous Gaussian models 
for the use in weather forecasting based on parametric distributional 
models (GAMLSS). While the latter have proved to be applicable to a 
wide range of empirical questions, the authors focus on precipitation 
forecasts in the Alps. The approach combines a distributional model 
with a random forest, which they call distributional random forests, 
in order to include variable selection and interactions or 
non-linearities of predictors. I have a number of major concerns 
given in the following. My impression is that the method is rather
an extension of existing methodology on random forests to censored 
normal problems without important with a lack in discussing 
advantages and disadvantages of distributional regression models 
and only a rather minor improvement over certain competitors.
\end{review}

Thank you very much for your feedback and helpful suggestions. We hope 
the improvements we made on the paper can clear your doubts and concerns.

\bigskip

\textbf{Main comments:}

\begin{review}
1. It is obvious in distributional regression that not only the 
variables influence the predictive performance but rather that 
the exact distributional assumption has a big impact on both the 
fit and the prediction. The authors do not consider any other
than the censored normal distribution, which I found odd. 
In earlier references, they used the same distribution but I 
did not find any justification why not to use a truncated normal, 
a zero-adjusted model or a continuous part for $y > 0$ other
than the normal. In any distributional model, checking the 
assumption on the error density is a crucial step which in 
my opinion should not be ignored or assumed not to be a problem.
\end{review}

We have applied the left-censored at zero Gaussian distribution
as it has proven to be an adequate choice for this type of 
application in earlier publications.
Moreover, the residual QQ plots and PIT histograms illustrate
that the models are well calibrated employing this distribution.
But thank you very much for the advice to consider a hurdle model!
This is definitely a good idea and therefore we have carried out the
same evaluations as presented in the paper but employing a
Gaussian hurdle model. Additionally, a left-censored at zero logistic
distribution has been applied as well in the same setting in
order to account for heavier tails. The results of these evaluation
can be found in Supplement 1 (Different Response Distributions). 
Overall, the distributional forest is proven to be very robust against 
distributional misspecifications. Therefore, we decided to keep the 
distributional assumption considered in the main manuscript but we have 
also discussed the tested alternatives in Section~4.


\begin{review}
2. The response and some predictors are power transformations 
of originally measured variables like total precipitation as 
it is known that skewness is usually present. Why? As far as I 
understand, one major advantage of distributional models is
that the response does not have to be normal but to model scale, 
skewness and the shape in general as a function of the covariates. 
By applying the transformation in advance and hence marginally, 
the dependence of covariates on further moments of the response 
is assumed to be not existing and simply ignored.
\end{review}

The skewness results from the characteristics of precipitation sums. 
Most of the time no or only moderate precipitation amounts are forecasted 
and observed. In some situations (e.g., days with thunderstorms, cold and 
warm fronts, \dots) large amounts of precipitation can be observed at 
specific sites. This is often also depict by the ensemble prediction 
system where a subset of all members predicts rather large amounts 
(compared to the overall ensemble mean or median). This yields strongly 
skewed ensemble forecasts which has to be addressed in some sort.\\
As you mention one way would be to directly apply a
distributional family with an additional parameter to capture
skewness. Another frequently used approach is to transform the 
data to remove large parts of the skewness. The latter has the 
advantage that the model assumptions get simpler as no estimate 
for the skewness parameter is required. 
Moreover, applying a transformation together with a censored 
at zero Gaussian distribution allows for a better comparison 
to the other models as they can all be built under the same 
settings.
In this study we are thus following Stauffer et al. (2017) 
using the power transformation which turned out to be optimal 
for a similar application for the very same study area.


\begin{review}
3. Is a random forest really the right thing to do? In the 
end, the analyst or meteorologist does not obtain an 
interpretable model and no explanation which variable 
affects the distribution in which direction is possible. 
I think, the reason that focusing on predictions should 
be made clearer and well justified.
\end{review}

This is the trade-off between interpretability and predictive 
skill. Regression-type models might be easier to interpret, 
however, if one is mainly interested in predictive skill and
a good performing fully automated weather forecasting tool the 
interpretability is not implicitly needed in some cases 
(machine learning performance vs. interpretability).
We adapted our manuscript as we definitely want to emphasize that 
in our application the focus is mainly on prediction but not on 
interpretation. We hope we could point this out clearly.

\begin{review}
4. The method itself is hard to follow in particular since 
authors reference to equations without using equation numbers. 
The part on random forests for instance is quite a black box 
without looking into a number of earlier works of some of 
the authors. From an applied perspective, there should be a 
better motivation and connection of the methodology and the 
data application.
\end{review}

We apologize for the confusion the missing equation numbers 
might have caused. They are now added.
We have also rephrased Section~2.3. which now first introduces random 
forests and then distributional forests as an extension of classical 
random forests.


\begin{review}
5. In the introduction it is said that ``while requiring no 
expert knowledge for the model specification''. I do not think 
it is true given that the authors do not consider a possible 
distributional misspecification at all. In addition, If I am 
not wrong, the functional forms in the distributional 
regression models do not have to be prespecified. Applying a 
mixed model type representation it should be possible to
have for instance interaction surfaces separated into the pure 
interaction effects and the main effects. For instance, 
Wood et al. (2013) discuss a generic approach for defining 
well-identified and interpretable effect decompositions in 
tensor product interactions again based on the mixed model 
representation of penalised model components, while Goicoa 
et al. (2017); Ugarte et al. (2017) determine the identifiability
constraints from the null space of the penalties associated 
with the spatio-temporal interaction effect.
\end{review}

Thank you for your suggestions and the references. These are all
good ideas, however, in our application the number of covariates
is too large in order to keep a model with all interactions manageable.
We have also discussed this in Section~4 of the main manuscript and
rephrased the corresponding sentence in the introduction to ``while 
requiring no meteorological knowledge about the atmospheric processes 
which drive formation of precipitation for the model specification.'' 
in order to clarify that this refers only to the variable prespecification 
in this application.


\begin{review}
6. A simulation study designed according to the data set should 
be used in order to give an empirical evidence that the random 
forests are generally better able to perform predictions compared 
to the competing methods. The figures indicate that advantages 
for the chosen station are rather minor and one should keep in 
mind that GAMLSS and boosting yield interpretable results which 
the random forests do not do. also, what happens when choosing 
another station than Axams? The figure 8 indicates that the 
distributional forest does not perform better in all stations 
and I am wondering whether a meteorologist would really do a 
better job on a relative scale of precipitation.
\end{review}

In order to investigate on these questions we have carried out the full
analysis as presented for station Axams in the main manuscript for 14
further observation stations. It shows that the distributional
forest is very robust against distributional misspecifications
and almost always competitive with the best among the other methods 
or even better. The exact results are provided in 
Supplement 2 (Stationwise Evaluation) and discussed in Section~4. 
Especially for meteorologists intending to apply model output 
statistics (MOS) for several hundreds of observation stations 
(e.g., Wahl 2014, Rasp and Lerch 2018)
the distributional forest provides a good and robust alternative. 
Even though computational costs are higher than for an EMOS model, 
they are similar as for a prespecified model and lower than for 
a model applying variable selection based on cross-validation.
Execution times have been measured and can be found
in Supplement~2 (Stationwise Evaluation).



\begin{review}
7. How are the folds chosen for performing the predictions? 
is it 4 subsequent years or randomly chosen 4 years out of 
the 28? I expect this to have a strong impact on the predictions 
and sensitivity with respect to this needs to be considered both 
in simulations and the real study.
\end{review}

The folds of the cross-validation are chosen randomly. The data 
set of 28 years is split randomly into 7 blocks of 4 years which 
are not necessarily successive. This is now also explained in the 
description of the cross-validation setup third paragraph of 
Section~3.3.

We have chosen two different setups: First we learned the model
on the first 24 years and evaluated on the following 4 years
in order to provide a classic time ordered setup. 
However, no influence of time is to be expected which is also supported by 
an autocorrelation coefficient of -0.007 of the out-of-bag quantile 
residuals of the distributional forest model for station Axams for
a time lag of 1 day.
% ## calculation of autocorrelation:
% load("Axams_24to4.rda") 
% set.seed(4)
% pdf <- predict(Axams_24to4$df, newdata = Axams_24to4$testdata, type = "parameter")
% pit_df <- cbind(0, pnorm(Axams_24to4$testdata[,"robs"], mean = pdf$mu, sd = pdf$sigma))
% pit_df[Axams_24to4$testdata[,"robs"]>0, 1] <- pit_df[Axams_24to4$testdata[,"robs"]>0, 2]
% ac <- acf(qqrplot(pit_df)$residuals)
To evaluate the models in a broader framework a cross-validation 
with the above described choice of folds was applied. The results
for station Axams are included in the main manuscript, results
for 14 additional stations can be found in
Supplement~2 (Stationwise Evaluation).


\begin{review}
8. I found the competing models to be chosen pretty unfair. 
First, for the prespecified GAMLSS, the authors use 
”relevant effects based on expert knowledge”. Why not all? 
Why not making a decision on some information criteria such as AIC/BIC? 
The latter would be done if the analyst decided to use a prespecified 
GAMLSS. I guess, the GAMLSS could improve a lot by this . 
\end{review}

As mentioned in our response to your comment 5, and also discussed in Section~4, 
the high number of covariates (80) restricts the possibilities of variable 
selection and model specification. For an AIC or BIC based selection an 
evaluation of 80 main effects for two parameters would make this a very complex
procedure. Moreover, Hofner et al. (2016, p.~3) stated that the 
AIC-based variable selection methods implemented in the \textsf{R} 
package \textbf{gamlss} ``[...] can be unstable, especially when it comes 
to selecting possibly different sets of variables for 
multiple distribution parameters.'' For that reason we decided
not to apply such a selection method.

\begin{review}
Second, what does a basic EMOS exactly mean? 
\end{review}

By a `basic EMOS' we are referring to the linear distributional 
regression model based on the idea presented by Gneiting et al. (2005) 
applying a left-censored at zero Gaussian distribution where only the 
ensemble mean is included for the location parameter and the ensemble 
standard deviation for the scale parameter.
We now introduce the model which we are referring to as a `basic EMOS'
in detail in the main manuscript in the first paragraph of Section~3. 



\begin{review}
Third, why not to include interactions in the boosting algorithm 
as well? this should be conceptually straight forward? 
\end{review}

Including only pairwise interactions
of the 80 available variables would already lead to 3160 additional
covariates which would make the model too complex and hardly manageable
regarding computational costs. Therefore, we decided not to include
any interactions in the boosting algorithm.
This issue is now addressed and discussed in Section~4.
% factorial(80)/factorial(80-2)/factorial(2)

\begin{review}
Fourth, why are 100 trees chosen in the forest? Is this a a default 
value? May this number not also be dependent on the complexity of 
the model? Why not to choose the number of trees similar to what is 
done in boosting? this would also increase the computation time of 
the forest a lot.
\end{review}


Following Breiman (2001) random forests are very robust and do not overfit, 
not even for a high number of trees. However, computational costs increase 
linearly with the number of trees (Biau et al. 2016).
Therefore, we followed these recommendations of choosing a high number of
trees, but still small enough to keep the computation time at
a reasonable level. Moreover, 100 is a commonly used number of trees that
seems to work very well. A larger number of trees could be used but 
the performance is usually not significantly better compared to a forest with 
100 trees. Tuning parameters of forest models, including the number of 
trees (\texttt{ntree}), are now discussed in Section~4 
of the main manuscript.





\bigskip

\textbf{Minor comments:}


\begin{review}
1. Given the length of the paper, I suggest to move the 
appendix to an online supplement.
\end{review}

Thank you for your advice. We have kept only the details regarding
the presented methodology in the appendix of the main manuscript
(Appendix A) and extended Appendix B to an online supplement
(Supplement 2: Stationwise Evaluation).

\begin{review}
2. Does the EMOS method employ ensemble post-processing 
techniques? There are recent references using this in weather 
forecasting (Chen et al.; 2014)?
\end{review}

The EMOS as originally suggested by Gneiting et al. (2005) can be seen
as one of the standard ensemble model output statistics (or post-processing)
approaches. This concept is well known within the post-processing community.
We have revised the introduction of our manuscript and introduce the `basic EMOS'
in more explicitly and in more detail (cf., Section~3).


\begin{review}
3. Looking at the PIT in the appendix, they seem to provide a 
worse fit as compared to the quantile residuals. Also, both 
just give a graphical device. If the focus is on prediction 
then my impression is that one should rather plot PIT and 
residuals for the predictions.
\end{review}

The PIT histograms and the residual QQ plots visualize the same
results on different scales. The out-of-sample PIT values are 
either plotted in a histogram or plotted against the corresponding
quantiles of the standard normal distribution. A more detailed 
explanation can be found in Supplement 2 (Stationwise Evaluation) 
which contains both, PIT histograms and residual QQ plots, 
for 15 stations. In the manuscript we decided to only show the 
residual QQ plot as it allows for a better analysis of the tail 
behavior than the PIT histogram.


\begin{review}
4. Figure 5: Which most important variables are included in the 
boosting algorithm? Why are the 10 most important covariates chosen?
\end{review}

Figure 6 is only a visualization of the 10 most important covariates 
of the forest model in one particular setting (station Axams, learned 
on 1985--2008). However, this top 10 list is not considered for any specification 
of the boosted GAMLSS for which all available covariates are included. As 
for the distributional forest, we have also calculated variable importance 
based on mean increase of out-of-bag CRPS for the gamboostLSS model for 
the exact same setting (station Axams, learned on 1985--2008). The resulting 
top 10 variables are listed in the following barplot.

\begin{center}
\includegraphics[width = 0.7\textwidth]{varimp_gb.jpeg}
\end{center}

Overall it can be stated that the most important covariates of the boosted 
GAMLSS are similar to the ones of the distributional forest even though they
are not exactly the same ones and the influence of \texttt{tp\_max} is clearly
stronger in the boosted GAMLSS. This can be explained by the random selection
of possible split variables in each node of the distributional forest. Thus,
if \texttt{tp\_max} is not available, a similar covariate such as \texttt{tp\_min}
or \texttt{tp\_mean} are very likely to be selected instead while in the boosting
algorithm \texttt{tp\_max} is always a possible choice.


% Out of them, in the exact same setting (Axams, 1985--2008), 
% the boosting algorithm selects 28 covariates 
% for the location parameter, mainly related to precipitation (7) 
% and temperature (11), and 46 covariates for the scale parameter, 
% mainly related to precipitation (10), convective available potential 
% energy (8) and temperature (15).
% mu: 7 tppow, 1 cape, 2 dswrf, 2 msl, 2 pwat, 3 tcolc, 11 temperature
% sigma: 10 tppow, 8 cape, 1 dswrf, 5 msl, 5 pwat, 2 tcolc, 15 temperature

% R> names(coef(gb, parameter = "mu"))
% [1] "bbs(tppow_min)"        "bbs(tppow_max)"        "bbs(tppow_mean1218)"  
% [4] "bbs(tppow_mean1824)"   "bbs(tppow_mean2430)"   "bbs(tppow_sprd0612)"  
% [7] "bbs(tppow_sprd2430)"   "bbs(capepow_sprd0612)" "bbs(dswrf_mean_mean)" 
%[10] "bbs(dswrf_sprd_mean)"  "bbs(msl_sprd_min)"     "bbs(msl_sprd_max)"    
%[13] "bbs(pwat_sprd_min)"    "bbs(pwat_sprd_max)"    "bbs(tcolc_mean_mean)" 
%[16] "bbs(tcolc_mean_max)"   "bbs(tcolc_sprd_mean)"  "bbs(t500_mean_min)"   
%[19] "bbs(t850_mean_min)"    "bbs(t500_sprd_mean)"   "bbs(t500_sprd_max)"   
%[22] "bbs(t700_sprd_mean)"   "bbs(t700_sprd_min)"    "bbs(t700_sprd_max)"   
%[25] "bbs(t850_sprd_min)"    "bbs(t850_sprd_max)"    "bbs(tdiff700850_min)" 
%[28] "bbs(tdiff500700_max)"

% R> names(coef(gb, parameter = "sigma"))
% [1] "bbs(tppow_mean)"       "bbs(tppow_sprd)"       "bbs(tppow_min)"       
% [4] "bbs(tppow_max)"        "bbs(tppow_mean1824)"   "bbs(tppow_mean2430)"  
% [7] "bbs(tppow_sprd0612)"   "bbs(tppow_sprd1218)"   "bbs(tppow_sprd1824)"  
%[10] "bbs(tppow_sprd2430)"   "bbs(capepow_sprd)"     "bbs(capepow_min)"     
%[13] "bbs(capepow_max)"      "bbs(capepow_mean1218)" "bbs(capepow_mean1224)"
%[16] "bbs(capepow_mean1230)" "bbs(capepow_sprd0612)" "bbs(capepow_sprd1218)"
%[19] "bbs(dswrf_sprd_mean)"  "bbs(msl_mean_mean)"    "bbs(msl_mean_max)"    
%[22] "bbs(msl_sprd_mean)"    "bbs(msl_sprd_min)"     "bbs(pwat_mean_mean)"  
%[25] "bbs(pwat_mean_min)"    "bbs(pwat_mean_max)"    "bbs(pwat_sprd_min)"   
%[28] "bbs(pwat_sprd_max)"    "bbs(tmax_mean_mean)"   "bbs(tmax_mean_min)"   
%[31] "bbs(tcolc_mean_min)"   "bbs(tcolc_sprd_max)"   "bbs(t500_mean_mean)"  
%[34] "bbs(t700_mean_mean)"   "bbs(t700_mean_max)"    "bbs(t850_mean_min)"   
%[37] "bbs(t850_mean_max)"    "bbs(t500_sprd_max)"    "bbs(t850_sprd_min)"   
%[40] "bbs(t850_sprd_max)"    "bbs(tdiff700850_min)"  "bbs(tdiff700850_max)" 
%[43] "bbs(tdiff500700_mean)" "bbs(tdiff500700_min)"  "bbs(tdiff500700_max)" 
%[46] "bbs(msl_diff)" 

\bigskip

%\bibliographystyle{jss}
%\bibliography{ref.bib}


\noindent{\large\textbf{References}}

\begin{itemize}[leftmargin=*]

\item[] Chen, J., Brissette, F. P. and Lhi, Z. (2014). Postprocessing 
of Ensemble Weather Forecasts Using a Stochastic Weather Generator, 
\textit{Monthly Weather Review}.

%\item[] Goicoa, T., Adin, A., Ugarte, M. D. and Hodges, J. S. (2017). 
%In Spatio-Temporal Disease Mapping Models, Identifiability Constraints 
%Affet PQL and INLA Results, \textit{Stochastic Environmental Research 
%and Risk Assessment} p. to appear.

%\item[] Ugarte, M. D., Adin, A. and Goicoa, T. (2017). One-Dimensional, 
%Two-Dimensional, and Three-Dimensional B-Splines to Specify Space-Time 
%Interactions in Bayesian Disease Mapping: Model Fitting and Model 
%Identifiability, \textit{Spatial Statistics} p. to appear.

\item[] Goicoa, T., Adin, A., Ugarte, M. D. and Hodges, J. S. (2018). 
In Spatio-Temporal Disease Mapping Models, Identifiability Constraints 
Affet PQL and INLA Results, \textit{Stochastic Environmental Research 
and Risk Assessment} \textbf{32, 3}: 749--770.

\item[] Ugarte, M. D., Adin, A. and Goicoa, T. (2017). One-Dimensional, 
Two-Dimensional, and Three-Dimensional B-Splines to Specify Space-Time 
Interactions in Bayesian Disease Mapping: Model Fitting and Model 
Identifiability, \textit{Spatial Statistics} \textbf{22}: 451--468.

\item[] Wood, S. N., Scheipl, F. and Faraway, J. J. (2013). 
Straightforward Intermediate Rank Tensor Product Smoothing in Mixed Models, 
\textit{Statistics and Computing} \textbf{23}: 341--360.

%%%%%%%%%
% references used in answers
\item[] Gneiting, T., Raftery, A. E., Westveld III, A. H. and Goldman, T. (2005). 
Calibrated Probabilistic Forecasting Using Ensemble Model Output Statistics and 
Minimum CRPS Estimation,
\textit{Monthly Weather Review} \textbf{133, 5}: 1098--1118.

\item[] Stauffer, R., Mayr, G. J., Messner, J. W., Umlauf, N. and Zeileis, A. (2017). 
Spatio-Temporal Precipitation Climatology over Complex Terrain Using a Censored Additive Regression Model,
\textit{International Journal of Climatology} \textbf{37, 7}: 3264--3275.

\item[] Hofner, B., Mayr, A. and Schmid, M. (2016). 
\textbf{gamboostLSS}: An \textsf{R} Package for Model Building and 
Variable Selection in the {GAMLSS} Framework,
\textit{Journal of Statistical Software} \textbf{74, 1}: 1--31.

%\item[] Hofner, B., Boccuto, L. and Goeker, M. (2015). 
%Controlling false discoveries in high-dimensional situations: Boosting 
%with stability selection,
%\textit{BMC Bioinformatics} \textbf{16:144}.

\item[] Meinshausen, N. and Buehlmann, P. (2010). 
Stability selection,
\textit{Journal of the Royal Statistical Society, Series B} 
\textbf{72}: 417--473.

\item[] Dunn, P. K. and Smyth, G. K. (1996).
Randomized Quantile Residuals,
\textit{Journal of Computational and Graphical Statistics}
\textbf{5, 3}: 236--244.

\item[] Gneiting, T., Balabdaoui, F. and Raftery, A. E. (2007).
Probabilistic Forecasts, Calibration and Sharpness,
\textit{Journal of the Royal Statistical Society B}
\textbf{69, 2}: 243--268.

\item[] Biau, G. and Scornet, E. (2016).
A Random Forest Guided Tour,
\textit{TEST}
\textbf{25}: 197--227.

\item[] Hastie, T., Tibshirani, R. and Friedman, J. (2001).
The Elements of Statistical Learning, Second Edition,
\textit{Springer New York Inc.}.

\item[] Breiman, L. (2001).
Random Forests,
\textit{Machine Learning}
\textbf{45, 1}: 5--32.

\item[] Wahl, S. (2015). Uncertainty in Mesoscale Numerical Weather Prediction:
Probabilistic Forecasting of Precipitation, PhD thesis, 
\textit{University of Bonn}, p. 1--120.% \url{http://hss.ulb.uni-bonn.de/2015/4190/4190.pdf}.

\item[] Rasp, S., Lerch, S. (2018). Neural Networks for Post-Processing Ensemble
Weather Forecasts, \textit{Montly Weather Review}, NA.
%doi:\href{https://doi.org/10.1175/MWR-D-18-0187.1}{10.1175/MWR-D-18-0187.1}.

\end{itemize}


\end{document}
