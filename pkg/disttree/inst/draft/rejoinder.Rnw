\documentclass[american,foldmarks=false,noconfig]{uibklttr}
\usepackage{amsmath,sfmath,hyperref,color,enumitem,soul}
    
\let\code=\texttt
\let\pkg=\emph
\let\proglang=\textsf
\newenvironment{review}{\fontshape{\itdefault}\fontseries{\bfdefault} \selectfont \smallskip}{\par}

\setkomavar{signature}{Lisa Schlosser}

\makeatletter
\@setplength{refvpos}{68mm}
\makeatother
\setlength{\textheight}{25cm}
\definecolor{quotecolor}{rgb}{0.4,0.4,0.5}

\definecolor{fixmecol}{rgb}{1,1,0.7}
\newcommand{\fixme}[1]{{\sethlcolor{fixmecol}\hl{\textit{FIXME: #1}}}}



\begin{document}
\SweaveOpts{concordance=TRUE}

\begin{letter}{
Nicoleta Serban\\
Area Editor\\
The Annals of Applied Statistics}


\setkomavar{subject}{Revision of AOAS1804-015}

\opening{Dear Professor Serban,}

please find attached the revised version of our manuscript 
``Distributional regression forests for probabilistic precipitation 
forecasting in complex terrain'' (AOAS1804-015).

Thank you very much for the constructive and helpful feedback from you, 
the associate editor, and the two referees. Based on this feedback, the
manuscript has been revised and embellished with additional results
from further evaluations. We feel that this substantially improved our
contribution.
%
The most important changes are:
\begin{itemize}

\item \emph{Supplement A: Different response distributions.}\\
To assess the appropriateness and robustness of the distributional
assumption (censored Gaussian) made in the main manuscript, further
response distributions (two-part Gaussian hurdle; censored
logistic) are evaluated to potentially better capture lower
and upper tails, respectively. The supplement follows the
evaluations performed for all 95 observation stations 
in the main manuscript using all three response distributions
for a subset of 15 stations.

\item \emph{Supplement B: Stationwise evaluation.}\\
To show that the more extensive cross-validation results -- obtained only
for one station (Axams) in the main manuscript -- are fairly typical,
they are extended to 14 other observation stations. This also incorporates
results that were previously presented in Appendix B which has consequently
been omitted from the main manuscript.

\item \emph{Section~4: Discussion.}\\
The concluding section of the main manuscript has been rewritten and
extended regarding discussion of: variable selection, tuning parameters,
distributional specifications (referring to Supplement~A), and regional
differences (referring to Supplement~B).

\item \emph{Appendix~A: Tree algorithm.}\\
The exposition has been extended and embellished, in particular regarding
mathematical notation.

% \item In the calculation of variable importance we have detected some inconsistencies.
% Thus, we have revised the applied method to evaluate this measurement and recalculated
% variable importance for the distributional forest.

\end{itemize}

All changes and additions are explained in much more detail in the
point-to-point reply on the next pages. 

\closing{Best regards,
\vspace*{1cm}
}

\vspace*{-2.8cm}
\hspace*{-0.3cm} 
\includegraphics[width = 0.23\textwidth]{signature-Schlosser}

\end{letter}

\newpage


\textbf{\LARGE Associate Editor}

\begin{review}
This manuscript proposes a framework for distributional regression 
forests which combine the idea of random forests with distributional 
regression in order to obtain a flexible class of forecast models 
where the full forecast distribution depends on the predictors. 
This new approach is demonstrated in the context of probabilistic 
precipitation forecasting where it is used to construct full 
predictive distributions based on the output of an ensemble 
weather prediction model. The paper is very well written, the 
proposed methodology is useful, and the data example used to 
illustrate this method is practically relevant and discussed 
thoroughly.
\end{review}

Thank you very much for your advice and the positive feedback, 
it is highly appreciated!


\begin{review}
A typical limitation of very flexible modeling approaches like 
the one proposed here is that a sufficiently large sample is 
required to fit the model. Can the authors provide some 
guidelines as to how large the training sample needs to be for 
this method to be effective? Does the stopping criterion 
guarantee that the model is not overfitted? 
Is it obvious how to define the specific stopping criterion and 
if not, can general guidelines for doing so be provided?
\end{review}

The required size of the training data heavily depends on the complexity 
of the underlying effects. However, in different applications we have tested the 
distributional forest performed quite well starting from about 50--100 observations.

Applying the Law of Large Numbers it can be shown that random forests do not overfit 
as the number of trees increases (Breiman 2001, Hastie et al.\ 2001, 
Biau and Scornet 2016). Therefore, in principle, forests can be built with a very
large number of trees as this cannot deteriorate the predictions.
However, ``[\dots] the computational cost for inducing a forest increases linearly 
with the number of trees, so a good choice results from a trade-off between 
computational complexity and accuracy'' (Biau and Scornet 2016, p.~205). Following this 
advice, we decided to build forests consisting of 100 trees. Increasing this number
further would not change the results much.

Moreover, Hastie et al.\ (2001, p.~596) recommend to build trees of maximal depth:
``Our experience is that using full-grown trees seldom costs much, and 
results in one less tuning parameter.''
Thus, the stopping criteria \texttt{minbucket} and \texttt{minsplit} (both 
determining the minimal number of observations in a node) should be kept low
-- but in our context large enough for estimating the distribution parameters
reasonably well. Thus, in our application we have set \texttt{minsplit} to 50 and
\texttt{minbucket} to 20. The significance level \texttt{alpha} (for early stopping
upon non-significance) is set to 1, thus disabling such early stopping.
These tuning parameters are now also listed in the main manuscript in Sections~3.2.
and discussed in Section~4.


\begin{review}
The equations are not numbered but the authors refer to equations 
by number (e.g. bottom of p7)
\end{review}

We apologize for the confusion that the missing equation numbers 
have caused. They have now been added.

\begin{review}
In the last section where computational details are discussed, 
can you also provide some information on the computational cost? 
In a weather forecasting contest like the one discussed here, 
forecasts are often provided on a high-resolution grid, 
so it would be important to understand if the approach 
proposed here is computationally affordable. This is not clear 
to me because the nearest neighbor weights are specific 
to each new observation, so in a forecasting context these 
computations have to be done in realtime.
\end{review}

We have measured fitting time and prediction time for our 
application. For observation-by-observation predictions -- as
done in real-time -- the computational cost for the distributional
forest is comparable to the GAMLSS approaches. The former have
to re-fit the model using the observation-specific weights
while the latter has to set up the model matrices for all the
additive terms. However, when predicting a set of observations
the costs for the GAMLSS are lower (due to leveraging matrix
operations) and for the distributional forest higher (as it
still operates observation-wise) but not prohibitively so.
The exact results and times can be found in Supplement B
(Stationwise Evaluation).


\begin{review}
abstract: the acronym `GAMLSS' should be spelled out the first 
time it is used
\end{review}

We have rephrased this part of the abstract now spelling out
`GAMLSS' more explicitly at its first appearance.

\begin{review}
p3: I'm not sure if people outside the weather forecasting 
community is familiar with the notion of an `ensemble', so 
this should be explained briefly
\end{review}

Ensemble models are now introduced in more detail in the
first paragraph of Section~3.


\begin{review}
p7: What is meant by `domain knowledge'?
\end{review}

We have rephrased this to `expert knowledge in the application domain'
in Section~2.2.


\begin{review}
p14: Was there any particular rationale for choosing Axams 
as the station to be studied in detail
\end{review}

Axams was chosen as the observation station being closest 
to Innsbruck, the capital of Tyrol and the work place of 
three of the authors, but not based on any other particular 
features. Furthermore, it has been checked whether it 
is an adequate representative of all stations regarding 
the results of our evaluations. This is now also 
confirmed by further analysis in Supplement B (Stationwise Evaluation) 
and discussed in Section~4.

\begin{review}
Fig. 4: Are these the plots for residuals of precipitation 
at the original or at the transformed scale?
\end{review}

The residual QQ plots (Dunn et al.\ 1996) are built on top of
the probability integral transform (PIT, Gneiting et al.\ 2007).
Therefore they are invariant to transformations that preserve
the PIT, as is the case here. A more detailed 
explanation can be found in Supplement B (Stationwise Evaluation).

\begin{review}
p17: Is there any explanation why the prespecified GAMLSS 
method is the best-performing method in East Tyrol? Any 
explanation why the distributional regression forests 
performed less well than the simple EMOS method in this area?
\end{review}

This seems to result from the one specific training and validation period 
(training: 1985--2008, validation: 2009-2012) and from East Tyrol having
somewhat different weather than the rest of Tyrol.

The advantages of the GAMLSS model even out at most of the stations when looking 
on the results of a cross-validation. We have extended Section~4 to discuss this 
issue. The results of an extended evaluation including a cross-validation for a 
set of $15$ stations can be found in Supplement B (Stationwise Evaluation).

\newpage


\textbf{\LARGE Reviewer 1}

\bigskip

\textbf{General comments:}

\begin{review}
The article presents a new parametric methodology, called 
distributional forests, to estimate the probability 
distribution of some random variables, based on information 
from covariates. The methodology is new in that it mixes the
automatic variable selection properties of random forests 
with a parametric assumption on the forecast distribution. 
This allows to keep the interpretability of parametric 
distributions with the flexibility of random forests in 
dealing with local fitting, non-linearity, interactions 
and variable selection.

This approach may be used in applied statistics, as 
illustrated with its application to forecasting daily 
precipitation amount in the mountainous region of Tyrol, 
Austria. The mountains make it very difficult for numerical 
weather prediction models to forecast local precipitation. 
Statistical post-processing of weather forecasts allows 
downscaling the prediction.

The paper is well written and is a pleasant reading. 
The methodology is introduced clearly and well grounded 
in statistical practices, but some points need to be 
made clearer (see later).

The article shows on the Tyrol rain forecasts that the 
proposed method performs better than three other methods, 
among which is the current state-of-the-art in statistical 
post-processing in meteorology (EMOS). Thus distributional
forests may be added to the several statistical post-processing 
techniques, as an efficient and easy-to-use parametric 
probabilistic forecast.

I recommend the paper to be published after the following 
minor revisions have been taken into account.
\end{review}

Thank you very much for the positive and constructive 
comments regarding the paper. These helped to 
substantially improve the manuscript.

\bigskip

\textbf{Specific comments:}

\begin{review}
1. {\color{quotecolor} page 2: exceedence}\\
This spelling is not wrong, but less common than ``exceedance''.
Please change into \textit{exceedance}
\end{review}

This has been changed in the manuscript.

\begin{review}
2. {\color{quotecolor}\textit{page 2:} 10$\%$ to 90\% quantile}\\
Please change into \textit{10\% to 90\% quantiles}
\end{review}

This has been changed in the manuscript.

\begin{review}
3. {\color{quotecolor}\textit{page 5:} Fig 3, caption: Observations 
are left-censored at 0}\\
Since observations are precipitation amount, they are truncated, not 
left-censored (which may let think that they could be negative). 
Please change into \textit{Observations are truncated at 0}
\end{review}

You are right, our explanation was incorrect, thank you for pointing
this out. We have now clarified that the \emph{model} employs a censored
distribution while the \emph{observations} are not censored, just non-negative
with many ties at zero.


\begin{review}
4. {\color{quotecolor}\textit{page 5:} Fig 3, caption: censoring point}\\
Please change into \textit{truncation point}
\end{review}

We have rephrased this part of the caption to ``Observations are non-negative 
and modeled by a Gaussian distribution left-censored at zero.
The observations are depicted by crosses and the predicted point mass
from the model by filled circles.'' to clearly distinguish between the
\emph{model} and the \emph{observations}.


\begin{review}
5. {\color{quotecolor}\textit{page 5:} Fig 3, legend: Point mass at 
censoring point}\\
Please change into \textit{Point mass at truncation point}
\end{review}

See point 4.

\begin{review}
6. {\color{quotecolor}\textit{page 5:} Fig 3, x label: $mm^{(1/1.6)}$/24\textit{h}}\\
This is not a very common unit, which make the figure not easily 
interpretable. Furthermore, since you have not yet said that 
observations have been power transformed, this may be surprising 
here at first reading. Please redraw this figure with 
observations in $mm$/24$h$.
\end{review}

Thank you for the advice, the figure is now redrawn on the scale $mm$/24$h$.


\begin{review}
7. {\color{quotecolor}\textit{page 7:} see Equation 2.1}\\
Your equations have no numbering. Please add one.
\end{review}

We apologize for the confusion that the missing equation numbers 
have caused. They have now been added.

\begin{review}
8. {\color{quotecolor}\textit{page 8:} $\hat{\Theta}(z) = \cdots$}\\
This expression may lead to think that the parameter is estimated 
for each new prediction. If I am right, this is not the case, 
since the weights $w_i^{tree}$ are either $0$ or $1$. Thus the 
estimated parameter vector is the same as the one for the 
observations in the same segments as the new observation.
Please make this clear in the text.
\end{review}

For each new observation $z$ the corresponding 
parameter vector $\hat{\Theta}(z)$ can be calculated following 
the given formula. But you are right, this is equivalent to simply
obtaining the parameter vector that has been estimated in the 
corresponding node when learning the tree. This is now emphasized
in the last paragraph of Section~2.2.


\begin{review}
9. {\color{quotecolor}\textit{page 9:} Each of the distributional trees}\\
Please change into \textit{Each of the distributional tree}
\end{review}

We have rephrased the second paragraph of Section~2.3.

\begin{review}
10. {\color{quotecolor}\textit{page 9:} $w_i^{forest}$}\\
The normalization with $|B_b^t|$ makes the weight $w_i^{forest}$ 
take their value in $[0; 1]$. If I am not wrong, this means the 
parameter vector has to be estimated for each new prediction. 
How long does it take? For operational applications, the time 
to produce post-processed forecast may be a constraint. It may 
be interesting to compare the prediction time with distributional 
forest and with GAMLSS, since you claim in the abstract that
GAMLSS are computationally demanding. Please add some information
about the computation time to train your models and produce predictions.
\end{review}

Yes, in distributional forests the parameter vector has to be estimated 
separately for each new prediction as it is based on
observation-specific weights. For that reason, making 
predictions for \emph{a set of} new observations is more 
time consuming for the forest (where predictions are obtained
separately) than the GAMLSS models (where matrix operations
can be leveraged). However, when making predictions observation
by observation -- as done in real-time -- the time required is
comparable for the forest and GAMLSS. The exact results 
regarding fitting and prediction times can now be found in
Supplement B (Stationwise Evaluation).


\begin{review}
11. {\color{quotecolor}\textit{page 10:} While this approach 
alone is already highly effective in the plains, it typically 
does not perform as well in complex terrain due to unresolved 
effects in the NWP system. For example, in the Tyrolean 
Alps -- considered in the following case study -- the NWP grid 
cells of $50 \times 50$ km$^2$ are too coarse to capture single 
mountains, narrow valleys, etc.}\\
Do you have references about this lack of performance of NWP 
in complex terrains? If so, please add them.
\end{review}


A reference to Bauer, Thorphe, and Brunet (2015) has been added. They
give a good overview of the history and open scientific challenges
of NWP ensemble forecast models including a discussion about
unresolved processes and possible solutions beyond the current state
of NWP models.

To illustrate the issue in our forecast domain,
the following figure shows a comparison of the true local topography
(Robinson et~al. 2014; left)
and the model topography of the GEFS reforecast model
($0.5^\circ \times 0.5^\circ$, approx. $50 \times 50~km^2$; right). 
This conveys the extent of topographical simplification needed in
such global weather forecast models.

\begin{center}
\setkeys{Gin}{width=0.8\textwidth}
<<topography, fig=TRUE, echo=FALSE, height=3.5, width=8>>=

# Preamble
library("sp")
library("raster")
#library("ncdf4")
data(StationsTyrol, package = "RainTyrol")
data(MapTyrol, package = "RainTyrol")
# data(MapTyrol_border, package = "RainTyrol")
# Create SpatialPointsDataFrame from station list
sp <- SpatialPointsDataFrame(subset(StationsTyrol,
                                    select=c(lon,lat)),
                             data = subset(StationsTyrol,
                                           select = -c(lon,lat)),
                             proj4string = crs(MapTyrol$RasterLayer))


## plot map of Tyrol with all 95 observations
par(mfrow = c(1, 2), mar = rep(0.1, 4), oma = rep(3, 4))

# limits and axis config
zlim <- c(400, 3900)
xat  <- pretty(coordinates(MapTyrol$RasterLayer)[,1], 5)
yat  <- pretty(coordinates(MapTyrol$RasterLayer)[,2], 5)
cols <- gray.colors(100, start = 0.95, end = 0.05)

# Plotting "real" topography
raster::image(MapTyrol$RasterLayer, col = cols,
              main=NA, ylab = "Latitude", xlab = "Longitude",
              xlim = c(9.8,13.2), ylim = c(46.6, 47.87), zlim = zlim,
              xaxt = "n", yaxt = "n")
box()
plot(MapTyrol$SpatialPolygons, add = TRUE)
points(sp, pch = 19, cex = .5)
axis(side = 1, at = xat); axis(side = 2, at = yat)
mtext(side = 2, line = 2, cex = .8, "Latitude")

# Loading and plotting regular_ll GFS topography
##gfs <- raster("gfs_topo.nc")
##gfs_resampled <- raster::resample(gfs, MapTyrol$RasterLayer)
raster::image(MapTyrol$RasterLayerGFS, col = cols,
              main=NA, ylab = "Latitude", xlab = "Longitude",
              xlim = c(9.8,13.2), ylim = c(46.6, 47.87), zlim = zlim,
              xaxt = "n", yaxt = "n")
box()
plot(MapTyrol$SpatialPolygons, add = TRUE)
points(sp, pch = 19, cex = .5)
axis(side = 1, at = xat); axis(side = 4, at = yat)
mtext(side = 4, line = 2, cex = .8, "Latitude")

mtext(side = 1, line = 2, cex = .8, outer = TRUE, "Longitude")
# Title
mtext(side = 3, line = 1, cex = 1.2, font = 2, outer = TRUE,
      "Comparison of Real Topography and GFS Model Topography")
@
\end{center}


%\begin{verbatim}
%@Article{Bauer2015,
%    author   = {Bauer, Peter and Thorpe, Alan and Brunet, Gilbert},
%    title    = {The Quiet Revolution of Numerical Weather Prediction},
%    journal  = {Nature},
%    year     = {2015},
%    month    = {Sep},
%    day      = {02},
%    volume   = {525},
%    pages    = {47--55},
%    doi      = {10.1038/nature14956}
%}
%\end{verbatim}
%Bauer and Thorpe (2015, p.~52): ``\textit{The scientific challenges:
%[\dots] the uncertainties inherent to physical parameterizations, either
%from incomplete process understanding or the dilemma of representing
%the impact of unresolved processes on the resolved scales, may require a
%fundamentally different approach.''



\begin{review}
12. {\color{quotecolor}\textit{page 11:} Table 1, caption}\\
Please move the caption above the table.
\end{review}

This has been changed in the manuscript.

\begin{review}
13. {\color{quotecolor}\textit{page 12:} Parameters are estimated 
by adaptive local likelihood based on the forest weights as 
described in Section 2.}\\
Please explain what is your stopping criterion.
\end{review}

As stopping criteria the minimal number of observations to perform 
a split (\texttt{minsplit}) is set to 50, the minimal number of 
observations in a terminal node (\texttt{minbucket}) is set to 20 
and early stopping (or ``pre-pruning'') based on the significance level is disabled
(by setting \texttt{alpha} to 1). We have added this information in 
the manuscript in Section~3.2, `Distributional forest', and
also discussed the choice of these tuning parameters in Section~4 and
in the answer to the second point of the associate editor.


\begin{review}
14. {\color{quotecolor}\textit{page 13:} Table 2, caption}\\
Please move the caption above the table.
\end{review}

This has been changed in the manuscript.

\begin{review}
15. {\color{quotecolor}\textit{page 17:} Thus, while the covariates 
themselves are not surprising, selecting a GAMLSS with a particular 
combination of all the transformations would be much more challenging.}\\
Did you compare the most important covariates in distributional forests
with the ones in preselected GAMLSS? If so, is there some insightful
information you could add?
\end{review}


The distributional forest selects very similar covariates as included in the
prespecified GAMLSS model. For both models, total precipitation (\texttt{tp})
and total column-integrated condensate (\texttt{tcolc}) are the two most important
covariates. Due to the randomization within the nodes, the distributional forest selects different variations of the same covariate (e.g., \texttt{tp\_max}, \texttt{tp\_mean},
\texttt{tp\_min}; see Figure~6 in the main manuscript and Supplement B) while
the prespecified GAMLSS mainly only uses one specific variation (\texttt{tp\_max}).
The same is true for variations of \texttt{tcolc\_mean\_*}, \texttt{tcolc\_sprd\_*}
and \texttt{tcolc\_sprd\_*}.

Overall, the covariates selected by the distributional forest do not provide 
new meteorological insights but show that the prespecified GAMLSS model contains an appropriate 
subset of all available covariates.


\begin{review}
16. {\color{quotecolor}\textit{page 20:} If $Z_l$ is numeric 
then $v_l$ is simply the identity function $v_l(z_l^i) = z_l^i$. 
If $Z_l$ is a categorical variable with $H$ categories then 
$v_l(z_l^i) = e_H(z_l^i) = (I(z_j^i = 1), \dots , I(z_l^i = H))$ 
such that $v_l$ is a unit vector}\\
Based on this sentence, $v_l$ can be a vector or a scalar, 
which makes not very clear what $T_l$ is: is it a vector 
or a scalar? Please clarify.
\end{review}

Apologies for the unclear notation in Appendix~A.
Depending on whether the split variable $Z_l$ is a numeric 
or a categorical variable, $t_l$ is a vector either of
dimension $k$ or $k \cdot H$.
We have revised the corresponding parts in the manuscript (also 
regarding your comments 17--20) and hope that these aspects
are now conveyed clearly.


\begin{review}
17. {\color{quotecolor}\textit{page 20:} the observed 
multivariate linear statistic $t$}\\
What is $t$? Is it the vector with $m$ components $T_l$? 
Please clarify.
\end{review}

Here we are actually referring to the linear statistic $t_l$ (instead of $t$) 
which is the observed value of $T_l$, the test statistic for the $l$-th split 
variable $Z_l$. This has been adjusted in the appendix of the manuscript.

\begin{review}
18. {\color{quotecolor}\textit{page 20:} $c_{quad}(t, \mu, \Sigma)$}\\
$\mu$ and $\Sigma$ have not been defined. What is their relationship 
with $\mu_l$ and $\Sigma_l$? Please clarify.
\end{review}

As in the previous point this was just a general notation, but 
actually the variables corresponding to the $l$-th split variable 
are considered, i.e. $t_l$, $\mu_l$ and $\sigma_l$. Thank you for
pointing this out, the missing indices have been added in the
appendix of the manuscript.

\begin{review}
19. {\color{quotecolor}\textit{page 21:} it has to be assessed 
whether any of the resulting p-values is beneath the selected 
significance level. If so, the partitioning variable $Z_l$
with the lowest p-value is chosen as splitting variable.}\\
What if no p-value is beneath the selected significance level. 
Is it a stopping criterion? Please clarify.
\end{review}

Yes, significance can be used as one of the stopping criteria,
so that partitioning is stopped early upon non-significance
of the tests. This is sometimes also called ``pre-pruning'' in
the tree literature.

However, in our applications pre-pruning is disabled which
is explained in Section~3.2 and in the appendix.


\begin{review}
20. {\color{quotecolor}\textit{page 21:} $B_{1r}$ is the first 
of the two new subgroups that are defined by splitting in split 
point $r$ of variable $Z_{l^{\ast}}$}\\
What do you mean by ``first of the two new subgroups''? Is it 
the subgroup with values $Z_{l^{\ast}} > r$? I don't see how 
such an ordering can be achieved if $Z_{l^{\ast}}$ is an 
unordered categorical variable. Please clarify how the two
subgroups are ordered.
\end{review}

The two subgroups are not ordered which is also not necessary as only 
the sum of scores over the two subgroups is considered for the linear 
statistic $T_{l^{\ast}}^{qr}$. We have adjusted the appendix of
the manuscript to clarify this issue.

\newpage


\textbf{\LARGE Reviewer 2}

\begin{review}
The authors propose an extension of non-homogeneous Gaussian models 
for the use in weather forecasting based on parametric distributional 
models (GAMLSS). While the latter have proved to be applicable to a 
wide range of empirical questions, the authors focus on precipitation 
forecasts in the Alps. The approach combines a distributional model 
with a random forest, which they call distributional random forests, 
in order to include variable selection and interactions or 
non-linearities of predictors. I have a number of major concerns 
given in the following. My impression is that the method is rather
an extension of existing methodology on random forests to censored 
normal problems without important with a lack in discussing 
advantages and disadvantages of distributional regression models 
and only a rather minor improvement over certain competitors.
\end{review}

Thank you very much for your feedback and helpful suggestions. We hope 
the improvements we made address your doubts and concerns.

\bigskip

\textbf{Main comments:}

\begin{review}
1. It is obvious in distributional regression that not only the 
variables influence the predictive performance but rather that 
the exact distributional assumption has a big impact on both the 
fit and the prediction. The authors do not consider any other
than the censored normal distribution, which I found odd. 
In earlier references, they used the same distribution but I 
did not find any justification why not to use a truncated normal, 
a zero-adjusted model or a continuous part for $y > 0$ other
than the normal. In any distributional model, checking the 
assumption on the error density is a crucial step which in 
my opinion should not be ignored or assumed not to be a problem.
\end{review}

Thank you for emphasizing this issue. In the initial submission
we did include assessments of calibration by graphical means
(QQ plots and PIT histograms). But we completely agree that a
more thorough assessment of the distributional specification is
preferable in this context.

Therefore, we followed your advice and considered both a different
distribution for the continuous part and a two-part hurdle model.
For the former, the logistic distribution (also left-censored at zero)
is used as it has heavier tails and was previously used in the
precipitation forecasting literature (Stauffer et al.\ 2017b).
For the latter, a two-part model is used combining a binary
zero hurdle ($y = 0$ vs.\ $y > 0$) and an adjusted Gaussian distribution
(left-truncated at zero).

We have carried out the same evaluations as presented in the main manuscript and 
present the full results in Supplement A (Different Response Distributions). 
The main insights from this are also discussed in Section~4:
At most stations the censored Gaussian distribution from the main
manuscript performs at least as well as the two alternative
distributions. %, if not better. 
Moreover, the distributional forest proves to be rather robust against distributional
misspecifications. Therefore, the discussion in the main manuscript is still based
on the censored Gaussian distribution.


\begin{review}
2. The response and some predictors are power transformations 
of originally measured variables like total precipitation as 
it is known that skewness is usually present. Why? As far as I 
understand, one major advantage of distributional models is
that the response does not have to be normal but to model scale, 
skewness and the shape in general as a function of the covariates. 
By applying the transformation in advance and hence marginally, 
the dependence of covariates on further moments of the response 
is assumed to be not existing and simply ignored.
\end{review}

Our manuscript follows the frequently-used approach of applying a
power-transformation (Stidd 1973, Hutchinson 1998, Stauffer et al.\ 2017a)
to be more easily comparable to previous publications in the field.
These focus on predicting location and scale based on mean and
variance from the NWP ensemble. Hence, we also follow that approach
but adopt a different strategy for estimating selecting variables
and estimating nonlinear effects and interactions.

As you correctly point out, another way to deal with skewness is to
use an extended distributional specification (e.g., Scheuerer and Hamill 2015,
Baran and Nemoda 2016). This increases the complexity of the statistical
models and makes the comparison to publications based on power transformations
more difficult. Therefore, we feel that this exceeds the scope of this
contribution but we do discuss it in Section~4 as being of interest for
future research. 



\begin{review}
3. Is a random forest really the right thing to do? In the 
end, the analyst or meteorologist does not obtain an 
interpretable model and no explanation which variable 
affects the distribution in which direction is possible. 
I think, the reason that focusing on predictions should 
be made clearer and well justified.
\end{review}

We completely agree with you that GAMLSS are tremendously useful,
especially in situations where an interpretable but still
well-performing model is needed. The intention of our work is not
to present distributional forests as a replacement of GAMLSS but
rather as a complementing technique for the distributional regression
toolbox. Much like random forests and GAMs are complements for
conditional mean regression.

In this sense, distributional forests are appealing for weather
forecasting tasks because the focus is not so much on interpretation
but often much more on: (a)~forecasting skill and (b)~(semi-)automatic
application of models on a larger domain. See also the discussion
in, e.g., Rasp and Lerch (2018).

We have adapted our introduction (Section~1) and discussion (Section~4)
to better reflect these aspects.



\begin{review}
4. The method itself is hard to follow in particular since 
authors reference to equations without using equation numbers. 
The part on random forests for instance is quite a black box 
without looking into a number of earlier works of some of 
the authors. From an applied perspective, there should be a 
better motivation and connection of the methodology and the 
data application.
\end{review}

We apologize for the confusion that the missing equation numbers 
have caused. They have now been added.
We have also rephrased Section~2.3. which now first introduces random 
forests and then distributional forests as an extension of classical 
random forests.


\begin{review}
5. In the introduction it is said that ``while requiring no 
expert knowledge for the model specification''. I do not think 
it is true given that the authors do not consider a possible 
distributional misspecification at all. In addition, If I am 
not wrong, the functional forms in the distributional 
regression models do not have to be prespecified. Applying a 
mixed model type representation it should be possible to
have for instance interaction surfaces separated into the pure 
interaction effects and the main effects. For instance, 
Wood et al.\ (2013) discuss a generic approach for defining 
well-identified and interpretable effect decompositions in 
tensor product interactions again based on the mixed model 
representation of penalised model components, while Goicoa 
et al.\ (2017); Ugarte et al.\ (2017) determine the identifiability
constraints from the null space of the penalties associated 
with the spatio-temporal interaction effect.
\end{review}

Thank you for your suggestions and the references. Indeed we did
not discuss sufficiently the possibilities for including interactions
in GAMLSS. This has been remedied, see Section~4.

However, in our application the number of covariates is too large
(80) to even consider all pairwise interactions (3160 combinations)
using the approaches mentioned above, let alone interactions of higher orders.

We now discuss this in Section~4 of the main manuscript and
rephrased the corresponding sentence in the introduction to ``while 
requiring no meteorological knowledge about the atmospheric processes 
which drive formation of precipitation for the model specification'' 
in order to clarify that this pertains to the variable selection.


\begin{review}
6. A simulation study designed according to the data set should 
be used in order to give an empirical evidence that the random 
forests are generally better able to perform predictions compared 
to the competing methods. The figures indicate that advantages 
for the chosen station are rather minor and one should keep in 
mind that GAMLSS and boosting yield interpretable results which 
the random forests do not do. Also, what happens when choosing 
another station than Axams? The figure 8 indicates that the 
distributional forest does not perform better in all stations 
and I am wondering whether a meteorologist would really do a 
better job on a relative scale of precipitation.
\end{review}

In order to investigate these questions we have carried out the full
analysis as presented for station Axams in the main manuscript for 14
further observation stations. It shows that at most stations the 
distributional forest is competitive with the best among the other 
methods or even better. The exact results are provided in 
Supplement B (Stationwise Evaluation) and discussed in Section~4. 
Especially for meteorologists intending to apply model output 
statistics (MOS) for dozens or hundreds of observation stations 
(e.g., Wahl 2014, Rasp and Lerch 2018)
the distributional forest provides a good and robust alternative. 
Computational costs are clearly higher than for a basic EMOS model, 
but similar to a prespecified GAMLSS and lower than for GAMLSS
using variable selection by cross-validation. Fitting and forecasting
times are reported now in Supplement~B (Stationwise Evaluation).

Regarding forecasting tasks other than the one presented in
the manuscript, we would \emph{not} expect that distributional
forests are \emph{``generally better''}. As for (boosted) GAMs and
random forests we would expect that sometimes (boosted) GAMLSS and
sometimes distributional forests perform better. As already argued
above we see the methods as complements not substitutes.
This is now also mentioned in Section~1 and discussed in Section~4,
\textit{Variable Selection}.



\begin{review}
7. How are the folds chosen for performing the predictions? 
Is it 4 subsequent years or randomly chosen 4 years out of 
the 28? I expect this to have a strong impact on the predictions 
and sensitivity with respect to this needs to be considered both 
in simulations and the real study.
\end{review}

The folds of the cross-validation are chosen randomly. The data 
set of 28 years is split randomly into 7 blocks of 4 years which 
are not necessarily successive. This is now also explained in the 
description of the cross-validation setup in the third paragraph of 
Section~3.3. As already argued previously, the same cross-validation
approach is not only applied to Axams but also 14 further stations
in Supplement~B to check for robustness across stations.

In addition to the cross-validation setup there is also the setup
where models are learned on the first 24 years and evaluated on the
final 4 years. Thus, the classic time-ordered setup is employed there,
again for Axams and 14 further stations.

Moreover, no influence of time is to be expected as autocorrelations of
daily lags are typically very low. For example, the autocorrelation
coefficient of the out-of-bag quantile residuals from the distributional
forest for station Axams is only $-0.007$.
% ## calculation of autocorrelation:
% load("Axams_24to4.rda") 
% set.seed(4)
% pdf <- predict(Axams_24to4$df, newdata = Axams_24to4$testdata, type = "parameter")
% pit_df <- cbind(0, pnorm(Axams_24to4$testdata[,"robs"], mean = pdf$mu, sd = pdf$sigma))
% pit_df[Axams_24to4$testdata[,"robs"]>0, 1] <- pit_df[Axams_24to4$testdata[,"robs"]>0, 2]
% ac <- acf(qqrplot(pit_df)$residuals)


\begin{review}
8. I found the competing models to be chosen pretty unfair. 
First, for the prespecified GAMLSS, the authors use ``relevant effects based on expert knowledge''. Why not all? 
Why not making a decision on some information criteria such as AIC/BIC? 
The latter would be done if the analyst decided to use a prespecified 
GAMLSS. I guess, the GAMLSS could improve a lot by this . 
\end{review}

As mentioned in our response to your comment 5 above (and now also discussed in Section~4),
the high number of covariates (80) prevents simply including all variables
(or even all interactions) without further penalization. For an AIC- or BIC-based selection an 
evaluation of 80 main effects for both distributional parameters would make this a very complex
procedure. Moreover, Hofner et al.\ (2016, p.~3) stated that the 
selection methods implemented in the \textsf{R} 
package \textbf{gamlss} ``[...] can be unstable, especially when it comes 
to selecting possibly different sets of variables for 
multiple distribution parameters.'' For that reason we considered
the boosting-based approach as an alternative approach to variable selection
in GAMLSS.


\begin{review}
Second, what does a basic EMOS exactly mean? 
\end{review}

By a `basic EMOS' we are referring to the idea of Gneiting et al.\ (2005)
that employs a distributional regression with linear predictors for
location and scale, respectively, based on the corresponding empirical
mean and variance from the NWP ensemble.
We now introduce the model which we are referring to as a `basic EMOS'
in detail in the main manuscript in the first paragraph of Section~3. 



\begin{review}
Third, why not to include interactions in the boosting algorithm 
as well? This should be conceptually straight forward? 
\end{review}

As argued above, including only pairwise interactions
of the 80 available variables would already lead to 3160 additional
covariates which would make the model even more complex and substantially
increase (the already high) computational costs. Therefore, we decided not to include
any interactions in the boosting algorithm which is now addressed and
discussed in Section~4.
% choose(80, 2)

\begin{review}
Fourth, why are 100 trees chosen in the forest? Is this a default 
value? May this number not also be dependent on the complexity of 
the model? Why not to choose the number of trees similar to what is 
done in boosting? This would also increase the computation time of 
the forest a lot.
\end{review}


As pointed out by Breiman (2001), random forests are very robust and do not overfit, 
not even for a high number of trees. However, computational costs increase 
linearly with the number of trees (Biau and Scornet, 2016).
Therefore, we followed their recommendations of choosing a high number of
trees, but still small enough to keep the computation time at
a reasonable level. For this, 100 is a commonly-used number of trees.
Tuning parameters of distributional forests, including the number of 
trees (\texttt{ntree}), are now discussed in Section~4 
of the main manuscript.





\bigskip

\textbf{Minor comments:}


\begin{review}
1. Given the length of the paper, I suggest to move the 
appendix to an online supplement.
\end{review}

Thank you for your advice. We have kept only the details regarding
the presented methodology in the appendix of the main manuscript
(Appendix A) and extended Appendix B to an online supplement
(Supplement B: Stationwise Evaluation).

\begin{review}
2. Does the EMOS method employ ensemble post-processing 
techniques? There are recent references using this in weather 
forecasting (Chen et al.; 2014)?
\end{review}

The EMOS as originally suggested by Gneiting et al.\ (2005) can be seen
as one of the standard ensemble model output statistics (or post-processing)
approaches. This concept is well known within the post-processing community.
We have revised the introduction of our manuscript and introduce the `basic EMOS'
more explicitly and in more detail (cf., Section~3).


\begin{review}
3. Looking at the PIT in the appendix, they seem to provide a 
worse fit as compared to the quantile residuals. Also, both 
just give a graphical device. If the focus is on prediction 
then my impression is that one should rather plot PIT and 
residuals for the predictions.
\end{review}

The PIT histograms and the residual QQ plots visualize the same
results on different scales. The out-of-sample PIT values are 
either plotted in a histogram or plotted against the corresponding
quantiles of the standard normal distribution. A more detailed 
explanation can be found in Supplement B (Stationwise Evaluation) 
which contains both, PIT histograms and residual QQ plots, 
for 15 stations. In the manuscript we decided to only show the 
residual QQ plot as it allows for a better analysis of the 
behavior in the upper tail compared to the PIT histogram.


\begin{review}
4. Figure 5: Which most important variables are included in the 
boosting algorithm? Why are the 10 most important covariates chosen?
\end{review}


The covariates selected in the distributional forest strongly overlap with the 
ones selected in the boosted GAMLSS. Both methods select variations of the 
forecasted total precipitation (\texttt{tp}) and the total column-integrated 
condensate (\texttt{tcolc}). Due to the randomization in the nodes of the 
trees, different variations of the same covariate (e.g., \texttt{tp\_max}, 
\texttt{tp\_mean}, \texttt{tp\_min}) are selected by the distributional 
forest while the boosted GAMLSS only uses one specific variation (\texttt{tp\_max}). 
The following figure show the CRPS variable importance of the boosted GAMLSS 
model for the very same training and validation period as in Figure~6 in the
manuscript.

\begin{center}
\setkeys{Gin}{width=0.6\textwidth}
<<varimp_gb, fig=TRUE, echo=FALSE, height=4, width=6>>=
if(file.exists("vimp_crps_gb.rda")){
  load("vimp_crps_gb.rda")
} else {
  
  nperm <- 50
  library("gamboostLSS")
  library("crch")
  library("scoringRules")
  library("RainTyrol")
  
  # set function for parallelization
  applyfun <- function(X, FUN, ...) parallel::mclapply(X, FUN, ..., mc.cores = pmax(1, detectCores() - 1))
  
  # model
  load("Axams_24to4.rda")
  gb <- Axams_24to4$gb
  
  # data
  data("RainTyrol")
  RainData <- RainTyrol[RainTyrol$station == "Axams", ]
  rownames(RainData) <- c(1:NROW(RainData))
  
  # learning data: 24 years (1985 - 2008, both inlcuded)
  # testing data: 4 successive years (2009, 2010, 2011, 2012)
  # learndata <- RainData[RainData$year < 2009,]
  testdata <- RainData[RainData$year %in% c(2009, 2010, 2011, 2012),]
  
  ## compute variable importance for the gamboostLSS object 'gb'
  
  meancrps <- function(permute = NULL, newdata = testdata) {
    if(!is.null(permute)) newdata[[permute]] <- sample(newdata[[permute]])
    m <- predict(gb, newdata = newdata, parameter = "mu", type = "response")
    s <- predict(gb, newdata = newdata, parameter = "sigma", type = "response")
    mean(crps_cnorm(newdata$robs, location = m, scale = s, lower = 0))
  }
  
  
  # apply for all covariates except for dswrf_mean_min and 
  # dswrf_sprd_min (columns 30 and 33) as they are always 0
  
  risklist <- applyfun(1:nperm, 
                       function(i){
                         set.seed(i)
                         sapply(c(5:29, 31, 32, 34: ncol(testdata)), meancrps)
                       })
  risk <- Reduce("+", risklist) / length(risklist)
  
  names(risk) <- names(testdata)[c(5:29, 31, 32, 34: ncol(testdata))]
  vimp_crps_gb <- risk - meancrps(newdata = testdata)
  vimp_crps_gb <- sort(vimp_crps_gb, decreasing = TRUE)
  
  save(vimp_crps_gb, file = "vimp_crps_gb.rda")
  
}

top10_gb <- vimp_crps_gb[1:10]

par(mar = c(4,10,1,2))
barplot(rev(top10_gb), 
        horiz = TRUE, las = 1, axes = FALSE,
        xlab = "Variable importance: mean increase in CRPS",
        font.axis = 3, #list(family="HersheySerif", face=3),
        # xlim = c(0,1.1),
        xlim = c(0,0.4),
        names.arg = gsub("pow", "", names(rev(top10_gb))))
axis(1, at = seq(0,1.6,0.1), las = 1, mgp=c(0,1,0))
@
\end{center}

Due to graphical reasons, the plots only show the 10 \textit{most important}
covariates based on mean increase in CRPS, however, the models (distributional
forest and boosted GAMLSS) are allowed to use as many covariates as required.



\bigskip

%\bibliographystyle{jss}
%\bibliography{ref.bib}


\noindent{\large\textbf{References}}

\begin{itemize}[leftmargin=*]

\item[] Baran, S., and Nemoda, D. (2016). Censored and Shifted Gamma Distribution Based EMOS
Model for Probabilistic Quantitative Precipitation Forecasting,
\textit{Environmetrics}, \textbf{27}: 280--292.
%doi: 10.1002/env.2391.

\item[] Bauer, P. and Thorpe, A. (2015). The Quiet Revolution of Numerical 
Weather Prediction,
\textit{Nature} \textbf{525}: 47--55.
%doi:10.1038/nature14956

\item[] Biau, G. and Scornet, E. (2016).
A Random Forest Guided Tour,
\textit{TEST}
\textbf{25}: 197--227.

\item[] Breiman, L. (2001).
Random Forests,
\textit{Machine Learning}
\textbf{45, 1}: 5--32.

\item[] Chen, J., Brissette, F. P. and Lhi, Z. (2014). Postprocessing 
of Ensemble Weather Forecasts Using a Stochastic Weather Generator, 
\textit{Monthly Weather Review}.

\item[] Dunn, P. K. and Smyth, G. K. (1996).
Randomized Quantile Residuals,
\textit{Journal of Computational and Graphical Statistics}
\textbf{5, 3}: 236--244.

\item[] Gneiting, T., Balabdaoui, F. and Raftery, A. E. (2007).
Probabilistic Forecasts, Calibration and Sharpness,
\textit{Journal of the Royal Statistical Society B}
\textbf{69, 2}: 243--268.

\item[] Gneiting, T., Raftery, A. E., Westveld III, A. H. and Goldman, T. (2005). 
Calibrated Probabilistic Forecasting Using Ensemble Model Output Statistics and 
Minimum CRPS Estimation,
\textit{Monthly Weather Review} \textbf{133, 5}: 1098--1118.

\item[] Goicoa, T., Adin, A., Ugarte, M. D. and Hodges, J. S. (2018). 
In Spatio-Temporal Disease Mapping Models, Identifiability Constraints 
Affet PQL and INLA Results, \textit{Stochastic Environmental Research 
and Risk Assessment} \textbf{32, 3}: 749--770.

\item[] Hastie, T., Tibshirani, R. and Friedman, J. (2001).
The Elements of Statistical Learning, %Second Edition,
\textit{Springer New York Inc.}.

\item[] Hofner, B., Mayr, A. and Schmid, M. (2016). 
\textbf{gamboostLSS}: An \textsf{R} Package for Model Building and 
Variable Selection in the {GAMLSS} Framework,
\textit{Journal of Statistical Software} \textbf{74, 1}: 1--31.

\item[] Hutchinson M. F. (1998). Interpolation of Rainfall Data with Thin
Plate Smoothing Splines -- Part II: Analysis of Topographic Dependence,
\textit{Journal of Geographic Information and
Decision Analysis} \textbf{2, 2}: 152--167.
%doi:10.1080/02693799508902045

\item[] Meinshausen, N. and Buehlmann, P. (2010). 
Stability selection,
\textit{Journal of the Royal Statistical Society, Series B} 
\textbf{72}: 417--473.

\item[] M{\"u}ller, M. D. (2011): Effects of Model Resolution and Statistical
Postprocessing on Shelter Temperature and Wind Forecasts,
\textit{Journal of Applied Meteorology and Climatology} 
\textbf{50, 8}: 1627--1636.
%doi:10.1175/2011JAMC2615.1

\item[] Rasp, S., Lerch, S. (2018). Neural Networks for Post-Processing Ensemble
Weather Forecasts, \textit{Montly Weather Review}, \textbf{146, 11}:, 3885--3900.
%doi:\href{https://doi.org/10.1175/MWR-D-18-0187.1}{10.1175/MWR-D-18-0187.1}.

\item[] Scheuerer, M. and Hamill T. M. (2015). Statistical Postprocessing of
Ensemble Precipitation Forecasts by Fitting Censored, Shifted Gamma
Distributions,
\textit{Monthly Weather Review} \textbf{143, 11}: 4578--4596.
%doi:10.1175/MWR-D-15-0061.1

\item[] Stauffer, R., Mayr, G. J., Messner, J. W., Umlauf, N. and Zeileis, A. (2017a). 
Spatio-Temporal Precipitation Climatology over Complex Terrain Using a Censored Additive Regression Model,
\textit{International Journal of Climatology} \textbf{37, 7}: 3264--3275.

\item[] Stauffer, R., Umlauf, N., Messner, J. W., Mayr, G. J. and Zeileis, A. (2017b). 
Ensemble Post-Processing of Daily Precipitation Sums over Complex Terrain Using Censored High-Resolution Standardized Anomalies,
\textit{Monthly Weather Review} \textbf{45, 3}: 955--969.
%doi = 10.1175/mwr-d-16-0260.1

\item[] Stidd, C. K. (1973). Estimating the Precipitation Climate,
\textit{Water Resources Research}, \textbf{9, 5}: 1235--1241.
%doi:10.1029/wr009i005p01235

\item[] Ugarte, M. D., Adin, A. and Goicoa, T. (2017). One-Dimensional, 
Two-Dimensional, and Three-Dimensional B-Splines to Specify Space-Time 
Interactions in Bayesian Disease Mapping: Model Fitting and Model 
Identifiability, \textit{Spatial Statistics} \textbf{22}: 451--468.

\item[] Wahl, S. (2015). Uncertainty in Mesoscale Numerical Weather Prediction:
Probabilistic Forecasting of Precipitation, PhD thesis, 
\textit{University of Bonn}, p. 1--120.% \url{http://hss.ulb.uni-bonn.de/2015/4190/4190.pdf}.

\item[] Wood, S. N., Scheipl, F. and Faraway, J. J. (2013). 
Straightforward Intermediate Rank Tensor Product Smoothing in Mixed Models, 
\textit{Statistics and Computing} \textbf{23}: 341--360.

\end{itemize}



\end{document}
