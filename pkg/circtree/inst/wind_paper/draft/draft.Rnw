\documentclass[nojss]{jss}

%% packages
\usepackage{amstext,amsfonts,amsmath,bm,thumbpdf,lmodern,hyperref}
\usepackage[all]{hypcap}

%% tikz
\usepackage{array,makecell,tikz,color,soul}
\usetikzlibrary{arrows.meta,positioning,shapes,arrows,decorations.pathreplacing,calc,automata,mindmap}

%% need no \usepackage{Sweave}
\SweaveOpts{engine = R, concordance = FALSE, eps = FALSE, keep.source = TRUE, eval = TRUE}

%% commands
\newcommand{\fixme}[1]{\emph{\marginpar{FIXME} (#1)}}
\renewcommand{\Prob}{\mathbb{P} }
\renewcommand{\E}{\mathbb{E}}
\newcommand{\V}{\mathbb{V}}
\newcommand{\Var}{\mathbb{V}}
\newcommand{\R}{\mathbb{R} }
\newcommand{\N}{\mathbb{N} }
\newcommand{\C}{\mathbb{C} }
\newcommand{\argmin}{\operatorname{argmin}\displaylimits}
\newcommand{\argmax}{\operatorname{argmax}\displaylimits}
\newcommand{\LS}{\mathcal{L}_n}
\newcommand{\TS}{\mathcal{T}_n}
\newcommand{\LSc}{\mathcal{L}_{\text{comb},n}}
\newcommand{\LSbc}{\mathcal{L}^*_{\text{comb},n}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\A}{\mathcal{A}}
\newcommand{\yn}{y_{\text{new}}}
\newcommand{\z}{\mathbf{z}}
\newcommand{\X}{\mathbf{X}}
\newcommand{\Y}{\mathbf{Y}}
\newcommand{\sX}{\mathcal{X}}
\newcommand{\sY}{\mathcal{Y}}
\newcommand{\T}{\mathbf{T}}
\newcommand{\x}{\mathbf{x}}
\renewcommand{\a}{\mathbf{a}}
\newcommand{\xn}{\mathbf{x}_{\text{new}}}
\newcommand{\y}{\mathbf{y}}
\newcommand{\w}{\mathbf{w}}
\newcommand{\ws}{\mathbf{w}_\cdot}
\renewcommand{\t}{\mathbf{t}}
\newcommand{\M}{\mathbf{M}}
\renewcommand{\vec}{\text{vec}}
\newcommand{\B}{\mathbf{B}}
\newcommand{\K}{\mathbf{K}}
\newcommand{\W}{\mathbf{W}}
\newcommand{\D}{\mathbf{D}}
\newcommand{\I}{\mathbf{I}}
\newcommand{\bS}{\mathbf{S}}
\newcommand{\cellx}{\pi_n[\x]}
\newcommand{\partn}{\pi_n(\mathcal{L}_n)}
\newcommand{\err}{\text{Err}}
\newcommand{\ea}{\widehat{\text{Err}}^{(a)}}
\newcommand{\ecv}{\widehat{\text{Err}}^{(cv1)}}
\newcommand{\ecvten}{\widehat{\text{Err}}^{(cv10)}}
\newcommand{\eone}{\widehat{\text{Err}}^{(1)}}
\newcommand{\eplus}{\widehat{\text{Err}}^{(.632+)}}
\newcommand{\eoob}{\widehat{\text{Err}}^{(oob)}}
\newcommand{\bft}{\mathbf{t}}

\definecolor{changes}{rgb}{1,1,0.7}
\newcommand{\hlc}[1]{{\sethlcolor{changes}\hl{#1}}}

\numberwithin{equation}{section}


<<preliminaries, echo=FALSE, results=hide>>=
options(prompt = "R> ", continue = "+  ", useFancyQuotes = FALSE, width = 70)
library("disttree")
library("circtree")

## HCL palette
pal <- hcl(c(10, 128, 260, 290, 50), 100, 50)
pallight <- hcl(c(10, 128, 260, 290, 70), 100, 50, alpha = 0.25)
transpgray <- rgb(0.190,0.190,0.190, alpha = 0.2)

# set function for parallelization
applyfun <- function(X, FUN, ...) parallel::mclapply(X, FUN, ..., mc.cores = pmax(1, parallel::detectCores() - 1))

@



\title{Circular Regression Trees and Forests with an Application to
Probabilistic Wind Direction Forecasting}
\Shorttitle{Circular Regression Trees and Forests}

\author{Moritz N. Lang\\Universit\"at Innsbruck
   \And Lisa Schlosser\\Universit\"at Innsbruck
   \And Torsten Hothorn\\Universit\"at Z\"urich
   \AND Georg~J.~Mayr\\Universit\"at Innsbruck
   \And Reto Stauffer\\Universit\"at Innsbruck
   \And Achim Zeileis\\Universit\"at Innsbruck}
\Plainauthor{M. N. Lang, L. Schlosser, T. Hothorn, 
G. J. Mayr, R. Stauffer, A. Zeileis}

\Abstract{
Despite the occurrence of circular data in a wide range of scientific
fields, the existing methodology for probabilistically forecasting
circular data
is highly limited. Most of the existing methods are built on the
framework of
generalized linear and additive models, which can incorporate
difficulties in
both the optimization and the interpretation. As a very intuitive
alternative
to additive circular regression models, we extend previous ideas of circular
trees and introduce probabilistic circular regression trees and forests
employing the von Mises distribution. The resulting tree-based models
simplify
the estimation process by separating the data into more homogeneous
subgroups
and fitting a simple intercept-only model for each resulting subset. By
incorporating the framework of distributional modeling, splits in all
distribution parameters are considered and a fully specified distribution is
provided for each terminal node.  The proposed circular regression trees are easy to
interpret, can detect non-additive effects, and select covariates and their
interactions automatically. By combining an ensemble of circular regression
trees a more stable and regularized circular regression forest can be built
which allows for modeling smooth effects as well.

To evaluate the proposed circular regression trees and forests, a case
study on
probabilistic forecasting of wind direction for two airports in Austria is
presented. In addition to the tree-based models, alternative common
approaches
are used as a benchmark in order to assess the predictive performances of
circular regression trees and forests.
%Establishing a proper regression model for circular data such as animal movement
%directions, periodic measurements of neuronal activity or wind directions,
%requires specific attention regarding its representation on the unit circle.
%Commonly applied generalized linear and additive models can provide a useful toolbox, 
%however, highly non-linear link functions can complicate interpretations while
%a non-concave log-likelihood function of the usually employed von Mises distribution 
%leads to difficulties in the incorporated optimization procedure.
%Moreover, an adequate model specification can be very challenging and non-additive 
%effects might not be detected.

%Therefore, an alternative approach to modeling circular data is proposed by
%employing the von Mises distribution within the methodology of distributional 
%trees and forests. Exploiting the tree-based separation of the data set into 
%subgroups an intercept-model is fitted within each subset such that no covariates 
%are included simplifying ....
%difficulties may arise in 
%modeling smooth effects due to highly non-linear link 
%functions and increasing irregularities when moving closer to the ``origin point'' 
%(0 which is equal to $2\pi$ in the radiant case).
%%% FIXME: clear explanation of difficulties
%Therefore, we propose a new approach by applying distributional trees and 
%forests to circular data. In particular, the parameters of the employed von Mises 
%distribution are regressed on covariates by a tree-based model yielding a constant set 
%of estimated distribution parameters for each resulting subgroup, regardless of any 
%``circular shift''/the ``circular position''.
%As circular data appears in many different areas, the development of
%appropriate statistical models which can account for periodicity has become an
%important but challenging research field. For probabilistic modeling of
%circular data typically the von Mises distribution is employed. In order to
%regress its parameters on covariates, a circular regression tree is
%proposed as an alternative to more commonly-used generalized linear and additive 
%models. 
%Moreover, the resulting circular regression trees are easy to interpret, 
%can detect non-additive effects, and select covariates and their interactions automatically. 
%By combining an ensemble of circular regression trees a more stable and regularized circular
%regression forest can be built which allows for modeling smooth effects as
%well.

%To evaluate the proposed circular regression trees and forests, a case study on
%probabilistic forecasting of wind direction for two airports in Austria is
%presented. In addition to the tree-based models, alternative common approaches
%are used as a benchmark in order to assess the predictive performances of
%circular regression trees and forests. 
}
\Keywords{Distributional Trees, Random Forests; Circular Data; von Mises Distribution}

\Address{
  Moritz N. Lang, Lisa Schlosser, Reto Stauffer, Achim Zeileis \\
  Universit\"at Innsbruck \\
  Department of Statistics \\
  Faculty of Economics and Statistics \\
  Universit\"atsstr.~15 \\
  6020 Innsbruck, Austria \\
  E-mail: \email{Moritz.Lang@uibk.ac.at}, \email{Lisa.Schlosser@uibk.ac.at},\\
  \email{Reto.Stauffer@uibk.ac.at},\email{Achim.Zeileis@R-project.org} \\
  URL: \url{https://www.uibk.ac.at/statistics/personal/moritz-lang/},\\
  \phantom{URL: }\url{https://www.uibk.ac.at/statistics/personal/schlosser-lisa/},\\
  \phantom{URL: }\url{https://retostauffer.org/},\\
  \phantom{URL: }\url{https://eeecon.uibk.ac.at/~zeileis/}\\

  Georg~J.~Mayr\\
  Universit\"at Innsbruck \\
  Department of Atmospheric and Cryospheric Science \\
  Faculty of Geo- and Atmospheric Sciences \\
  Innrain~52f \\
  6020 Innsbruck, Austria \\
  E-mail: \email{Georg.Mayr@uibk.ac.at} \\
  URL: \url{http://acinn.uibk.ac.at/persons/georg_mayr}\\
  
  Torsten Hothorn\\
  Universit\"at Z\"urich \\
  Institut f\"ur Epidemiologie, Biostatistik und Pr\"avention \\
  Hirschengraben 84\\
  CH-8001 Z\"urich, Switzerland \\
  E-mail: \email{Torsten.Hothorn@R-project.org}\\
  URL: \url{http://user.math.uzh.ch/hothorn/}\\
  
}

% -------------------------------------------------------------------
% Introduction
% -------------------------------------------------------------------
\begin{document}
\section{Introduction}
\label{sec:introduction}
Circular data can be found in a variety of applications and subject areas,
e.g., hourly crime rate in the social-economics, animal movement direction or
gene-structure in biology, and wind direction as one of the most important
weather variables in meteorology. Fitting a statistical model to this type of
data requires the incorporation of its specific feature of periodicity, i.e.,
in case of angular data the fact that values are restricted to an interval such
as $[0,2\pi)$ with $0$ being equivalent to $2\pi$.

In many approaches to model circular data it is assumed that the circular
variable of interest follows a circular distribution, in particular the von
Mises distribution which is also known as the ``circular normal distribution''.
%This is also the basis
%which early regression models for circular data are built on as they regress
%the parameter(s) of the von Mises distribution on covariates. 
One of the first
regression models with a circular response variable and linear covariates was
presented by \cite{Gould:1969} where the circular mean, i.e., the location
parameter of the von Mises distribution is predicted by a linear combination of
covariates. 
\cite{Johnson+Wehrly:1978} refined this idea by
plugging in a link function transforming the linear predictor to a 
restricted interval of length $2\pi$. 
%%%
%%%In order to restrict the circular response to an interval of length $2\,pi\
%%%\cite{Johnson+Wehrly:1978} refined this idea by linintroducing link functions transforming
%%%the linear predictor to the restricted interval of length $2\pi$. 
%\cite{Johnson+Wehrly:1978} took this idea one step further by
%plugging in a link function such that the values of the linear predictor are
%transformed to a restricted interval of length $2\pi$. 
%This generalized linear
%model (GLM)-type approach was further extended by \cite{Fisher+Lee:1992} and
%subsequently by \cite{Fisher:1993} introducing another specific transformation
%function which maps the values of the real line to the unit circle. 
This generalized linear
model (GLM)-type approach was further extended by \cite{Fisher+Lee:1992} and
subsequently by \cite{Fisher:1993} introducing independent GLMs for either the 
location or scale parameter with appropriate link functions while keeping the other 
parameter constant. Additionally, they developed a combined heteroscedastic version 
where the location and scale parameter are alternately reestimated conditional on 
respective sets of covariates until convergence.
%Moreover, the presented methodology does not only allow for the mean direction to be modeled 
%depending on covariates while a constant estimate is obtained for the concentration parameter 
%but also for the vice versa version. For each of these two approaches a separate model is introduced, 
%however, they are also combined in a joint model (referred to as ``mixed model'').
%%Moreover, the presented methodology allows for both distribution parameters, the mean
%%direction and the concentration parameter of the von Mises distribution, to be
%%modeled depending on covariates, not only separately but also in a
%%combined model (also referred to ``mixed model''). 
%In the employed iterative optimization algorithm the two sets of regression coefficients used
%to model $\mu$ and $\sigma$ respectively are updated in alternation until convergence.
%%To obtain proper initial values it is recommended to apply two separate models 
%%where either one of the parameters is fixed while the other is predicted employing covariates 
%%in a GLM-type model.
%While the combined model but also the two separate models are built on well elaborated theory 
While all of these models are built on well elaborated theory 
the employed methodology has shown to be very challenging in its application, mainly due to the 
complexity encountered in optimizing the corresponding log-likelihood function which is not globally concave. 
Therefore, highly informative starting values are crucial for these circular GLMs to converge at all 
\citep{Pewsey+Neuhaeuser+Ruxton:2013, Gill+Hangartner:2010}. 
In order to avoid this strong dependence on appropriate initial values, \cite{Mulder+Klugkist:2017} 
have presented a Bayesian alternative of a homoscedastic GLM for circular data.
However, apart from potential difficulties in the optimization procedure of circular GLMs, 
additive effects and their interpretation are often not intuitive for circular responses
due to the highly non-linear link function and the representation of smooth transitions 
on the unit circle is not straightforward. For example, the same rotation can be obtained in either 
positive or negative direction on the circle leading to an ambiguous interpretation.

%%%All listed methods and most of their further developments \citep[see, e.g.,][]{Jammalamadaka+Sengupta:2001} 
%%%are built on additive regression models.
%%%Generally these provide a powerful toolbox for modeling particularly smooth effects.
%%%however, in the case of modeling circular data 
%%%additive effects conditional on linear covariates are not intuitive
%%%due to a possibly strongly non-linear rotation on the unit circle, whereby the same transformation
%%%can be obtained in either positive or negative direction on the circle.
%a possibly highly non-linear link function
%can induce a more complex behavior of the modeled parameters as the location
%parameter shifts closely towards the ``origin point'' $0$, also depending on the 
%direction of the shift.

As a very intuitive and data-driven alternative, we propose a flexible
tree-based regression approach for modeling circular data by applying the von
Mises distribution within the methodology of distributional trees and
distributional forests \citep{Schlosser+Hothorn+Stauffer:2019}. 
%In order to avoid these difficulties in regression modeling of circular data 
%(and also the requirement of initial values) 
%we propose an alternative and very flexible 
%approach by applying the von Mises distribution within the methodology of distributional 
%trees and distributional forests \citep{Schlosser+Hothorn+Stauffer:2019}. 
The resulting circular regression trees and forests avoid the discussed difficulties 
of circular GLMs by separating the data into more homogeneous subgroups and fitting a 
simple intercept-only model for each resulting subset.
Therefore, no covariates and, thus, no link function must be employed in the estimation
of the group-specific distribution parameters which also simplifies the optimization process.
By incorporating the framework of distributional modeling, we allow for detecting 
splits in all distribution parameters and provide a fully specified circular response distribution 
for each terminal node offering a wide range of inference.
In addition, the employed tree structure captures non-additive effects while forests allow for 
modeling smooth changes as well.
Furthermore, covariates and their possible interactions do not need to be specified in advance as 
they are selected automatically.

%Moreover, non-additive effects are captured by the tree structure while forests allow for 
%modeling smooth changes as well. Thus, a high level of flexibility is provided while a full 
%distributional model is specified in each terminal node offering a wide range of inference. 

%The resulting circular regression trees and forests do not require a pre-specified link function 
%or any other model assumptions as covariates and their possible interactions are
%selected automatically. 

%Moreover, as covariates are employed for splitting only and not
%considered for the parameter estimation within the resulting subgroups, their effects are easier to be interpreted for circular responses.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
This novel approach to circular regression trees and forests complements the literature 
on tree-based circular modeling.
%In particular, 
\cite{Lund:2002} has already introduced the concept of circular regression trees where 
binary splits are made based on an angular distance measure employed to evaluate node 
homogeneity.
While this approach and also further extensions \citep{Larraondo+Inza+Lozano:2018} allow not 
only for linear but also for a circular covariate, the tree only considers effects in the mean 
direction for splitting, i.e., only the location parameter $\mu$ is regressed on covariates.
Therefore, the introduced distributional approach to circular regression trees extends the concept
of previous circular trees by considering splits in all distribution parameters and 
yielding a full probabilistic model. In addition, as a natural further development, ensembles or forests 
of circular regression trees are presented in this study. 
% that can improve forecasts by regularizing and stabilizing the model.

%which is evaluated between 
%the observed response values and the conditional mean direction of the circular response variable
%and in that way serves as a measure of homogeneity within subgroups. 
%%For a circular response $\theta$, covariate(s) $z$ and the conditional mean direction $\mu(z)$
%%the employed circular distance is defined by $1-\cos(\theta - \mu(z)$.
%%In each terminal node a predicted values is provided by the sample mean direction of the corresponding 
%%subset of observations.
%Furthermore, even though an estimate of dispersion in the form of total node heterogeneity is provided 
%along with the predicted mean value in each terminal node
%By incorporating the framework of distributional modeling, we extend the idea of circular trees allowing splits in all distribution parameters and providing a fully specified circular response distribution for each terminal node. 

%Hence, the here proposed circular regression trees and forests can be seen as a further step in the development
%of tree-based circular models by incorporating the framework of distributional modeling and in that way
%considering splits in all distribution parameters and providing a fully specified distribution fitted 
%in each terminal node.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%An alternative modeling approach that can deal with non-additive effects is
%provided by tree-based methods. \cite{Lund:2002} introduced the concept of
%circular regression trees which was further extended by
%\cite{Larraondo+Inza+Lozano:2018}. Following this idea of employing tree-based
%methods but also including the probabilistic concept of regressing distribution
%parameters on covariates, we propose a very flexible approach by applying the
%von Mises distribution within the methodology of distributional trees and
%distributional forests \citep{Schlosser+Hothorn+Stauffer:2019} to circular
%data. The resulting circular distributional trees and forests do not require
%any model assumptions as covariates and their possible interactions are
%selected automatically. Non-additive effects are captured by the tree structure
%while circular forests allow for modeling smooth changes as well. Thus, a high
%level of flexibility is provided while a full distributional model is specified
%offering a wide range of inference.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection*{Motivating example}
To provide a first impression of the presented methodology a circular regression 
tree is employed to probabilistic wind direction forecasting. Wind direction is a 
classical circular quantity and accurate forecasts are of great importance for
decision-making processes especially in air traffic management.
Figure~\ref{fig:tree_ibk} shows an estimated tree for 1-hourly forecasts at the
airport of Innsbruck which lies at the bottom of a deep valley in the Alps.
Topography channels wind along the west-east valley axis or along a tributary
valley intersecting from the south. Hence, pressure gradients to which valley
wind regimes react are considered as covariates along with other meteorological
measurements at the airport (lagged by one hour), such as wind direction and
wind speed at the airport.
%%
\begin{figure}[p!]
  \centering
  \includegraphics[width=0.95\textheight,,angle=90,origin=c]{_plot_circforest_finalexampletree_ibk_lag1_v14.pdf}
  \caption{Fitted tree based on the von Mises distribution for 1-hourly wind
  direction forecasts at the airport of Innsbruck. In each terminal node the
  empirical histogram (gray) and fitted density (red line) are depicted along
  with the estimated location parameter (red hand). The covariates employed are
  wind direction (degree), wind speed ($\text{ms}^{-1}$), and pressure gradients
  ($\text{dpressure; hPa}$) west, east and south of the airport, all lagged by
  one hour.}
  \label{fig:tree_ibk} 
\end{figure}
%%
Together with the tree structure itself, Figure~\ref{fig:tree_ibk} depicts the
empirical (gray) and fitted von Mises (red) distribution of wind direction in
each terminal node. Based on the fitted location parameters $\hat \mu$, the
subgroups can be distinguished into the following wind regimes: (1)~Up-valley
winds blowing from the valley mouth towards the upper valley (from east to
west, nodes~4 and 5). (2) Downslope winds blowing across the Alpine crest
along the intersecting valley towards Innsbruck (from south-east to north-west,
node~8). (3) Down-valley winds blowing in the direction of the valley mouth
(from west to east, nodes 10, 12 and 13). Node~7 captures observations with
rather low wind speeds that cannot be distinguished clearly into wind regimes
and consequently are associated with a very low estimated concentration $\hat
\kappa$. In terms of covariates, the lagged wind direction (``persistence'') is
mostly responsible for distinguishing the broad wind regimes listed above while
the pressure gradients and wind speed separate between subgroups with high vs.\
low precision. Note that in the meteorological context wind direction 
is defined on the scale $[0,360]$ degree and increases clockwise from North ($0$ degree).

A more extensive case study of circular regression trees and forests
applied to probabilistic forecasting of wind direction at the airports of
Innsbruck and Vienna will be presented in this paper. Moreover, their
performances are benchmarked to alternative commonly used approaches. The
remainder of the paper is structured as follows: The theory on probabilistic
circular modeling introducing the von Mises distribution will be discussed in
Section~\ref{sec:prob_circ}. The methodology of circular regression trees
and forests and their features are introduced in Section~\ref{sec:tree_forest}.
After the case study presented in \ref{sec:wind}, a comprehensive summary and
conclusion is given in Section~\ref{sec:summary}.

% -------------------------------------------------------------------
% Probabilistic circular modeling
% -------------------------------------------------------------------
%\newpage
\section{Probabilistic circular modeling}
\label{sec:prob_circ}
Probabilistic modeling of circular data requires the selection of a proper
circular probability distribution, i.e., a probability distribution which
accounts for the periodicity of circular data. Generally, this feature can be
obtained by ``wrapping'' the probability density function of any continuous
distribution around the unit circle \citep{Mardia+Jupp:2009}. In that way, the
wrapped Cauchy distribution or the wrapped normal distribution can be employed
to model symmetric unimodal circular data. A close approximation to the wrapped
normal distribution that is mathematically simpler and hence easier to use
\citep{Fisher:1993} is provided by the von Mises distribution, a purely
circular distribution which is also known as ``the circular normal
distribution'' and commonly applied for probabilistic modeling of circular
data. Based on a location parameter $\mu \in (-\pi, \pi]$ and a concentration
parameter $\kappa > 0$ the density of the von Mises distribution for an
observation $y \in (-\pi, \pi]$ is given by:
%%
\begin{equation}
  f_\mathrm{vM}(y; \mu, \kappa) = \frac{1}{2 \pi I_0(\kappa)}~e^{ \kappa \cos(y - \mu)}\label{schlosser:equ_vm}
\end{equation}
%%
where $I_0(\kappa)$ is the modified Bessel function of the first kind and order
$0$ \citep[see, e.g.,][for a more detailed
overview]{Jammalamadaka+Sengupta:2001}.

The corresponding log-likelihood function is defined by
%%
\begin{equation}
  \begin{aligned}
    \ell(\mu, \kappa; y) &= \log(f_\mathrm{vM}(y;\mu, \kappa)) \\
    &= -\log(2 \pi I_0(\kappa)) + \kappa \cos(y - \mu).\label{equ:vM:loglik}
  \end{aligned}
\end{equation}
%%

Once an appropriate distribution family is selected fitting a probabilistic
model corresponds to estimating the distribution parameters. Thus, when
applying the von Mises distribution to fit a probabilistic model $\text{vM}(Y;
\mu, \kappa)$ to a circular response variable $Y \in \mathcal{Y}$ the
distribution parameters $\mu$ and $\kappa$ are to be estimated. For a learning
sample with $n$ observations $\{y_i\}_{i=1,\ldots,n}$ this can be done by
maximizing the log-likelihood function $\ell(\mu, \kappa; y)$, hence
\begin{equation}\label{eq:optim} (\hat{\mu},\hat{\kappa}) =
\argmax_{\mu,\kappa} \sum_{i=1}^n \ell(\mu, \kappa; y_i) \end{equation}
yielding maximum likelihood estimators $\hat{\mu}$ and $\hat{\kappa}$ such that
a fully specified distributional model is fit to the learning data.

By means of the score function
%%
\begin{equation}
  \label{eq:scores}
  \begin{aligned}
    s(\mu, \kappa, y) &= \bigg(\frac{\partial \ell}{\partial \mu}(\mu,\kappa; y)
    \smallskip &,
    \quad & \frac{\partial \ell}{\partial \kappa}(\mu,\kappa; y) \bigg) 
    \\
    &= \bigg(\kappa \sin(y-\mu)
    \smallskip &,
    \quad &-\frac{I_1(\kappa)}{2\pi I_0(\kappa)}+\cos(y-\mu) \bigg)
  \end{aligned}
\end{equation}
%%
an indicator of deviation and in that way a measure of goodness of fit of the
model can be obtained for each observation and fitted parameter.
Moreover, the optimization problem in Equation~\ref{eq:optim} can also be
defined by 
%%
\begin{equation}
  \sum_{i = 1}^n s(\hat{\mu}, \hat{\kappa}, y_i) = 0.
\end{equation}
%%
%%
\begin{figure}[t]
  \begin{minipage}{.05\textwidth}
    \hfill
  \end{minipage}%
  \begin{minipage}{.45\textwidth}
    \vspace{-1em}
    \includegraphics[width=1.05\linewidth]{density_linear.pdf}
  \end{minipage}%
  \begin{minipage}{.45\textwidth}
    \includegraphics[width=1.2\linewidth]{density_circular.pdf}
  \end{minipage}
  \begin{minipage}{.05\textwidth}
    \hfill
  \end{minipage}%
  \caption{Illustration of a distributional model fitted to circular data by
    maximum likelihood estimation employing the von Mises distribution. Left
    panel: ``linear'' illustration restricted to the interval $[0, 2\pi)$. Right
    panel: circular illustration. In both panels the empirical histogram (gray)
    and fitted density (red line) are depicted along with the estimated location
    parameter (red hand).}
  \label{fig:densities} 
\end{figure}
%%

Figure~\ref{fig:densities} depicts a distributional model fitted to circular
data employing the von Mises distribution. While the left panel only serves as
an illustration of the corresponding ``linear'' description restricted to an
interval of length $2\pi$ but consequently not accounting for periodicity, the
right panel displays an appropriate representation of a circular quantity on
the unit circle. Looking at the fitted density (red line) and estimated
location parameter (red hand) this example shows that reasonably well fitting
probabilistic models can be established for circular data by specifying an
appropriate distribution family such as the von Mises distribution and
estimating its parameters via maximum likelihood. However, this procedure
considers only the response variable. Including covariates can improve any
model remarkably as they might provide valuable additional information.
Therefore, (distributional) regression models are of high interest for all types
of data, including circular data.

In most generalized linear or additive approaches to circular regression modeling 
the location parameter $\mu$ is regressed on covariates $\mathbf{z}$ in the form of 
%models employ linear combinations of the covariates to connect them to distribution 
%parameters. By plugging in a link function $g$ 
\begin{equation}
\mu = \mu_0 + g\left(\mathbf{\beta}^{\top} \mathbf{z}\right),
\end{equation}
with a circular intercept $\mu_0$ and a coefficient vector $\mathbf{\beta}$; whereby the 
additive predictor is transformed to an interval of length $2\pi$  by a link function $g$. 
As an appropriate link function typically $g(x) = 2 \cdot arctan(x)$ is employed, 
as suggested by \citet{Fisher+Lee:1992}.
While most of the proposed models estimate a constant concentration parameter, hence, assume
homoscedasticity, \citet{Fisher+Lee:1992} also developed a heteroscedastic version by combining two  
individual GLMs, each for one of the parameters $\mu$ and $\kappa$. 
This provides a first approach to a fully probabilistic regression model for circular 
data, however, the parameters are not regressed simultaneously on covariates as known from the 
more general framework provided by generalized additive models for location, scale, and shape 
\citep[GAMLSS, ][]{Rigby+Stasinopoulos:2005}. 
However, all circular additive models incorporate the previously discussed difficulties induced by
the characteristics of the log-likelihood function and the strongly non-linear link function.
%For example, \cite{Johnson+Wehrly:1978} guarantee for the link function to return values
%on an interval of length $2\pi$ by setting 
%$g(x) = 2\pi \cdot F(x)$ 
%for a cumulative distribution function $F$ while \cite{Fisher+Lee:1992} suggest to use
%$g(x) = 2 \cdot arctan(|x|^{\lambda} \cdot sgn(x))$. 
%Most of these approaches assume homogeneity, thus, the concentration parameter $\kappa$ is estimated 
%as a constant. However, \cite{Fisher+Lee:1992} also present a model where $\kappa$ is regressed on 
%covariates employing the exponential function as a link function while $\mu$ is assumed to be a 
%constant value. Additionally to these two model variations where only one of the two distribution 
%parameters depends on covariates a combination of them is introduced. In this joint model the 
%two sets of regression coefficients employed to model $\mu$ or $\kappa$ respectively are reestimated 
%in alternation within an iterative optimization algorithm. 
%Hence, the presented theory provides a first approach to probabilistic regression modeling of circular 
%data, even though, the parameters are not regressed simultaneously on covariates as for example in a 
%more general case by generalized additive models for location, scale, and shape 
%\citep[GAMLSS, ][]{Rigby+Stasinopoulos:2005}.
%However, in practice the incorporated optimization procedure has shown to be very complex, already
%for only one parameter being regressed on covariates and consequently even more so in the joint model.
%This is primarily due to characteristics of the log-likelihood function of the employed von Mises 
%distribution with the plugged-in link function. In particular, the function is not globally concave and
%possibly very sharp local maxima can prevent the algorithm from converging towards the true parameters.
%Furthermore, representing smooth effects on the unit circle and interpreting the corresponding coefficients
%is not straightforward, mainly owing to possibly highly nonlinear link functions. In particular, changing 
%covariates can induce rotations, however, potentially in both directions and in certain cases yielding a 
%compression of the estimated density function.
%\newline
Referring to additive models in general, it has to be considered that a proper model specification 
can be very challenging, particularly for a high number of covariates and no information on possible 
interactions. Moreover, the additive structure might impose a smooth effect even if the true underlying 
effect is an abrupt shift.

An alternative to additive models, which can deal or even 
avoid the mentioned difficulties in circular regression modeling, is to employ tree-based models. 
For the particular case of circular data, the methodology of circular regression trees and forests is
presented in the following section.



% -------------------------------------------------------------------
% Circular regression trees and forests
% -------------------------------------------------------------------
\section{Circular regression trees and forests}
\label{sec:tree_forest}

The main goal of employing tree-based models to circular data is to provide a flexible and 
easy-to-apply modeling approach which accounts for a proper representation on the unit circle.
Based on ideas of \citet{Lund:2002}, we introduce probabilistic circular regression trees and forests
employing the von Mises distribution. The resulting tree-based models provide a very intuitive and data-driven 
alternative to commonly used regression models for circular data.


%A very flexible framework should allow for detecting a wide range of 
%effects, from abrupt changes to smooth transitions, while for the latter difficulties related
%to a circular representation should be avoided as well as any dependence on initial values.
%\cite{Lund:2002} introduced the concept of circular regression trees where a circular response 
%variable is regressed on linear as well as a circular covariate. For the crucial decision on how 
%and where to split the data an angular distance measure is evaluated between the mean direction 
%and each observation in a resulting subgroup in order to assess homogeneity within this subgroup. 
%Hence, only the location parameter is considered for splitting such that effects in other parameters 
%might be missed. Therefore, we introduce a distributional approach to circular regression trees 
%where a fully specified distributional model is fitted in each node of the tree which enables the 
%detecting of splits in all parameters. Moreover, not only predictions of the expected value but also 
%corresponding confidence intervals, thresholds and quantiles can be obtained among many other information
%quantities.
%Additionally, possible difficulties induced by circular rotations are avoided as the distributional model
%within each node is fitted without employing covariates.
%A common way of including covariates is to regress the model parameters on
%covariates. In the case of a probabilistic model for a circular response this
%corresponds to expressing the location parameter $\mu$ and the concentration
%parameter $\kappa$ of the von Mises distribution by means of the available
%covariates, e.g., in the form of a linear combination, possibly with an
%appropriate link function plugged in as in GLMs. This kind of approach is
%presented for example in the mixed model of \cite{Fisher+Lee:1992} and
%\cite{Fisher:1993}. Apart from the methodology developed specifically for
%circular data more general approaches to regressing model parameters on
%covariates are commonly used such as for example generalized additive models
%for location, scale, and shape \citep[GAMLSS, ][]{Rigby+Stasinopoulos:2005}
%where each distribution parameter is estimated by its own generalized additive
%model (GAM). However, difficulties might arise in case of non-additive changes
%and a proper model specification can be very challenging, particularly for a
%high number of covariates and no information on possible interactions. As an
%alternative regression approach which can deal with these problems, we
%introduce a circular probabilistic tree-structured model in this section.

\subsection{Circular regression trees}
\label{sec:circtree}
Fitting a global model to a full data set can be very challenging, particularly
for complex data with strong variations. Therefore, separating the data set
into more homogeneous subgroups based on covariates before fitting a local
model in each of these subgroups allows to capture (possibly) group specific
effects more precisely and hence can result in an overall better fitting model.
This is the general idea of regression trees which are combined with
distributional modeling in \cite{Schlosser+Hothorn+Stauffer:2019} based on the
unbiased recursive partitioning algorithms MOB
\citep{Zeileis+Hothorn+Hornik:2008} or CTree
\citep{Hothorn+Hornik+Zeileis:2006}. By applying the presented distributional
trees, a full distributional model is specified in each node of the tree for a
specific distribution family chosen in advance. Hence, selecting the von Mises
distribution allows for an application of distributional trees to circular data
following the tree building algorithm as introduced in Section~2.2. of
\cite{Schlosser+Hothorn+Stauffer:2019}. 

In the applied tree-building algorithm, in each node the crucial decision on
how and where to split the data is based on model scores which are obtained by
evaluating the score function $s$ for the individual observations and parameter
estimates (Equation~\ref{eq:scores}). For the von Mises distribution with its
two distribution parameters and a data set of $n$ observations, this yields an
$n \times 2$ matrix that can be employed as a discrepancy measure, capturing
how well each given observation conforms with the estimated location
$\hat{\mu}$ and precision $\hat{\kappa}$, respectively. To capture dependence
on covariates, the association between the model's scores and each available
covariate is assessed using either a parameter instability test~(MOB) or a
permutation test~(CTree). By doing so in each partitioning step, the covariate
with the highest significant association (i.e., lowest significant $p$-value,
if any) is selected for splitting the data. The corresponding split point is
chosen either by optimizing the log-likelihood~(MOB) or a two-sample test
statistic~(CTree) over all possible partitions. This procedure is repeated
recursively until there are no significant parameter instabilities or until
another stopping criterion is met (e.g., subgroup size or tree depth).
A more detailed description of the applied tree-building algorithm
can be found in Appendix~\ref{app:algorithm}.

Once a distributional tree model is fitted it can be employed to obtain
probabilistic predictions for a possibly new set of observed covariates $\bm{z}
= (z_1, \ldots, z_m)$. Starting at the root node the tree structure leads the
observation to a terminal node, depending on the values of the covariates,
where the parameter pair $(\hat{\mu}, \hat{\kappa})$ is estimated for the
corresponding subset of learning observations. This can also be expressed by
employing weights which indicate whether the $i$-th learning observation and
the observation $\bm{z}$ belong to the same terminal node: \begin{equation}
w^{\text{tree}}_i(\bm{z}) = \sum_{b=1}^B \mathbf{1}((\bm{z}_i \in
\mathcal{B}_b) \land (\bm{z} \in \mathcal{B}_b)), \end{equation} where
$\mathbf{1}(\cdot)$ is the indicator function and $\mathcal{B}_b$ is the $b$-th
out of $B$ segments partitioning the covariate space in disjoint subsets. In
that way the estimated parameter pair $(\hat{\mu},\hat{\kappa})(\bm{z})$
specifying the predicted von Mises distribution for a given $\bm{z}$ is
obtained by 
%%
\begin{equation} 
  (\hat{\mu},\hat{\kappa})(\bm{z}) =
  \argmax_{\mu,\kappa} \sum_{i=1}^n w^{\text{tree}}_i(\bm{z}) \cdot
  \ell(\mu,\kappa; y_i).
\end{equation}
%%
Therefore, the same parameter pair is estimated for all observations belonging
to the same terminal node. This facilitates the application as the parameter
estimates do not need to be recalculated for each (new) observation via maximum
likelihood but can be extracted directly from the learning sample and the
fitted model.

While tree models can capture non-additive effects their structure and the
consequential strict separation of data into subgroups hinders an adequate
depiction of smooth effects. Therefore, they might impose abrupt changes even
in case of rather smooth transitions. This can be avoided by combining an
ensemble of trees in order to obtain a more stable forest model. 


\subsection{Circular regression forests}
\label{sec:circforest} 
A natural extension of circular regression trees are ensembles or forests
that can improve forecasts by regularizing and stabilizing the model. Random
forests introduced by \cite{Breiman:2001} average the predictions of an
ensemble of trees, each built on a subsample or bootstrap of the original data.
A generalization of this strategy is to obtain weighted predictions by adaptive
local likelihood estimation of the distributional parameters
\citep[Section~2.3. of][]{Schlosser+Hothorn+Stauffer:2019,
Hothorn+Zeileis:2017}. More specifically, for each possibly new
observation~$\bm{z}$ a set of averaged ``nearest neighbor'' weights
$w_i^{forest}(\bm{z})$ is obtained that is based on the number of trees in
which $\bm{z}$ is assigned to the same terminal node as each learning
observation $y_i, i \in \{1,\ldots,n\}$. Hence, for a forest of $T$ trees the
weights are calculated via
%%
\begin{equation}
  w^{\text{forest}}_i(\bm{z}) = \frac{1}{T} \sum_{t=1}^T \sum_{b=1}^{B^t}
  \frac{\mathbf{1}((\bm{z}_i \in \mathcal{B}^t_b) \land (\bm{z} \in \mathcal{B}^t_b))}{|\mathcal{B}^t_b|},
\end{equation}
%%
where $|\mathcal{B}^t_b|$ denotes the number of observations in the $b$-th
segment of the $t$-th tree. Therefore, similar observations ending up more
often in the same terminal node have higher weights and in that way a stronger
influence in the estimation process.

In that way a specific set of weights can be calculated for each observation
yielding its specific parameter estimates for the von Mises distribution
%%
\begin{equation}
  (\hat{\mu},\hat{\kappa})(\bm{z}) = \operatorname{argmax}\displaylimits_{\mu,
  \kappa} \sum_{i=1}^n w_i^{forest}(z) \cdot \ell(\mu, \kappa; y_i). 
\end{equation}
%%

Therefore, the resulting parameter estimates can smoothly adapt to the given
covariates $\bm{z}$ whereas $w_i^{forest}(\bm{z}) = 1$ would correspond to the
unweighted full-sample estimates and $w_i^{forest}(\bm{z}) \in \{0, 1\}$
corresponds to the abrupt splits from a tree. Thus, circular regression
forests can capture both smooth and abrupt changes, while covariates and
possible interactions are selected automatically allowing for an easy-to-apply
methodology with a full specification of the von Mises distribution.


% -------------------------------------------------------------------
% Case study
% -------------------------------------------------------------------
\section{Case study: Probabilistic wind direction forecasting}
\label{sec:wind}
Accurate forecasts of wind directions are of great importance for risk
management in various fields such as agriculture, energy production or air
safety control. For example, in order to direct airplanes to a safe landing,
precise knowledge of wind direction for the next hour(s) at the respective
airport is highly desirable and adequate prediction methods are required. In
this section, a comprehensive case study on probabilistic wind direction
forecasting is provided for two airports in Austria with fundamentally
different site characteristics: Innsbruck with a rather unusual location for an
airport, located at the bottom of a deep Alpine valley, and Vienna located
within flat terrain in the East of Austria. In addition to the newly introduced
circular regression trees and forests, the case study employs various
alternative approaches to forecast wind direction as a benchmark. The study is
based on $1$\,h and $3$\,h forecasts employing lagged observations in the
vicinity of the airports as predictor variables. 

\subsection{Data}
\label{sec:wind:data}
The circular response variable considered in this case study is a $10$\,min
mean of wind direction measurements at the airports Innsbruck and Vienna on an
hourly temporal resolution. As predictor variables, we use $1$-hourly resolved
$10$\,min mean observations of various meteorological quantities such as wind
direction, wind speed, temperature, air pressure and humidity, all lagged by
one or three hours according to the respective forecasting step. The
meteorological variables are measured either directly at the airports or within
their vicinities. For Innsbruck, measurements at the airport and along the
intersecting valleys are used, whereas, for Vienna, measurements at the airport
and within an area of about XXX\,km$^2$ are used. A topographical overview of
the airports and their surrounding areas with the station sites employed in
this study is provided in Figure~XXX. In addition, we use derived quantities
such as 3-hourly means, minima and maxima, as well as 1-and 3-hourly temporal
changes and spatial differences towards the airport of the respective
quantities. An overview of the employed data sets can be found in
Table~\ref{tab:data}. 

The data used in this study consists of five total years from January 2015 to
December 2018. After first eliminating predictor variables with more than 5\%
missing values and then time points with missing observations, the data set
consists of 41979 time points and 260 covariates for Innsbruck, and of 38985
times points and 494 covariates for Vienna, respectively.

%%
\begin{table}[t!]
  \caption[Table caption text]{Overview of the data sets employed in the case
    study: For Innsbruck and Vienna, various meteorological variables and derived
    quantities of these are considered at the respective stations, located either
    directly at the airports or in their vicinities.}
  \label{tab:data}
  \begin{center}
    \begin{tabular}{l  l}
      \hline
      Data components               & Description \\
      \hline
      Meteorological variables:     & Wind direction, wind (gust) speed, \\
                                    & (reduced) air pressure, relative humidity, \\
                                    & temperature\\ 
      \noalign{\vskip 1mm}                           
      Derived quantities:           & 3-hourly means/minima/maxima, \\
                                    & 1-hourly and 3-hourly temporal changes, \\
                                    & spatial differences towards the airport\\
      \noalign{\vskip 1mm}                              
      Weather stations (Innsbruck): & 4 stations at the airport, \\
                                    & Igls, Kematen, Kufstein, Landeck, Patscherkofel, \\
                                    & Steinach\\
      \noalign{\vskip 1mm}
      Weather stations (Vienna):    & 9 stations at the airport, \\
                                    & Arsenal, Donaufeld, Exelberg, G\"anserndorf, \\
                                    & Gro{\ss}-Enzersdorf, Gumpoldskirchen, Hohe Warte,\\
                                    & Innere Stadt, Jubil\"aumswarte, Mariabrunn, \\
                                    & Seibersdorf, Unterlaa, Wolkersdorf\\
      \hline
    \end{tabular}
  \end{center}
\end{table}
%%

\subsection{Models and evaluation}
\label{sec:wind:models}
For a fair evaluation of circular regression trees and forests, and to
investigate whether they can be applied as a reasonable alternative to already
existing approaches, three additional statistical models are employed in this
study for probabilistic forecasting of wind directions. Two of them are based
on existing approaches in the meteorological field, while the third is a
state-of-the-art model to forecast circular response variables. The next
paragraphs introduce the reference methods and provide the corresponding model
specifications used in this study for all considered models including the
circular regression tree and forest. 

\begin{itemize}
  \item \emph{Climatological model:} 
    Accurate knowledge of weather quantities' climatologies can be important for a
    wide range of applications and climatologies are often also used as a baseline for the
    validation of newly developed forecasting systems
    \citep{Simon+Umlauf+Zeileis:2017, Stauffer+Mayr+Messner:2017}. Usually, the performance of
    climatological models strongly depends on the temporal dependency of the
    quantity itself, either on a daily or yearly basis. Wind direction at a single
    location is often quite unstable and shows only a daily or annual seasonality
    in case of predominant local wind systems like the ones at Innsbruck introduced
    for the analysis of Figure~\ref{fig:tree_ibk}. Hence, the climatological model
    in this study provides a very simple implementation of a baseline model, which
    might experience serious performance losses in case of random temporal
    variabilities or abrupt changes in the employed response variable wind
    direction.
    \newline
    For simplicity, rather to fit one single climatological model, we perform the
    model fitting separately rolling over all time points. For each time point, the
    training data set consists of the same daytime as the time of interest within
    31~days centered around the same calender day over all years except the year of
    interest. To gain full probabilistic climatological forecasts, we employ the
    steps described in Section~\ref{sec:prob_circ} and fit the distribution
    parameters of the von Mises distribution via maximum likelihood estimation. The
    construction of a climatological reference model was similarly pursued by
    \citet{Vogel+Knippertz+Fink:2018} and is discussed in a comprehensive summary on
    different time-adaptive training schemes in \citet{Lang+Lerch+Mayr:2019}.
    %%
  \item \emph{Persistency model:}
    Persistence describes the previous value of a single weather quantity in a time
    series. Hence, it is another objective measure in the verification of weather
    forecasts and also often applied as a reference model
    \citep{noaasnationalweatherservice:2019}. For short forecast steps under stable
    atmospheric conditions, persistence can be a very good estimate, but as soon as
    any major change takes place in the response variable during the forecast
    period, forecasts based on persistence may also fail remarkably. Therefore, it
    heavily depends on the variability of the variable of interest and the length
    of the forecasting step whether persistence can provide overall reliable
    predictions.
    \newline
    To gain a full probabilistic persistency model, we proceed similarly as for the
    climatological model by using maximum likelihood estimation and fitting the
    distribution parameters of the von Mises distribution conditional on lagged
    response values according to the description in Section~\ref{sec:prob_circ}. We
    fit one model for every time point in the validation data set employing the
    previous six lagged response values as training data. In order to allow for a
    stronger influence of observations closer to the time of interest exponential
    smoothing is employed with a smoothing factor of $0.5$; accordingly, for every
    prediction the current observation and all previous five observations together
    have an equal influence rate of 50 percent. Observations with longer time lags
    have exponential weights below $0.01$ and are therefore omitted from the
    training data.
    %%
  \item \emph{Generalized linear model:}
    Traditional approaches to forecast circular response variables are often based
    on circular GLM-typed models \citep{Fisher:1993}. As discussed in
    Section~\ref{sec:introduction}, circular regression models often experience the
    problem that the likelihood function can be strongly irregular which makes
    optimization rather difficult. Hence, they often do not converge if no
    appropriate initial values are provided \citep{Pewsey+Neuhaeuser+Ruxton:2013,
    Gill+Hangartner:2010}. In this study, to be able to employ a GLM out of the box
    as a reference, we use the Bayesian implementation of
    \cite{Mulder+Klugkist:2017} which less depends on initial values due to an MCMC
    sampling algorithm using weakly informative priors.
    \newline
    Following \cite{Mulder+Klugkist:2017} the employed model plugs in an
    appropriate link function~$g$ in order to guarantee response values within an
    interval of length $2\pi$. As the implementation cannot handle circular covariates,
    we use the components of the lagged 2-dimensional wind vector $vec$ and the
    lagged wind speed $spd$ as predictor variables. The model formula for the
    location parameter $\mu$ of the von Mises distribution can be written as:
    %%
    \begin{align}
      \mu = \beta_0 + g(\beta_1 \cdot vec_{1} + \beta_2 \cdot vec_{2} + \beta_3 \cdot spd)
    \end{align}
    %%
    with $\beta_0$ being a circular intercept, $\beta_\bullet$ the regression
    coefficients and $g$ the link function $g(x) = 2 \cdot \arctan(x)$. In
    addition, a constant concentration parameter $\kappa$ is fitted to the full
    learning sample.
    %%
  \item \emph{Circular regression tree:}
    For the circular regression tree introduced in Section~\ref{sec:circtree},
    all covariates provided in the learning data can be considered due to an
    intrinsic automatic variable selection performed in the tree estimation. The
    tree building is performed by the newly developed R-package \pkg{circtree}
    employing the CTree algorithm \citep{Hothorn+Hornik+Zeileis:2006} with a
    minimal number of 2000 observations in each terminal node serving as a stopping
    criterion (argument \code{minbucket}).
    %%
  \item \emph{Circular regression forest:} Following the description in
    Section~\ref{sec:circforest}, a circular forest is constructed based on 100
    individual trees employing the R-package \pkg{circtree}. Each of these trees is
    again built by the CTree algorithm on a subsample containing a fraction of 30
    percent of the original learning data. As it can be expected that the lagged
    response variable is one of the most informative predictor variables for wind
    direction forecasting, all covariates are included for building each tree which
    ensures that the lagged response variable is always considered for splitting.
    This bagging approach can be applied in \pkg{circtree} by setting the argument
    \code{mtry} to the total number of covariates. Since a high number of possible
    split points leads to high computational costs, the covariates are binned in a
    maximum of $50$ classes (argument \code{nmax = c("yx" = Inf, "z" = 50)}).
    Contrary to a single-tree model, forests usually consist of very large trees as
    they are not prone to overfitting the data due to the stabilization obtained by
    combining the individual trees. Therefore, we use the following control
    arguments to build rather large trees: The minimal number of observations to
    perform a split is set to 20 (argument \texttt{minsplit}), the minimal number
    of observations in each terminal node is set to 7 (argument
    \texttt{minbucket}), and the significance level for variable selection is kept
    at its maximum value of $1$ (argument \texttt{alpha}).
\end{itemize}

To compare the predictive performances of all proposed models a circular
analogue of the continuous ranked probability score (CRPS) as introduced by
\cite{Grimit+Gneiting+Berrocal:2006} is computed. Just as the linear version of
the CRPS \citep[for more details see][]{Hersbach:2000} it is a proper scoring
rule \citep{Gneiting+Raftery:2007} and measures the difference between an
observation and the corresponding predicted distribution function in order to
assess the probabilistic goodness of fit for the estimated model. Hence, the
lower the CRPS value the better the predictive performance. Contrary to the
linear version, the circular CRPS reduces not to the absolute error but to the
angular distance when the forecast is deterministic.

In addition to the raw CRPS, also CRPS-based skill scores are computed to
assess differences in the improvement of the various statistical models over
the climatological model used as a reference:
%%
\begin{equation} 
  \text{CRPSS}_{\text{model}} = 1 -
  \frac{\text{CRPS}_{\text{model}}}{\text{CRPS}_{\text{climatology}}}.
\end{equation}
%%

All scores presented in the next section are computed out-of-sample based on
five years of observations. For the persistency model only time points prior to
the time of interest are used and the validation is performed rolling over all
observations. For all other models a five-fold cross-validation is employed
using up to four calendar years for model training and the remaining single
calendar year for validation. Due to the large sample size of 24 hourly values
per day over five years, some kind of temporal aggregation is needed to ensure
a correct visual comparison of the individual methods. Performed analyses have
shown that for the employed models the variability of the predictive
performance over the five years is lower than over a single day or over a
single year. Hence, CRPS and CRPS skill scores are aggregated over the
respective five validation years which yields 24 hourly scores per month
averaged over the five validation years.

\subsection{Results} 
This section provides a detailed analysis on the predictive performance of the
different proposed statistical models applied to probabilistic wind direction
forecasting. To ensure a comprehensive comparison of the models, wind direction
forecasts are evaluated for two different lead times at two airports with
different climatological site characteristics.
Figure~\ref{fig:boxplot_crpsraw} shows the CRPS values of the employed models
at forecast steps 1\,h and 3\,h for the airports Innsbruck (Panels~a,\,c) and
Vienna (Panels~b,\,d). The scores are aggregated over the five validation years,
yielding yearly mean values for every hour per calendar month, with a lower
score indicating better performance. For both stations at both forecast steps,
the circular forest overall provides the best predictive performance, followed
by the circular regression tree and, except for the $3$\,h forecast at
Innsbruck, the persistency model. In comparison to the circular regression tree and
forest, for both stations and forecast steps, the climatological model and the
linear model show clearly higher CRPS values and hence a lower predictive
performance.
%%
\begin{figure}[t]
  \centering
  \setkeys{Gin}{width=1.0\textwidth}
  \includegraphics{_plot_circforest_validation_crpsraw_agg_comparison_with_lowff_v14b.pdf}
  \caption{CRPS skill scores for wind direction forecasts based on the full
    predictive von~Mises distribution for $+1$ and $+3$\,h forecasts at the
    airports Innsbruck and Vienna. Each box-and-whisker contains $24$~hourly scores
    for each of the $12$~months averaged over the $5$~validation years which
    yields a total of $288$~yearly mean values. The scores are shown for the
    climatological, persistency and the linear model as well as for the circular
    distributional tree and forest.}
  \label{fig:boxplot_crpsraw} 
\end{figure}
%%
The different site characteristics of the airports Innsbruck
(Figure~\ref{fig:boxplot_crpsraw}\,a,\,c) and Vienna
(Figure~\ref{fig:boxplot_crpsraw}\,b,\,d) seem to have an effect on the
absolute level of the model performances and on their respective predictive
performance variances. At Innsbruck, due to the surrounding mountains a
limited number of possible wind directions exists, namely the three wind
regimes discussed for Figure~\ref{fig:tree_ibk} in
Section~\ref{sec:introduction}. Therefore, for Innsbruck the wind direction
remains rather constant in one of these possible states, but once a change
takes place it is mostly a major wind direction shift. Due to the few wind
regimes the rather inflexible climatological and linear models score relatively
well with similar CRPS values as the other models
(Figure~\ref{fig:boxplot_crpsraw}\,a,\,c). In addition, at Innsbruck the
potential high prediction errors in case of a paradigm shift seem to lead to a
higher variation in the predictive performance for all models in comparison to
Vienna; this variation is especially high for the persistency model due to its
strong vulnerability to abrupt wind shifts. On the contrary, at Vienna the
geographic surroundings do not constrain any wind direction which leads to
smaller and less abrupt changes in the wind direction as well as less
pronounced wind regimes. This seems to weaken the predictive performance of the
climatological and linear models, and to reduce the performance variability for
all models (Figure~\ref{fig:boxplot_crpsraw}\,b,\,d).

The different forecast steps have apparently only a minor effect on the
predictive performance of the climatological model and the linear model at both
stations. However, for the persistency model, at both stations, higher scores
for the $3$\,h forecast (Figure~\ref{fig:boxplot_crpsraw}\,c,\,d) reveal a
lower performance for longer lead times; this is probably due to the lower 
information content of minimum 3-hourly instead of 1-hourly lagged response 
values employed as covariates in the persistency model. 
The circular regression tree and forest seem to
partially compensate for the lower skill of the lagged response values by other
covariates, hence their predictive performance only slightly decreases for the
longer lead time. This compensation is especially evident for Innsbruck, where
the performance difference between the persistency model and the tree-based
methods significantly increases from the 1-hourly to the 3-hourly forecast.


In addition to the raw CRPS (Figure~\ref{fig:boxplot_crpsraw}), CRPS skill
scores with the climatological model as a reference are provided in
Figure~\ref{fig:boxplot_crpsskill}. Skill scores are in percent, and positive
values indicate an improvement in the predictive performance over the
reference. For all setups, the circular forest has the highest skill scores
with a mean performance gain of 13--25\% and 58--71\% for Innsbruck and Vienna,
respectively. As discussed for Figure~\ref{fig:boxplot_crpsraw}, this
improvement over the climatological model is lower for Innsbruck due to the low
number of predominant wind regimes and hence a relatively good performance of
the climatological model. Additionally, Figure~\ref{fig:boxplot_crpsskill}
shows that while the persistency model's performance is lower than the
reference (Panel~c) the tree-based models can compensate for the low skill of the 
lagged response values employed as covariates and, hence, are still significantly 
superior to the reference.

%%
\begin{figure}[t]
  \centering
  \setkeys{Gin}{width=1.0\textwidth}
  \includegraphics{_plot_circforest_validation_crpsskill_agg_comparison_with_lowff_v14b.pdf}
  \caption{As Figure~\ref{fig:boxplot_crpsraw}, but showing CRPS skill scores
    with the climatology model as reference. Skill scores are in percent; positive
    values indicate improvements over the reference.} 
  \label{fig:boxplot_crpsskill} 
\end{figure}
%%

% -------------------------------------------------------------------
% Summary
% -------------------------------------------------------------------
\section{Summary and conclusion}
\label{sec:summary}
Circular regression trees for circular responses are established by
coupling model-based recursive partitioning with the von Mises distribution.
The resulting trees can capture non-linear changes, shifts, and potential
interactions in covariates without prespecification of such effects. This is
particularly useful for modeling a highly fluctuating response such as wind
direction. \dots

\begin{itemize}
  \item Add summary/conclusion of case study;
  \item Add summary/conclusion of circular regression trees and forests.
  \item Outlook on possible extensions (use of NWP data, circular splits, ...).
\end{itemize}

\section*{Acknowledgments}
This project was partially funded by the Austrian Research Promotion
Agency~(FFG) grant number~$858537$. Torsten Hothorn received funding from the
Swiss National Science Foundation, grant number~$200021\_184603$. Lisa
Schlosser received a PhD scholarship granted from the University of Innsbruck.

\section*{Computational details}
The corresponding implementation of the proposed methodology for circular
trees and forests is provided in the \textsf{R}
package \textbf{circtree} (version~\Sexpr{packageVersion("circtree")}).
% The proposed circular tree and forest models are implemented in the \textsf{R}
% package \textbf{circtree} (version~\Sexpr{packageVersion("circtree")}). 
The package is based on the \textbf{disttree} package
(version~\Sexpr{packageVersion("disttree")}) which applies the main tree
building functions from the \textbf{partykit} package
(version~\Sexpr{packageVersion("partykit")}). All three packages are available
on \textsf{R}-Forge at \url{https://R-Forge.R-project.org/projects/partykit/}.

For the circular GLM considered as reference model the corresponding
implementation is provided in the \textsf{R} package \textbf{circglmbayes} by
\cite{Mulder+Klugkist:2017}. In particular the function \code{circGLM} is
applied to estimates the intercept and regression coefficient along with the
concentration parameter.


%\newpage
\bibliography{ref.bib}

\begin{appendix}

\section{Tree algorithm}
\label{app:algorithm}
This section provides a more detailed overview on the permutation-test-based CTree algorithm 
\citep{Hothorn+Hornik+Zeileis:2006}, 
specifically for circular data as applied to build the circular regression trees and forests 
in the presented case study. 
Alternatively, also the MOB algorithm, which is based on M-fluctuation tests, can be employed 
\citep[see][for more details]{Zeileis+Hothorn+Hornik:2008}.

\subsection*{CTree}
In the following, the testing and splitting strategy is described for the root node of the tree
which contains the entire learning sample.
%consisting of circular observations denoted by $\{y_i\}_{i = 1,\ldots,n}$, $n \in \mathbb{N}$. 
For a complete tree model, the same procedure is applied iteratively to all resulting child nodes 
with the corresponding subsamples.

First, employing the von Mises distribution, a distributional model $\text{vM}(Y; \mu,\kappa)$ 
is fitted to the learning sample of circular observations $\{y_i\}_{i = 1,\ldots,n}$ as explained 
in Section~\ref{sec:prob_circ}.
In a next step, a goodness-of-fit measurement %of $\text{vM}(Y; \mu,\kappa)$ 
is obtained for each parameter and each observation by evaluating the score 
function $s(\mu, \kappa, Y)$ at the estimated location and concentration 
parameter $\hat{\mu}$ and $\hat{\kappa}$.
To detect dependencies between the resulting score values
\begin{equation}
s(\hat{\mu}, \hat{\kappa}, y) = 
\begin{pmatrix} 
s(\hat{\mu}, \hat{\kappa}, y_1)_1 & s(\hat{\mu}, \hat{\kappa}, y_1)_2\\
\vdots & \vdots\\
s(\hat{\mu}, \hat{\kappa}, y_n)_1 & s(\hat{\mu}, \hat{\kappa}, y_n)_2
\end{pmatrix}
\end{equation}
and each possible split variable $Z_l \in \{Z_1, \ldots, Z_m\}$ a permutation test is applied. 
In particular, the hypotheses
\begin{align}
H_0^l:  s(\hat{\mu}, \hat{\kappa}, Y) \qquad \bot \qquad Z_l
\end{align}
is assessed by employing the multivariate linear statistic
\begin{equation}
T_l = vec\left(\sum_{i=1}^n v_l(Z_{li}) \cdot s(\hat{\mu}, \hat{\kappa}, Y_i)\right)
\end{equation}
with $s(\hat{\mu}, \hat{\kappa}, Y_i) \in \mathbb{R}^{1\times 2}$. 
For a numeric split variable $Z_l$ the transformation function $v_l$
is simply the identity function $v_l(Z_{li}) = Z_{li}$ such that $T_l \in \mathbb{R}^2$ 
as the ``vec'' operator converts the matrix of dimension $1 \times 2$ into a $2$ column vector.
If $Z_l$ is a categorical variable with $H$ categories then 
$v_l(Z_{li}) = (\I(Z_{li} = 1), \ldots, \I(Z_{li} = H))$, hence, $v_l$ returns a unit vector
of dimension $H$ where the entry $1$ indicates the category of $Z_{li}$. 
In this case the ``vec'' operator converts the $H \times 2$ matrix into a $H \cdot 2$ column vector 
by column-wise combination such that $T_l \in \mathbb{R}^{H \cdot 2}$. 
If there are any observations with missing values these are not included in the calculation of $T_l$.

To map the observed multivariate linear statistic $t_l$ onto the real line a univariate test statistic
$c$ is employed, for example in a quadratic form
\begin{equation}
c_{\text{quad}}(t_l,\mu_l,\Sigma_l) = (t_l-\mu_l)\Sigma_l^+(t_l-\mu_l)^{\top}
\end{equation}
where $\mu_l$ and $\Sigma_l$ are the conditional expectation and the covariance of $T_l$,
as derived by \cite{Strasser+Weber:1999} and used to standardize $t_l$, and $\Sigma_l^+$ 
is the Moore-Penrose inverse of $\Sigma_l$.
As an alternative, also a maximum form ($c_{\text{max}}$) can be considered such that
the maximum of the absolute values of the standardized linear statistic is returned.

The asymptotic conditional distribution of $c(t_{l},\mu_{l},\Sigma_{l})$ 
is either normal (for $c_{\text{max}}$) or $\chi^2$ (for $c_{\text{quad}}$) owing to 
the asymptotic conditional distribution of the linear statistic $t_l$ being a multivariate 
normal with parameters $\mu_l$ and $\Sigma_l$ \citep{Strasser+Weber:1999}.
With this knowledge at hand, the corresponding $p$-values can be calculated and used
to select the best splitting variable. A small $p$-value corresponding to 
$c(t_{l},\mu_{l},\Sigma_{l})$ indicates a strong discrepancy from the assumption of independence 
between the scores and the split variable $Z_l$.
Therefore, if any of the Bonferroni-adjusted $p$-values is beneath the selected significance level,
the partitioning variable $Z_{l^\ast}$ with the lowest $p$-value is selected as split variable, otherwise 
no split is performed. This early stopping induced by the significance level is referred to as 
``pre-pruning'' which is often avoided for forest models by setting the significance level to $1$.

To select the best split point within the already chosen split variable, again, a linear test statistic
is employed. In particular, for a breakpoint $r$ of the variable $Z_{l^{\ast}}$ leading to two subgroups 
$\mathcal{B}_{1r}$ and $\mathcal{B}_{2r}$ the discrepancy between score functions in the subgroups
is measured by evaluating
\begin{equation}
T_{l^{\ast}}^{qr} = \sum_{i \in \mathcal{B}_{qr}} s(\hat{\mu}, \hat{\kappa}, Y_i)
\end{equation}
for $q \in \{1,2\}$.
The breakpoint that leads to the highest discrepancy is then selected as split point as defined by
\begin{equation}
r^{\ast} = \argmin_{r} (\min_{q=1,2}(c(t_{l^{\ast}}^{qr},\mu_{l^{\ast}}^{qr},\Sigma_{l^{\ast}}^{qr})).
\end{equation}

Subsequently, the same testing and splitting procedure is repeated in each of the resulting 
subgroups until some stopping criterion is reached. Next to the already mentioned 
significance-level-based stopping criterion, i.e., a minimal $p$-value for the statistical tests,
also a maximal tree depth or a minimal number of observations in a node can be employed as stopping
criteria.

%This permutation-test-based tree algorithm is presented in 
%\cite{Hothorn+Hornik+Zeileis:2006} as the CTree algorithm. 
%A different framework to build a likelihood-based tree is provided by the MOB algorithm 
%which is based on M-fluctuation tests (\citealp{Zeileis+Hothorn+Hornik:2008}).



%\subsection{Teststatistic: CTree}\label{app:teststat_ctree}
%To measure the association of a response $Y$ and each possible split variable $Z_j$, $j=1,\ldots,J$,
%the CTree algorithm applies a linear test statistic $T_j$ which is excerpted from Section~3.1.
%(``Variable selection and stopping criteria'') of the original paper 
%\citep{Hothorn+Hornik+Zeileis:2006} and is of the following form:
%$$
%T_j(Y, Z_j, w) = \text{vec}\left( \sum_{i=1}^N w_i g_j(Z_{ji})h(Y_i)^{\top}\right)
%$$
%where $w$ are optional weights, $g_j: \mathcal{Z}_j \rightarrow \mathbb{R}^{P}$ is a nonrandom 
%transformation of the split variable $Z_j$ and the influence function 
%$h: \mathcal{Y} \times \mathcal{Y}^N \rightarrow \mathbb{R}^Q$ depends on the response 
%$Y = (Y_1, \ldots, Y_N)$ in a permutation symmetric way and is set to 
%$h(Y_i) = s(Y_i, X_i, \hat{\beta})$ for a score-based approach. 
%Moreover, by applying the ``vec'' operator the resulting
%$P~\times~Q$ matrix is converted into a $PQ$ column vector.
%Following \cite{Strasser+Weber:1999}
%the conditional expectation $\mu_j$ and covariance $\Sigma_j$ of a linear test statistic
%$T_j$ can be calculated and used to standardize an observed linear test statistic $t_j$ within a 
%function $c$ mapping into the real line.
%For example, the maximum of the absolute values of the standardized linear statistic
%$$
%c_{\max}(t_j,\mu_j,\Sigma_j) = \max \left| \frac{(t_j-\mu_j)}{\text{diag}(\Sigma_j)} \right|
%$$
%or a quadratic form
%$$
%c_{\text{quad}}(t_j, \mu_j, \Sigma_j) = (t_j - \mu_j)\Sigma_j^{+} (t_j - \mu_j)^{\top}
%$$
%can be considered where $\Sigma_j^{+}$ is the Moore-Penrose inverse of $\Sigma_j$.
%Since the asymptotic conditional distribution of a linear test statistic $T_j$ is a 
%multivariate normal with parameters $\mu_j$ and $\Sigma_j$ \citep{Strasser+Weber:1999}, 
%the asymptotic distribution of $c_{\text{max}}$ is normal while the quadratic form 
%$c_{\text{quad}}$ follows an asymptotic $\chi^2$~distribution. Based on this knowledge 
%the corresponding $p$-values can be calculated easily.

\end{appendix}

\end{document}
