\documentclass[english, noconfig]{uibklttr}

\newcommand{\section}[1]{{\Large{\textbf{#1}}}}
\newcommand{\subsection}[1]{{\large \textbf{#1}}}
\newcommand{\subsubsection}[1]{{\large \textbf{#1}}}
\newcommand{\tightlist}[0]{}

% Some colors
\definecolor{myblue}{rgb}{0.2,0.2,0.9}
\definecolor{mygray}{rgb}{0.7,0.7,0.7}

\makeatletter
\newenvironment{thebibliography}[1]
     {\list{\@biblabel{\@arabic\c@enumiv}}%
           {\settowidth\labelwidth{\@biblabel{#1}}%
            \leftmargin\labelwidth
            \advance\leftmargin\labelsep
            \usecounter{enumiv}%
            \let\p@enumiv\@empty
            \renewcommand\theenumiv{\@arabic\c@enumiv}}%
      \sloppy
      \clubpenalty4000
      \@clubpenalty \clubpenalty
      \widowpenalty4000%
      \sfcode`\.\@m}
     {\def\@noitemerr
       {\@latex@warning{Empty `thebibliography' environment}}%
      \endlist}
\newcommand\newblock{\hskip .11em\@plus.33em\@minus.07em}
\makeatother
\usepackage{natbib}

%\usepackage{subcaption}
%\captionsetup{font={bf,small},skip=0.25\baselineskip}
%\captionsetup[subfigure]{font={bf,small}, skip=1pt, singlelinecheck=false}

\usepackage{amsmath}

\usepackage{float} % For figure placements
\usepackage{enumitem}
\setitemize{itemsep=0em}
\setlist{itemsep = 0em}

\usepackage{parskip}
\setlength{\parskip}{.4em}

% fake-float with caption for figures
\usepackage{caption}
\usepackage{newfloat}
\DeclareFloatingEnvironment[fileext=lot]{figure}
\DeclareCaptionFont{myblue}{\color{myblue}}
\captionsetup{labelfont={bf},textfont={it}}

% short re
\newcommand{\sre}[1]{
    \begin{color}{uibkgraym}#1\end{color}%
}
% long re
\newenvironment{re}{
    \begin{color}{uibkgraym}
        \itshape
}{
    \end{color}
}
\newcommand{\todo}[1]{
    \begin{color}{red}\textbf{TODO:} #1\end{color}%
}
\newcommand{\note}[1]{
    \begin{color}{orange}\textbf{Reto's comment:} #1\end{color}%
}
\newcommand{\see}[2]{Page \textbf{#1}, line \textbf{#2}.}
\newcommand{\msee}[3]{Page \textbf{#1}, lines \textbf{#2--#3}.}
\newcommand{\fig}[1]{\textit{now Fig~#1}}
\newcommand{\nsec}[1]{\textit{now Sec~#1}}


\begin{document}

\setkomavar{subject}{Revision of `JRSS-SC-Jan-20-0007'}
\setkomavar{signature}{Moritz Lang\\Corresponding Author}

\setkomavar{fromname}[Name]{Moritz Lang}
\setkomavar{fromemail}{Moritz.Lang@uibk.ac.at}




\setkomavar{fromaddress}{University of Innsbruck, Department of Statistics, Universit\"atsstrasse
15, 6020 Innsbruck, Austria}

\begin{letter}[fromemail]{To Prof. Peter Smith}
\opening{Dear Prof. Peter Smith}

We thank you, as well as the associate editor and both reviewers, for the
positive and constructive feedback regarding our manuscript ``\textbf{Circular
Regression Trees and Forests with an Application to Probabilistic Wind
Direction Forecasting}''.

\vspace{5mm}

We have carefully revised our manuscript according to given comments.
The most substantial changes in the manuscript are the following:

\begin{itemize}
\item We have fully revised the `Abstract' in order to put a larger
focus on the application. In addition, we now use the term `application' 
instead of `case study' throughout the manuscript and have also renamed Sect.~4 accordingly.
 
\item In the section `Computational details', we have additionally listed the needed
computing time of the different methods on a standard desktop computer. 

\item We now discuss the work of Hara and Chellappa~(2017) and compare their distribution-based 
tree-building approach to our implementation of circular distributional trees within Sect.~1.1.

\item Regarding the employed GLM implemented by Mulder and Klugkist~(2017), we now
explicitly state that the accommodation of circular covariates would be possible
but would require an additional manual adjustment, e.g., an approximation by a finite
Fourier expansion (cf., Lund 1999).

\end{itemize}

\vspace{5mm}

On the following pages a point-to-point response to all comments will be given.
The attached manuscript highlights the changes in the text in blue color.

\closing{Yours sincerely,}

\end{letter}

\newpage

\section{Editor: Prof. Peter Smith - Comments to the Author}

\begin{re}
Please can you rewrite the Summary to give the application more prominence.
Currently, the last sentence reads to me like an afterthought. Furthermore, I
would prefer you to use the term `application' rather than `case study'
throughout the paper, since in Applied Statistics papers the methodological
developments should be motivated by the application.
\end{re}

\vspace{-1em}
First of all we want to thank you for your valuable input. 

We agree with your comment and have rewritten the `Abstract' to put a larger
focus on the application. Throughout the manuscript we now use the term
`application' instead of `case study' and have also renamed Sect.~4
accordingly.

\vspace{0.5em}
\begin{re}
Page 2, line 46: `… structure can capture non-additive …'?
\end{re}

Thank you, we have rephrased the sentence according to your suggestion.

\vspace{0.5em}
\begin{re}
Page 2, lines 54 and 55: `… mean, whereas modelling the conditional …
distribution would also allow uncertainty in the forecast to be estimated.'?
\end{re}

We have rephrased the sentence accordingly.

\vspace{0.5em}
\begin{re}
Page 6, line 16 and Equation (2.6): bold the vector $\beta$.
\end{re}

Thank you for pointing that out, we have corrected that accordingly.

\vspace{0.5em}
\begin{re}
Page 6, lines 29 and 30: `In general, for additive models a proper model …'?
\end{re}

We have rephrased the sentence according to your suggestion.

\vspace{0.5em}
\begin{re}
Equations (3.1) to (3.4) and elsewhere: I find the use of multiple letters for a single superscript or subscript awkward and prefer to keep lower case letters for indices, so please consider replacing them, for example, T for tree and F for forest. Also for Equation (4.2), how about using parentheses rather than subscripts?
\end{re}

We have followed your suggestions and now use only single letters for super-
and subscripts in the main body of the manuscript. In the appendix, we keep the
notation as it is in order to be consistent with the referenced article by Hothorn~\emph{et al.}~2006.

\vspace{0.5em}
\begin{re}
Equation (3.4): bold vector $z$.
\end{re}

Thank you for pointing that out, the font style has been adapted.

\vspace{0.5em}
\begin{re}
Page 9, line 39: delete `respectively'.
\end{re}

We have corrected the sentence accordingly.

\vspace{0.5em}
\begin{re}
Page 15, line 23: replace `leveraged' with `used'?
\end{re}

We have rephrased the sentence accordingly.

\vspace{0.5cm}
References

Hothorn T, Hornik K, Zeileis A (2006). ``Unbiased Recursive Partitioning: A Conditional
Inference Framework.'' \emph{Journal of Computational and Graphical Statistics}, \textbf{15}\,(3), 651--674.
doi:10.1198/106186006x133933.

\newpage

\section{Associate Editor - Comments to the Author}

\begin{re}
Both referees agree this is a good paper, and have only a few suggestions for
changes, so I recommend minor revisions to address these. I have two short suggestions in addition to this:

Can you comment on the typical computational requirements of the various
methods used in your application, in terms of hardware required and length of
computing time.
\end{re}

We first want to thank you for the positive feedback and your valuable input. 

We agree with your comment that additional information on the calculation
requirements is valuable for the user. We have therefore listed the needed
computing time of the different methods on a standard desktop computer within
the section 'Computational details'.

\vspace{0.5em}
\begin{re}
Is it possible to include a link to computer code to reproduce your
analysis? This is not essential for publication but would be helpful for
readers who wish to perform similar analyses. The R package you have provided
for your method is very helpful in this regard.  
\end{re}

As we have used data from the Austrian air navigation service provider, which
we are not entitled to distribute, we are unfortunately not able to provide
code and data to reproduce the application. However, as you have already
pointed out the implementation of circular regression trees and forests is
provided in a freely available R-package with examples included in the documentation.
Independent of this publication, we are planning to provide an updated online
platform for the whole `partykit' project in the near future.

\newpage

\section{Referee: 1 - Comments to the Author}

\begin{re}
I found Circular Regression Trees and Forests to be a very nicely written
paper, with a meaningful contribution to the literature on regression models
for a circular response variable. 
\end{re}

\begin{re}
I have very few suggestions to the authors; but here are two:

On page 2, what is the reference for the phrase "Additionally, they
developed a combined ... version ...".
\end{re}

First of all we want to thank you for your positive and constructive feedback.

Thanks for pointing out that the citation here is not clearly assigned. We have therefore
listed the references at the end of the sentence once more.

\vspace{0.5em}
\begin{re}
On page 11, regarding "As the implementation cannot handle circular
covariates ...": It could handle circular covariates in a fashion similar to
Lund (1999), using a rotational or reflective relationship, or modeling the
association with a trigonometric polynomial. Adding this to their comparison
model, or at least mentioning the possibility of doing so, would be more
appropriate than stating that circular covariates cannot be accommodated.
\end{re}

A very good remark. We have adapted the statement accordingly and now
explicitly state that the accommodation of circular covariates would be
possible but would require an additional manual adjustment, e.g., an approximation by
a finite Fourier expansion.

\vspace{0.5cm}
References

Lund UJ (1999). ``Least Circular Distance Regression for Directional Data.''
\emph{Journal of Applied Statistics}, \textbf{26}\,(6), 723--733.
doi:10.1080/02664769922160.

\newpage

\section{Referee: 2 - Comments to the Author}

\begin{re}
This is a well-written paper on using circular regression trees for analyzing a
specific type of circular data. The probabilistic approach is well-founded. The
experiments on wind direction data are well organized and the results are
thoroughly analyzed.
\end{re}

\begin{re}
The authors could address model order determination problem using the
Bayes Information Criterion (Schwartz, 1978, Annals of Statistics).  
\end{re}

First of all we want to thank you for your positive feedback and valuable input. 

Regarding your suggestion, when building a circular distributional tree, the
package \textbf{circtree} uses per default \emph{p}-values from association
tests both for selecting the split variable and for a so-called pre-pruning
strategy which stops growing the tree as soon as no significant associations
can be found in a given subgroup. This is the default in both available
unbiased recursive partitioning algorithms CTree and MOB. For the latter, as
discussed by Zeileis~\emph{et al.}~(2008), an alternative, already implemented
strategy  is to use information criteria such as AIC (Akaike information
criterion) or BIC (Bayes information criterion) for post-pruning (after growing
the initial tree).  As we use neither MOB nor post-pruning in the presented
application, we refrain from discussing this aspect any further in the
manuscript. However, we want to refer to the submitted manuscript by
Schlosser~\emph{et al.}~2019 which investigates the performance of different 
testing and pruning strategies employed in unbiased recursive partitioning algorithms.

\vspace{0.5em}
\begin{re}
I would like to point out related works on circular regression models for
shape representation (Kashyap and Chellappa) and circular random forests for
vehicle direction estimation (Hara and Chellappa) given below. I feel there is
some overlap between this paper and the work of Hara and Chellappa on using
circular statistics for vehicle orientation estimation. The authors may include
some comparisons with Hara, Chellappa work.
\end{re}

Thank you very much for the very interesting and to us unfortunately so far unknown references.
We now review the work of Hara and Chellappa~(2017) and briefly compare their approach
to our implementation of circular distributional trees in Sect.~1.1.

\vspace{0.5cm}
References

Hara K, Chellappa R (2017). ``Growing Regression Tree Forests by
Classification for Continuous Object Pose Estimation.'' \emph{International
Journal of Computer Vision}, \textbf{122}\,(2), 292--312.
doi:10.1007/s11263-016-0942-1.

Kashyap R, Chellappa R (1981). ``Stochastic Models for Closed Boundary
Analysis: Representation and Reconstruction.'' \emph{IEEE Transactions on
Information Theory}, \textbf{27}\,(5), 627--637. doi:10.1109/TIT.1981.1056390.

Schlosser L, Hothorn T, Zeileis A (2019). ``The Power of Unbiased Recursive
Partitioning: A Unifying View of CTree, MOB, and GUIDE.'' arXiv:1906.10179,
arXiv.org E-Print Archive.

Zeileis A, Hothorn T, Hornik K (2008). ``Model-Based Recursive Partitioning.''
\emph{Journal of Computational and Graphical Statistics}, \textbf{17}\,(2),
492--514. doi:10.1198/106186008x319331.

\end{document}
